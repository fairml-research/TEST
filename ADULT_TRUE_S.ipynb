{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ADULT_TRUE_S.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmE44i++f959EiOyDwjoZp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fairml-research/TEST/blob/main/ADULT_TRUE_S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNURgdnKSxAJ",
        "outputId": "1469d193-cc88-4551-9c33-2e3cd578c0a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkTzod-UBvg2",
        "outputId": "6be141a7-603a-4f89-b810-789565447b27"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(7)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\n",
        "from IPython import display\n",
        "%matplotlib inline\n",
        "import sys \n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import keras as ke\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "def load_ICU_data(path):\n",
        "    column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', \n",
        "                    'marital_status', 'occupation', 'relationship', 'race', 'sex', \n",
        "                    'capital_gain', 'capital_loss', 'hours_per_week', 'country', 'target']\n",
        "    input_data = (pd.read_csv(path, names=column_names, \n",
        "                              na_values=\"?\", sep=r'\\s*,\\s*', engine='python'))\n",
        "                  #.loc[lambda df: df['race'].isin(['White', 'Black'])])\n",
        "    input_data = pd.concat([input_data, pd.read_csv('http://grarivincent.com/old/adult.test', names=column_names, na_values=\"?\", sep=r'\\s*,\\s*', engine='python').loc[1:,:] ])\n",
        "\n",
        "    input_data[['age','fnlwgt','education_num','capital_gain', 'capital_loss', 'hours_per_week']] = input_data[['age','fnlwgt','education_num','capital_gain', 'capital_loss', 'hours_per_week']].astype(int)\n",
        "    \n",
        "    # sensitive attributes; we identify 'race' and 'sex' as sensitive attributes\n",
        "    sensitive_attribs = ['sex']\n",
        "    Z = (input_data.loc[:, sensitive_attribs]\n",
        "         .assign(sex=lambda df: (df['sex'] == 'Male').astype(int)))\n",
        "    # targets; 1 when someone makes over 50k , otherwise 0\n",
        "    y = input_data['target'].replace({'<=50K.': 0, '>50K.': 1, '>50K': 1, '<=50K': 0 })\n",
        "    XNC = input_data.loc[:, ['race','age','country']]\n",
        "    XNC = XNC.assign(race=lambda df: (df['race'] == 'White').astype(int))\n",
        "    print(XNC.shape)\n",
        "    XNC = (XNC\n",
        "           .fillna('Unknown')\n",
        "           .pipe(pd.get_dummies, columns = ['country'], drop_first=True))\n",
        "    # features; note that the 'target' and sentive attribute columns are dropped\n",
        "    X = (input_data\n",
        "         .drop(columns=['target','race','age','sex','country'])\n",
        "         .fillna('Unknown')\n",
        "         .pipe(pd.get_dummies, columns = ['workclass', 'education', \n",
        "                    'marital_status', 'occupation', 'relationship']))\n",
        "    G = pd.DataFrame({'G1': X['relationship_Wife'], 'G2': X['relationship_Husband']})\n",
        "    X = X.drop(columns=['relationship_Wife', 'relationship_Husband'])\n",
        "\n",
        "    print(f\"features X: {X.shape[0]} samples, {X.shape[1]} attributes\")\n",
        "    print(f\"features X_NC: {XNC.shape[0]} samples, {XNC.shape[1]} attributes\")\n",
        "    print(f\"targets y: {y.shape[0]} samples\")\n",
        "    print(f\"sensitives Z: {Z.shape[0]} samples, {Z.shape[1]} attributes\")\n",
        "    return X, XNC, y, Z, G\n",
        "\n",
        "# load ICU data set\n",
        "X, XNC, y, S, G = load_ICU_data('http://grarivincent.com/old/adult.data') "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48841, 3)\n",
            "features X: 48841 samples, 56 attributes\n",
            "features X_NC: 48841 samples, 43 attributes\n",
            "targets y: 48841 samples\n",
            "sensitives Z: 48841 samples, 1 attributes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "ju4B3uI9guhr",
        "outputId": "e7db5bcc-d106-412a-fd35-15dd60cfb56b"
      },
      "source": [
        "G"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16276</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16277</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16278</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16279</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16280</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48841 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       G1  G2\n",
              "0       0   0\n",
              "1       0   1\n",
              "2       0   0\n",
              "3       0   1\n",
              "4       1   0\n",
              "...    ..  ..\n",
              "16276   0   0\n",
              "16277   0   0\n",
              "16278   0   1\n",
              "16279   0   0\n",
              "16280   0   1\n",
              "\n",
              "[48841 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Geo8IRwRfUFe"
      },
      "source": [
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', \n",
        "                'marital_status', 'occupation', 'relationship', 'race', 'sex', \n",
        "                'capital_gain', 'capital_loss', 'hours_per_week', 'country', 'target']\n",
        "input_data = (pd.read_csv('http://grarivincent.com/old/adult.data', names=column_names, \n",
        "                          na_values=\"?\", sep=r'\\s*,\\s*', engine='python'))\n",
        "              #.loc[lambda df: df['race'].isin(['White', 'Black'])])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "1jZZlfmAfaMS",
        "outputId": "45855548-b42e-40cb-d4d6-6a5daeab169b"
      },
      "source": [
        "input_data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>country</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32556</th>\n",
              "      <td>27</td>\n",
              "      <td>Private</td>\n",
              "      <td>257302</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32557</th>\n",
              "      <td>40</td>\n",
              "      <td>Private</td>\n",
              "      <td>154374</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32558</th>\n",
              "      <td>58</td>\n",
              "      <td>Private</td>\n",
              "      <td>151910</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32559</th>\n",
              "      <td>22</td>\n",
              "      <td>Private</td>\n",
              "      <td>201490</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32560</th>\n",
              "      <td>52</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>287927</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>15024</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32561 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age         workclass  fnlwgt  ... hours_per_week        country target\n",
              "0       39         State-gov   77516  ...             40  United-States  <=50K\n",
              "1       50  Self-emp-not-inc   83311  ...             13  United-States  <=50K\n",
              "2       38           Private  215646  ...             40  United-States  <=50K\n",
              "3       53           Private  234721  ...             40  United-States  <=50K\n",
              "4       28           Private  338409  ...             40           Cuba  <=50K\n",
              "...    ...               ...     ...  ...            ...            ...    ...\n",
              "32556   27           Private  257302  ...             38  United-States  <=50K\n",
              "32557   40           Private  154374  ...             40  United-States   >50K\n",
              "32558   58           Private  151910  ...             40  United-States  <=50K\n",
              "32559   22           Private  201490  ...             20  United-States  <=50K\n",
              "32560   52      Self-emp-inc  287927  ...             40  United-States   >50K\n",
              "\n",
              "[32561 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E1to_Ad0UmX"
      },
      "source": [
        "# split into train/test set\n",
        "X_train, X_test, XNC_train, XNC_test, y_train, y_test, S_train, S_test, G_train, G_test = train_test_split(X, XNC, y, S, G.values, test_size=0.2, random_state=7)\n",
        "\n",
        "# standardize the data\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "scale_df = lambda df, scaler: pd.DataFrame(scaler.transform(df), columns=df.columns, index=df.index)\n",
        "\n",
        "scalerNC = MinMaxScaler().fit(XNC_train)\n",
        "scale_dfNC = lambda df, scaler: pd.DataFrame(scalerNC.transform(df), columns=df.columns, index=df.index)\n",
        "\n",
        "X_train, X_test = X_train.pipe(scale_df, scaler), X_test.pipe(scale_df, scaler)\n",
        "XNC_train, XNC_test = XNC_train.pipe(scale_dfNC, scaler), XNC_test.pipe(scale_dfNC, scalerNC)\n",
        "X_train, X_test, XNC_train, XNC_test, y_train, y_test = X_train.values, X_test.values, XNC_train.values, XNC_test.values, y_train.values, y_test.values\n",
        "\n",
        "S_train, S_test =S_train.values, S_test.values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJvYAP5OhByr",
        "outputId": "78e1e416-6b70-4ed7-93f5-924ad9f5edfd"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39072, 56)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4i3l_WWhELz",
        "outputId": "830444de-f247-444d-dffb-a09c0802b309"
      },
      "source": [
        "XNC_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39072, 43)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mgobh6_ThduN",
        "outputId": "b2119e8b-65b9-42b0-e586-4773c04411f3"
      },
      "source": [
        "53+43+1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce4cUstCP8BE",
        "outputId": "7ae26235-8ac6-4170-8349-4cc2c807eadb"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0948343 , 0.8       , 0.14344143, ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.09831035, 0.6       , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.35573281, 0.8       , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.11796308, 0.6       , 0.        , ..., 0.        , 1.        ,\n",
              "        0.        ],\n",
              "       [0.0704316 , 0.8       , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.14809064, 0.53333333, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7cTUDq6uloeP",
        "outputId": "f34be0db-762a-4d57-c4fd-3689ae7df6dd"
      },
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "H = 15\n",
        "H2 = 15\n",
        "epochs_hgr=50\n",
        "\n",
        "\n",
        "batch_size = 1024\n",
        "num_epochs = 75\n",
        "learning_rate = 0.001\n",
        "batch_no = len(X_train) // batch_size\n",
        "#X_train_inv = recon_X_batch_a.data.numpy()\n",
        "#Y_train_inv = recon_Y_batch_a.data.numpy()\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from torch.autograd import Variable\n",
        "criterionMSE = nn.MSELoss()\n",
        "import math\n",
        "nb_a=200\n",
        "from torch.nn import functional as F\n",
        "def sigmoid(x):\n",
        "  output = [1 / (1 + math.exp(-x)) for x in x]\n",
        "  return output\n",
        "\n",
        "class NN_b(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN_b, self).__init__()\n",
        "        self.fc1 = nn.Linear(99, 32)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, 8)\n",
        "        self.fc4 = nn.Linear(8, 1)        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "class NN_s(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN_s, self).__init__()\n",
        "        self.fc1_s = nn.Linear(1, 8)\n",
        "        self.fc2_s = nn.Linear(8, 8)\n",
        "        self.fc3_s = nn.Linear(8, 1)\n",
        "        #self.fc4_s = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1_s(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2_s(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc3_s(x)\n",
        "        #x = torch.relu(x)\n",
        "        #x = self.fc4_s(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "m_NN_s = NN_s().to(device)\n",
        "optimizer_s = torch.optim.Adam(m_NN_s.parameters(), lr=learning_rate)\n",
        "\n",
        "model_Y_b = NN_b().cuda()\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer_Y = torch.optim.Adam(model_Y_b.parameters(), lr=learning_rate)\n",
        "criterion_ADV =  nn.MSELoss()\n",
        "#A0 = sensitive.mean() + sensitive.std()*Variable(torch.randn(data.shape[0]*nb_a, 1),requires_grad=False)\n",
        "#recon_X_batch_a0, z_a0, recon_Y_batch_a0, mu_a0, logvar_a0 = model(data.repeat(nb_a,1).view(-1, 33),A0)\n",
        "#recon_x, recon_xNC, S, U,  recon_y, mu, logvar = model(x_var, x_varNC, y_var,s_var)\n",
        "from sklearn.metrics import accuracy_score\n",
        "X_trainCUDA = Variable(torch.FloatTensor(X_train)).cuda()\n",
        "XNC_trainCUDA = Variable(torch.FloatTensor(XNC_train)).cuda()\n",
        "y_trainCUDA = Variable(torch.FloatTensor(np.expand_dims(y_train,axis = 1))).cuda()\n",
        "\n",
        "X_testCUDA = Variable(torch.FloatTensor(X_test)).cuda()\n",
        "XNC_testCUDA = Variable(torch.FloatTensor(XNC_test)).cuda()\n",
        "y_testCUDA = Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).cuda()\n",
        "\n",
        "\n",
        "G_trainCUDA = Variable(torch.FloatTensor(G_train)).cuda()\n",
        "G_testCUDA =  Variable(torch.FloatTensor(G_test)).cuda()\n",
        "\n",
        "table = [0,0,0,0,0,0,0,0]\n",
        "for epoch in range(num_epochs):\n",
        "    lambda_ADV =100\n",
        "    #if epoch % 50 != 0:\n",
        "        #x_train = Variable(torch.FloatTensor(X_train.values),requires_grad=True)\n",
        "        #x_test = Variable(torch.FloatTensor(X_test.values),requires_grad=True)\n",
        "        #print('Epoch {}'.format(epoch+1))\n",
        "        \n",
        "        #y_predX= model(x_train).data.numpy().T\n",
        "        #y_predXinv= model(recon_X_batch_a0).data.numpy().T\n",
        "\n",
        "        #accuracy = (y_train-np.squeeze(y_predX)).pow(2).sum()     \n",
        "        #accuracycount = accuracy_score(Y_train_inv.squeeze(1), np.squeeze(y_predXinv))\n",
        "        #print (\"Train Accuracy:\", accuracy)#,\"Train Accuracy Count:\", accuracycount, \"CLP:\", np.mean(logit_y_predX-logit_y_predXinv)**2)\n",
        "    x_train, x_trainNC, ytrain, sens_train, gtrain = shuffle(X_train, XNC_train, np.expand_dims(y_train,axis = 1),  S_train, G_train)\n",
        "\n",
        "    #A = s_var.mean() + s_var.std()*Variable(torch.randn(batch_size*nb_a, 1),requires_grad=False)\n",
        "    # Mini batch learning\n",
        "    for i in range(batch_no):\n",
        "        print('Epoch: ', epoch, 'Batch:',i)\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "\n",
        "        x_var = Variable(torch.FloatTensor(x_train[start:end])).cuda()\n",
        "        xNC_var = Variable(torch.FloatTensor(x_trainNC[start:end])).cuda()\n",
        "        y_var = Variable(torch.FloatTensor(ytrain[start:end])).cuda()\n",
        "        s_var = Variable(torch.FloatTensor(sens_train[start:end])).cuda()\n",
        "        # Forward + Backward + Optimize\n",
        "        Ypred_var0 = model_Y_b(torch.cat([xNC_var.view(-1, 43),x_var.view(-1, x_var.shape[1])],1)).detach()\n",
        "\n",
        "\n",
        "        for l in range(50):\n",
        "            optimizer_s.zero_grad()\n",
        "            Spred_var = m_NN_s(torch.sigmoid(Ypred_var0))\n",
        "            lossS = criterion(Spred_var, s_var)\n",
        "            optimizer_s.step()\n",
        "\n",
        "        optimizer_Y.zero_grad()\n",
        "        Ypred_var = model_Y_b(torch.cat([xNC_var.view(-1, 43),x_var.view(-1, x_var.shape[1])],1))\n",
        "        Spred_var = m_NN_s(torch.sigmoid(Ypred_var))\n",
        "        lossS = criterion(Spred_var, s_var)\n",
        "        lossY = criterion(Ypred_var, y_var)\n",
        "        loss =  lossY\n",
        "        if epoch >= 20:\n",
        "            loss =  -lambda_ADV * lossS + lossY\n",
        "        ret=lossS\n",
        "        loss.backward()\n",
        "        optimizer_Y.step()\n",
        "        print(loss)\n",
        "\n",
        "Ypred = torch.sigmoid(model_Y_b(torch.cat([XNC_trainCUDA.view(-1, 43),X_trainCUDA.view(-1, X_trainCUDA.shape[1])],1)))>0.5\n",
        "Ho = (S_train==1)\n",
        "Fe = (S_train==0)\n",
        "odds=Ypred.float()[Ho].mean()/ Ypred.float()[Fe].mean()\n",
        "PRULE= min(odds, 1/odds)\n",
        "\n",
        "\n",
        "Ypredtest = torch.sigmoid(model_Y_b(torch.cat([XNC_testCUDA.view(-1, 43),X_testCUDA.view(-1, X_testCUDA.shape[1] )],1)))>0.5\n",
        "Ho = (S_test==1)\n",
        "Fe = (S_test==0)\n",
        "odds=Ypredtest.float()[Ho].mean()/ Ypredtest.float()[Fe].mean()\n",
        "PRULEtest= min(odds, 1/odds)\n",
        "\n",
        "print('ACC Train',(Ypred==y_trainCUDA).sum()/X_train.shape[0], 'PRULE',PRULE, 'ACC Test',(Ypredtest==y_testCUDA).sum()/X_test.shape[0],'PRULEtest',PRULEtest)\n",
        "table = np.vstack([table,[num_epochs, lambda_ADV, (Ypred.cpu().data.numpy()==y_trainCUDA.cpu().data.numpy()).sum()/X_train.shape[0]*100,PRULE.cpu().data.numpy(),ret.cpu().data.numpy(), \n",
        "                        (Ypredtest.cpu().data.numpy()==y_testCUDA.cpu().data.numpy()).sum()/X_test.shape[0]*100,PRULEtest.cpu().data.numpy(),ret.cpu().data.numpy()]])\n",
        "\n",
        "np.savetxt('Adult_ZhangFairness', table[1:,])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 Batch: 0\n",
            "tensor(0.7167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 1\n",
            "tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 2\n",
            "tensor(0.7124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 3\n",
            "tensor(0.7095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 4\n",
            "tensor(0.7074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 5\n",
            "tensor(0.7055, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 6\n",
            "tensor(0.7048, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 7\n",
            "tensor(0.7018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 8\n",
            "tensor(0.7015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 9\n",
            "tensor(0.6999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 10\n",
            "tensor(0.6983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 11\n",
            "tensor(0.6968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 12\n",
            "tensor(0.6953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 13\n",
            "tensor(0.6937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 14\n",
            "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 15\n",
            "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 16\n",
            "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 17\n",
            "tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 18\n",
            "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 19\n",
            "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 20\n",
            "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 21\n",
            "tensor(0.6816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 22\n",
            "tensor(0.6783, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 23\n",
            "tensor(0.6780, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 24\n",
            "tensor(0.6754, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 25\n",
            "tensor(0.6736, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 26\n",
            "tensor(0.6722, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 27\n",
            "tensor(0.6686, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 28\n",
            "tensor(0.6704, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 29\n",
            "tensor(0.6662, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 30\n",
            "tensor(0.6637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 31\n",
            "tensor(0.6606, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 32\n",
            "tensor(0.6588, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 33\n",
            "tensor(0.6550, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 34\n",
            "tensor(0.6530, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 35\n",
            "tensor(0.6546, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 36\n",
            "tensor(0.6532, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 37\n",
            "tensor(0.6434, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 0\n",
            "tensor(0.6434, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 1\n",
            "tensor(0.6372, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 2\n",
            "tensor(0.6463, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 3\n",
            "tensor(0.6356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 4\n",
            "tensor(0.6310, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 5\n",
            "tensor(0.6303, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 6\n",
            "tensor(0.6241, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 7\n",
            "tensor(0.6220, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 8\n",
            "tensor(0.6186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 9\n",
            "tensor(0.6153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 10\n",
            "tensor(0.6111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 11\n",
            "tensor(0.6049, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 12\n",
            "tensor(0.6032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 13\n",
            "tensor(0.6046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 14\n",
            "tensor(0.6017, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 15\n",
            "tensor(0.5911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 16\n",
            "tensor(0.5826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 17\n",
            "tensor(0.5810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 18\n",
            "tensor(0.5764, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 19\n",
            "tensor(0.5771, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 20\n",
            "tensor(0.5585, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 21\n",
            "tensor(0.5667, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 22\n",
            "tensor(0.5624, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 23\n",
            "tensor(0.5502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 24\n",
            "tensor(0.5566, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 25\n",
            "tensor(0.5559, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 26\n",
            "tensor(0.5532, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 27\n",
            "tensor(0.5357, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 28\n",
            "tensor(0.5415, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 29\n",
            "tensor(0.5264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 30\n",
            "tensor(0.5252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 31\n",
            "tensor(0.5334, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 32\n",
            "tensor(0.5044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 33\n",
            "tensor(0.5013, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 34\n",
            "tensor(0.5134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 35\n",
            "tensor(0.5257, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 36\n",
            "tensor(0.5167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 37\n",
            "tensor(0.5194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 0\n",
            "tensor(0.5197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 1\n",
            "tensor(0.5074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 2\n",
            "tensor(0.4805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 3\n",
            "tensor(0.5073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 4\n",
            "tensor(0.4888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 5\n",
            "tensor(0.4807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 6\n",
            "tensor(0.4781, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 7\n",
            "tensor(0.4832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 8\n",
            "tensor(0.4791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 9\n",
            "tensor(0.5265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 10\n",
            "tensor(0.4948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 11\n",
            "tensor(0.4675, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 12\n",
            "tensor(0.4626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 13\n",
            "tensor(0.4575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 14\n",
            "tensor(0.4674, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 15\n",
            "tensor(0.4616, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 16\n",
            "tensor(0.4469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 17\n",
            "tensor(0.4565, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 18\n",
            "tensor(0.4458, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 19\n",
            "tensor(0.4363, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 20\n",
            "tensor(0.4322, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 21\n",
            "tensor(0.4592, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 22\n",
            "tensor(0.4238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 23\n",
            "tensor(0.4149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 24\n",
            "tensor(0.4215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 25\n",
            "tensor(0.4264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 26\n",
            "tensor(0.4170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 27\n",
            "tensor(0.4128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 28\n",
            "tensor(0.4254, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 29\n",
            "tensor(0.4211, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 30\n",
            "tensor(0.4231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 31\n",
            "tensor(0.3984, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 32\n",
            "tensor(0.3956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 33\n",
            "tensor(0.4186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 34\n",
            "tensor(0.3979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 35\n",
            "tensor(0.3960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 36\n",
            "tensor(0.3879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 37\n",
            "tensor(0.4018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 0\n",
            "tensor(0.4154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 1\n",
            "tensor(0.3991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 2\n",
            "tensor(0.4114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 3\n",
            "tensor(0.4144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 4\n",
            "tensor(0.3744, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 5\n",
            "tensor(0.3767, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 6\n",
            "tensor(0.3933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 7\n",
            "tensor(0.4163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 8\n",
            "tensor(0.3667, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 9\n",
            "tensor(0.3835, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 10\n",
            "tensor(0.4010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 11\n",
            "tensor(0.3660, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 12\n",
            "tensor(0.3921, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 13\n",
            "tensor(0.3695, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 14\n",
            "tensor(0.3926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 15\n",
            "tensor(0.3893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 16\n",
            "tensor(0.3903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 17\n",
            "tensor(0.3421, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 18\n",
            "tensor(0.3752, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 19\n",
            "tensor(0.3878, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 20\n",
            "tensor(0.3927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 21\n",
            "tensor(0.3659, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 22\n",
            "tensor(0.3687, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 23\n",
            "tensor(0.3610, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 24\n",
            "tensor(0.3859, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 25\n",
            "tensor(0.3726, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 26\n",
            "tensor(0.3426, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 27\n",
            "tensor(0.3803, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 28\n",
            "tensor(0.3799, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 29\n",
            "tensor(0.3614, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 30\n",
            "tensor(0.3669, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 31\n",
            "tensor(0.3759, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 32\n",
            "tensor(0.3717, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 33\n",
            "tensor(0.3783, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 34\n",
            "tensor(0.3494, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 35\n",
            "tensor(0.3626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 36\n",
            "tensor(0.3525, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 37\n",
            "tensor(0.3570, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 0\n",
            "tensor(0.3829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 1\n",
            "tensor(0.3669, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 2\n",
            "tensor(0.3640, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 3\n",
            "tensor(0.3825, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 4\n",
            "tensor(0.4033, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 5\n",
            "tensor(0.3286, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 6\n",
            "tensor(0.3635, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 7\n",
            "tensor(0.3557, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 8\n",
            "tensor(0.3823, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 9\n",
            "tensor(0.3529, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 10\n",
            "tensor(0.3453, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 11\n",
            "tensor(0.3576, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 12\n",
            "tensor(0.3661, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 13\n",
            "tensor(0.3836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 14\n",
            "tensor(0.3630, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 15\n",
            "tensor(0.3577, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 16\n",
            "tensor(0.3593, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 17\n",
            "tensor(0.3769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 18\n",
            "tensor(0.3596, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 19\n",
            "tensor(0.3953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 20\n",
            "tensor(0.3498, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 21\n",
            "tensor(0.3808, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 22\n",
            "tensor(0.3714, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 23\n",
            "tensor(0.3575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 24\n",
            "tensor(0.3645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 25\n",
            "tensor(0.3485, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 26\n",
            "tensor(0.3456, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 27\n",
            "tensor(0.3418, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 28\n",
            "tensor(0.3534, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 29\n",
            "tensor(0.3425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 30\n",
            "tensor(0.3545, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 31\n",
            "tensor(0.3688, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 32\n",
            "tensor(0.3327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 33\n",
            "tensor(0.3434, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 34\n",
            "tensor(0.3541, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 35\n",
            "tensor(0.3500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 36\n",
            "tensor(0.3206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 37\n",
            "tensor(0.3223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 0\n",
            "tensor(0.3484, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 1\n",
            "tensor(0.3812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 2\n",
            "tensor(0.3504, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 3\n",
            "tensor(0.3258, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 4\n",
            "tensor(0.3602, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 5\n",
            "tensor(0.3723, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 6\n",
            "tensor(0.3676, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 7\n",
            "tensor(0.3624, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 8\n",
            "tensor(0.3321, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 9\n",
            "tensor(0.3595, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 10\n",
            "tensor(0.3413, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 11\n",
            "tensor(0.3677, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 12\n",
            "tensor(0.3322, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 13\n",
            "tensor(0.3278, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 14\n",
            "tensor(0.3624, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 15\n",
            "tensor(0.3579, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 16\n",
            "tensor(0.3679, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 17\n",
            "tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 18\n",
            "tensor(0.3389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 19\n",
            "tensor(0.3416, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 20\n",
            "tensor(0.3726, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 21\n",
            "tensor(0.3597, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 22\n",
            "tensor(0.3734, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 23\n",
            "tensor(0.3538, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 24\n",
            "tensor(0.3481, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 25\n",
            "tensor(0.3769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 26\n",
            "tensor(0.3341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 27\n",
            "tensor(0.3510, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 28\n",
            "tensor(0.3577, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 29\n",
            "tensor(0.3336, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 30\n",
            "tensor(0.3647, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 31\n",
            "tensor(0.3471, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 32\n",
            "tensor(0.3712, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 33\n",
            "tensor(0.3291, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 34\n",
            "tensor(0.3720, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 35\n",
            "tensor(0.3128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 36\n",
            "tensor(0.3653, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 37\n",
            "tensor(0.3441, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 0\n",
            "tensor(0.3748, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 1\n",
            "tensor(0.3604, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 2\n",
            "tensor(0.3503, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 3\n",
            "tensor(0.3349, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 4\n",
            "tensor(0.3594, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 5\n",
            "tensor(0.3403, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 6\n",
            "tensor(0.3399, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 7\n",
            "tensor(0.3554, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 8\n",
            "tensor(0.3596, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 9\n",
            "tensor(0.3642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 10\n",
            "tensor(0.3195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 11\n",
            "tensor(0.3595, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 12\n",
            "tensor(0.3659, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 13\n",
            "tensor(0.3312, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 14\n",
            "tensor(0.3441, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 15\n",
            "tensor(0.3591, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 16\n",
            "tensor(0.3587, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 17\n",
            "tensor(0.3419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 18\n",
            "tensor(0.3426, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 19\n",
            "tensor(0.3524, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 20\n",
            "tensor(0.3392, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 21\n",
            "tensor(0.3596, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 22\n",
            "tensor(0.3712, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 23\n",
            "tensor(0.3419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 24\n",
            "tensor(0.3570, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 25\n",
            "tensor(0.3413, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 26\n",
            "tensor(0.3489, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 27\n",
            "tensor(0.3282, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 28\n",
            "tensor(0.3080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 29\n",
            "tensor(0.3215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 30\n",
            "tensor(0.3374, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 31\n",
            "tensor(0.3601, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 32\n",
            "tensor(0.3340, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 33\n",
            "tensor(0.3380, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 34\n",
            "tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 35\n",
            "tensor(0.3527, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 36\n",
            "tensor(0.3715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 37\n",
            "tensor(0.3084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 0\n",
            "tensor(0.3631, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 1\n",
            "tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 2\n",
            "tensor(0.3227, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 3\n",
            "tensor(0.3346, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 4\n",
            "tensor(0.3642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 5\n",
            "tensor(0.3191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 6\n",
            "tensor(0.3289, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 7\n",
            "tensor(0.3466, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 8\n",
            "tensor(0.3682, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 9\n",
            "tensor(0.3726, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 10\n",
            "tensor(0.3687, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 11\n",
            "tensor(0.3458, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 12\n",
            "tensor(0.3454, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 13\n",
            "tensor(0.3303, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 14\n",
            "tensor(0.3199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 15\n",
            "tensor(0.3421, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 16\n",
            "tensor(0.3682, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 17\n",
            "tensor(0.3301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 18\n",
            "tensor(0.3275, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 19\n",
            "tensor(0.3413, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 20\n",
            "tensor(0.3649, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 21\n",
            "tensor(0.3283, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 22\n",
            "tensor(0.3502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 23\n",
            "tensor(0.3491, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 24\n",
            "tensor(0.3386, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 25\n",
            "tensor(0.3261, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 26\n",
            "tensor(0.3896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 27\n",
            "tensor(0.3295, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 28\n",
            "tensor(0.3361, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 29\n",
            "tensor(0.3598, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 30\n",
            "tensor(0.3389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 31\n",
            "tensor(0.3172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 32\n",
            "tensor(0.3522, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 33\n",
            "tensor(0.3284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 34\n",
            "tensor(0.3283, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 35\n",
            "tensor(0.3539, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 36\n",
            "tensor(0.3680, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 37\n",
            "tensor(0.3223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 0\n",
            "tensor(0.3397, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 1\n",
            "tensor(0.3559, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 2\n",
            "tensor(0.3199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 3\n",
            "tensor(0.3083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 4\n",
            "tensor(0.3247, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 5\n",
            "tensor(0.3457, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 6\n",
            "tensor(0.3518, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 7\n",
            "tensor(0.3392, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 8\n",
            "tensor(0.3362, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 9\n",
            "tensor(0.3821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 10\n",
            "tensor(0.3540, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 11\n",
            "tensor(0.3706, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 12\n",
            "tensor(0.3520, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 13\n",
            "tensor(0.3463, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 14\n",
            "tensor(0.3443, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 15\n",
            "tensor(0.3353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 16\n",
            "tensor(0.3674, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 17\n",
            "tensor(0.3135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 18\n",
            "tensor(0.3694, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 19\n",
            "tensor(0.3316, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 20\n",
            "tensor(0.3378, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 21\n",
            "tensor(0.3085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 22\n",
            "tensor(0.3336, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 23\n",
            "tensor(0.3340, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 24\n",
            "tensor(0.3452, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 25\n",
            "tensor(0.3384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 26\n",
            "tensor(0.3395, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 27\n",
            "tensor(0.3351, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 28\n",
            "tensor(0.3256, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 29\n",
            "tensor(0.3358, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 30\n",
            "tensor(0.3202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 31\n",
            "tensor(0.3326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 32\n",
            "tensor(0.3714, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 33\n",
            "tensor(0.3337, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 34\n",
            "tensor(0.3378, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 35\n",
            "tensor(0.3444, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 36\n",
            "tensor(0.3349, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 37\n",
            "tensor(0.3296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 0\n",
            "tensor(0.3532, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 1\n",
            "tensor(0.3313, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 2\n",
            "tensor(0.3583, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 3\n",
            "tensor(0.3327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 4\n",
            "tensor(0.3547, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 5\n",
            "tensor(0.3343, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 6\n",
            "tensor(0.3168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 7\n",
            "tensor(0.3392, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 8\n",
            "tensor(0.3322, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 9\n",
            "tensor(0.3479, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 10\n",
            "tensor(0.3500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 11\n",
            "tensor(0.3328, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 12\n",
            "tensor(0.3683, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 13\n",
            "tensor(0.3248, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 14\n",
            "tensor(0.3488, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 15\n",
            "tensor(0.3317, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 16\n",
            "tensor(0.3350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 17\n",
            "tensor(0.3426, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 18\n",
            "tensor(0.3508, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 19\n",
            "tensor(0.3195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 20\n",
            "tensor(0.3267, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 21\n",
            "tensor(0.3170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 22\n",
            "tensor(0.3379, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 23\n",
            "tensor(0.3255, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 24\n",
            "tensor(0.3521, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 25\n",
            "tensor(0.3354, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 26\n",
            "tensor(0.3226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 27\n",
            "tensor(0.3253, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 28\n",
            "tensor(0.3442, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 29\n",
            "tensor(0.3347, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 30\n",
            "tensor(0.3503, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 31\n",
            "tensor(0.3562, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 32\n",
            "tensor(0.3329, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 33\n",
            "tensor(0.3247, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 34\n",
            "tensor(0.3451, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 35\n",
            "tensor(0.3319, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 36\n",
            "tensor(0.3344, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 37\n",
            "tensor(0.3375, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 0\n",
            "tensor(0.3225, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 1\n",
            "tensor(0.3318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 2\n",
            "tensor(0.3273, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 3\n",
            "tensor(0.3475, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 4\n",
            "tensor(0.3235, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 5\n",
            "tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 6\n",
            "tensor(0.3247, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 7\n",
            "tensor(0.3340, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 8\n",
            "tensor(0.3408, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 9\n",
            "tensor(0.3383, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 10\n",
            "tensor(0.3384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 11\n",
            "tensor(0.3246, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 12\n",
            "tensor(0.3430, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 13\n",
            "tensor(0.3620, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 14\n",
            "tensor(0.3364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 15\n",
            "tensor(0.3118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 16\n",
            "tensor(0.3645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 17\n",
            "tensor(0.3532, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 18\n",
            "tensor(0.3401, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 19\n",
            "tensor(0.3288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 20\n",
            "tensor(0.3416, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 21\n",
            "tensor(0.3274, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 22\n",
            "tensor(0.3367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 23\n",
            "tensor(0.3405, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 24\n",
            "tensor(0.3115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 25\n",
            "tensor(0.3226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 26\n",
            "tensor(0.3350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 27\n",
            "tensor(0.3344, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 28\n",
            "tensor(0.3205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 29\n",
            "tensor(0.3382, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 30\n",
            "tensor(0.3578, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 31\n",
            "tensor(0.3592, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 32\n",
            "tensor(0.3451, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 33\n",
            "tensor(0.3301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 34\n",
            "tensor(0.3496, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 35\n",
            "tensor(0.3399, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 36\n",
            "tensor(0.3109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 37\n",
            "tensor(0.3299, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 0\n",
            "tensor(0.2997, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 1\n",
            "tensor(0.3473, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 2\n",
            "tensor(0.3418, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 3\n",
            "tensor(0.3153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 4\n",
            "tensor(0.3260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 5\n",
            "tensor(0.2965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 6\n",
            "tensor(0.3606, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 7\n",
            "tensor(0.3131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 8\n",
            "tensor(0.3511, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 9\n",
            "tensor(0.3425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 10\n",
            "tensor(0.3170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 11\n",
            "tensor(0.3385, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 12\n",
            "tensor(0.3326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 13\n",
            "tensor(0.3163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 14\n",
            "tensor(0.3204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 15\n",
            "tensor(0.3564, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 16\n",
            "tensor(0.3172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 17\n",
            "tensor(0.3132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 18\n",
            "tensor(0.3214, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 19\n",
            "tensor(0.3549, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 20\n",
            "tensor(0.3599, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 21\n",
            "tensor(0.3488, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 22\n",
            "tensor(0.3171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 23\n",
            "tensor(0.3650, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 24\n",
            "tensor(0.3231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 25\n",
            "tensor(0.3330, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 26\n",
            "tensor(0.3265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 27\n",
            "tensor(0.3526, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 28\n",
            "tensor(0.3793, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 29\n",
            "tensor(0.3307, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 30\n",
            "tensor(0.3509, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 31\n",
            "tensor(0.3071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 32\n",
            "tensor(0.3246, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 33\n",
            "tensor(0.3180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 34\n",
            "tensor(0.3475, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 35\n",
            "tensor(0.3494, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 36\n",
            "tensor(0.3355, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 37\n",
            "tensor(0.3212, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 0\n",
            "tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 1\n",
            "tensor(0.3106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 2\n",
            "tensor(0.3194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 3\n",
            "tensor(0.3199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 4\n",
            "tensor(0.3756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 5\n",
            "tensor(0.3329, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 6\n",
            "tensor(0.3377, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 7\n",
            "tensor(0.3158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 8\n",
            "tensor(0.3395, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 9\n",
            "tensor(0.3574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 10\n",
            "tensor(0.3409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 11\n",
            "tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 12\n",
            "tensor(0.3186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 13\n",
            "tensor(0.3595, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 14\n",
            "tensor(0.3299, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 15\n",
            "tensor(0.3319, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 16\n",
            "tensor(0.3226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 17\n",
            "tensor(0.3365, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 18\n",
            "tensor(0.3326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 19\n",
            "tensor(0.3542, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 20\n",
            "tensor(0.3077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 21\n",
            "tensor(0.3435, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 22\n",
            "tensor(0.3168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 23\n",
            "tensor(0.3247, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 24\n",
            "tensor(0.3354, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 25\n",
            "tensor(0.3172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 26\n",
            "tensor(0.2911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 27\n",
            "tensor(0.3672, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 28\n",
            "tensor(0.3484, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 29\n",
            "tensor(0.3551, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 30\n",
            "tensor(0.3117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 31\n",
            "tensor(0.3220, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 32\n",
            "tensor(0.3056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 33\n",
            "tensor(0.3349, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 34\n",
            "tensor(0.3528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 35\n",
            "tensor(0.3114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 36\n",
            "tensor(0.3264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 37\n",
            "tensor(0.3678, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 0\n",
            "tensor(0.3137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 1\n",
            "tensor(0.3329, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 2\n",
            "tensor(0.3161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 3\n",
            "tensor(0.3492, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 4\n",
            "tensor(0.3192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 5\n",
            "tensor(0.3281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 6\n",
            "tensor(0.3283, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 7\n",
            "tensor(0.3074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 8\n",
            "tensor(0.3193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 9\n",
            "tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 10\n",
            "tensor(0.3046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 11\n",
            "tensor(0.3107, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 12\n",
            "tensor(0.3468, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 13\n",
            "tensor(0.3244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 14\n",
            "tensor(0.3412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 15\n",
            "tensor(0.3356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 16\n",
            "tensor(0.3483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 17\n",
            "tensor(0.3255, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 18\n",
            "tensor(0.3177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 19\n",
            "tensor(0.3151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 20\n",
            "tensor(0.3193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 21\n",
            "tensor(0.3427, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 22\n",
            "tensor(0.3531, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 23\n",
            "tensor(0.3310, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 24\n",
            "tensor(0.3544, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 25\n",
            "tensor(0.3397, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 26\n",
            "tensor(0.3359, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 27\n",
            "tensor(0.3357, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 28\n",
            "tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 29\n",
            "tensor(0.3142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 30\n",
            "tensor(0.3273, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 31\n",
            "tensor(0.3421, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 32\n",
            "tensor(0.3416, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 33\n",
            "tensor(0.3103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 34\n",
            "tensor(0.3236, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 35\n",
            "tensor(0.3371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 36\n",
            "tensor(0.3354, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 37\n",
            "tensor(0.3466, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 0\n",
            "tensor(0.3151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 1\n",
            "tensor(0.3174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 2\n",
            "tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 3\n",
            "tensor(0.2991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 4\n",
            "tensor(0.3222, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 5\n",
            "tensor(0.3076, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 6\n",
            "tensor(0.3153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 7\n",
            "tensor(0.3335, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 8\n",
            "tensor(0.3399, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 9\n",
            "tensor(0.3588, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 10\n",
            "tensor(0.3326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 11\n",
            "tensor(0.3293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 12\n",
            "tensor(0.3079, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 13\n",
            "tensor(0.3225, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 14\n",
            "tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 15\n",
            "tensor(0.3267, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 16\n",
            "tensor(0.3135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 17\n",
            "tensor(0.3512, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 18\n",
            "tensor(0.3449, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 19\n",
            "tensor(0.3189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 20\n",
            "tensor(0.3432, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 21\n",
            "tensor(0.3089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 22\n",
            "tensor(0.3342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 23\n",
            "tensor(0.3332, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 24\n",
            "tensor(0.3439, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 25\n",
            "tensor(0.3258, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 26\n",
            "tensor(0.3504, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 27\n",
            "tensor(0.3314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 28\n",
            "tensor(0.3331, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 29\n",
            "tensor(0.2915, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 30\n",
            "tensor(0.3175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 31\n",
            "tensor(0.3451, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 32\n",
            "tensor(0.3206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 33\n",
            "tensor(0.3492, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 34\n",
            "tensor(0.3495, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 35\n",
            "tensor(0.3266, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 36\n",
            "tensor(0.3222, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 37\n",
            "tensor(0.3286, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 0\n",
            "tensor(0.3060, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 1\n",
            "tensor(0.3654, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 2\n",
            "tensor(0.3216, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 3\n",
            "tensor(0.2861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 4\n",
            "tensor(0.3042, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 5\n",
            "tensor(0.3123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 6\n",
            "tensor(0.3276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 7\n",
            "tensor(0.3502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 8\n",
            "tensor(0.3397, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 9\n",
            "tensor(0.3162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 10\n",
            "tensor(0.2931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 11\n",
            "tensor(0.3188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 12\n",
            "tensor(0.3106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 13\n",
            "tensor(0.3233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 14\n",
            "tensor(0.3250, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 15\n",
            "tensor(0.3116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 16\n",
            "tensor(0.3318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 17\n",
            "tensor(0.3476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 18\n",
            "tensor(0.2902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 19\n",
            "tensor(0.3108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 20\n",
            "tensor(0.3434, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 21\n",
            "tensor(0.3241, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 22\n",
            "tensor(0.3307, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 23\n",
            "tensor(0.3135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 24\n",
            "tensor(0.3308, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 25\n",
            "tensor(0.3202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 26\n",
            "tensor(0.3714, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 27\n",
            "tensor(0.3293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 28\n",
            "tensor(0.3223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 29\n",
            "tensor(0.3454, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 30\n",
            "tensor(0.3656, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 31\n",
            "tensor(0.3211, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 32\n",
            "tensor(0.3114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 33\n",
            "tensor(0.3572, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 34\n",
            "tensor(0.3458, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 35\n",
            "tensor(0.3141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 36\n",
            "tensor(0.3169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 37\n",
            "tensor(0.3182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 0\n",
            "tensor(0.3180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 1\n",
            "tensor(0.3380, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 2\n",
            "tensor(0.3362, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 3\n",
            "tensor(0.3227, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 4\n",
            "tensor(0.3335, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 5\n",
            "tensor(0.3471, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 6\n",
            "tensor(0.3137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 7\n",
            "tensor(0.3155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 8\n",
            "tensor(0.2992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 9\n",
            "tensor(0.3538, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 10\n",
            "tensor(0.2907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 11\n",
            "tensor(0.3323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 12\n",
            "tensor(0.3218, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 13\n",
            "tensor(0.3290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 14\n",
            "tensor(0.3297, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 15\n",
            "tensor(0.3081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 16\n",
            "tensor(0.3046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 17\n",
            "tensor(0.3166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 18\n",
            "tensor(0.3457, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 19\n",
            "tensor(0.3349, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 20\n",
            "tensor(0.3209, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 21\n",
            "tensor(0.3194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 22\n",
            "tensor(0.3420, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 23\n",
            "tensor(0.3528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 24\n",
            "tensor(0.3521, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 25\n",
            "tensor(0.3137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 26\n",
            "tensor(0.3199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 27\n",
            "tensor(0.3328, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 28\n",
            "tensor(0.3376, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 29\n",
            "tensor(0.3396, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 30\n",
            "tensor(0.2981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 31\n",
            "tensor(0.3185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 32\n",
            "tensor(0.3109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 33\n",
            "tensor(0.3122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 34\n",
            "tensor(0.3423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 35\n",
            "tensor(0.3222, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 36\n",
            "tensor(0.3289, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 37\n",
            "tensor(0.2902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 0\n",
            "tensor(0.2937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 1\n",
            "tensor(0.3293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 2\n",
            "tensor(0.3139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 3\n",
            "tensor(0.3225, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 4\n",
            "tensor(0.3081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 5\n",
            "tensor(0.3109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 6\n",
            "tensor(0.3156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 7\n",
            "tensor(0.2939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 8\n",
            "tensor(0.3421, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 9\n",
            "tensor(0.3288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 10\n",
            "tensor(0.3304, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 11\n",
            "tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 12\n",
            "tensor(0.3160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 13\n",
            "tensor(0.3280, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 14\n",
            "tensor(0.3352, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 15\n",
            "tensor(0.3301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 16\n",
            "tensor(0.3083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 17\n",
            "tensor(0.3104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 18\n",
            "tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 19\n",
            "tensor(0.3269, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 20\n",
            "tensor(0.3491, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 21\n",
            "tensor(0.3213, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 22\n",
            "tensor(0.3167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 23\n",
            "tensor(0.3340, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 24\n",
            "tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 25\n",
            "tensor(0.3465, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 26\n",
            "tensor(0.3137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 27\n",
            "tensor(0.3228, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 28\n",
            "tensor(0.2895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 29\n",
            "tensor(0.3087, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 30\n",
            "tensor(0.3284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 31\n",
            "tensor(0.3495, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 32\n",
            "tensor(0.3377, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 33\n",
            "tensor(0.3050, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 34\n",
            "tensor(0.3490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 35\n",
            "tensor(0.3301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 36\n",
            "tensor(0.3115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 37\n",
            "tensor(0.3457, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 0\n",
            "tensor(0.3048, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 1\n",
            "tensor(0.3408, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 2\n",
            "tensor(0.3123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 3\n",
            "tensor(0.3052, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 4\n",
            "tensor(0.3588, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 5\n",
            "tensor(0.3090, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 6\n",
            "tensor(0.3084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 7\n",
            "tensor(0.3200, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 8\n",
            "tensor(0.3155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 9\n",
            "tensor(0.3256, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 10\n",
            "tensor(0.3314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 11\n",
            "tensor(0.3175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 12\n",
            "tensor(0.3128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 13\n",
            "tensor(0.3058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 14\n",
            "tensor(0.3197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 15\n",
            "tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 16\n",
            "tensor(0.3367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 17\n",
            "tensor(0.3356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 18\n",
            "tensor(0.3167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 19\n",
            "tensor(0.3324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 20\n",
            "tensor(0.3327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 21\n",
            "tensor(0.3128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 22\n",
            "tensor(0.2968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 23\n",
            "tensor(0.2964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 24\n",
            "tensor(0.3406, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 25\n",
            "tensor(0.3355, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 26\n",
            "tensor(0.3221, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 27\n",
            "tensor(0.3315, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 28\n",
            "tensor(0.3158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 29\n",
            "tensor(0.3406, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 30\n",
            "tensor(0.2995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 31\n",
            "tensor(0.3254, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 32\n",
            "tensor(0.3264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 33\n",
            "tensor(0.3217, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 34\n",
            "tensor(0.3421, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 35\n",
            "tensor(0.3253, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 36\n",
            "tensor(0.3065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 37\n",
            "tensor(0.3250, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 0\n",
            "tensor(0.3153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 1\n",
            "tensor(0.2959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 2\n",
            "tensor(0.3161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 3\n",
            "tensor(0.3344, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 4\n",
            "tensor(0.3088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 5\n",
            "tensor(0.3084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 6\n",
            "tensor(0.3102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 7\n",
            "tensor(0.2956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 8\n",
            "tensor(0.3412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 9\n",
            "tensor(0.3494, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 10\n",
            "tensor(0.3415, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 11\n",
            "tensor(0.3174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 12\n",
            "tensor(0.3267, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 13\n",
            "tensor(0.3343, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 14\n",
            "tensor(0.3415, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 15\n",
            "tensor(0.3131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 16\n",
            "tensor(0.3409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 17\n",
            "tensor(0.3318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 18\n",
            "tensor(0.3227, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 19\n",
            "tensor(0.3276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 20\n",
            "tensor(0.3393, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 21\n",
            "tensor(0.3086, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 22\n",
            "tensor(0.3118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 23\n",
            "tensor(0.3044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 24\n",
            "tensor(0.3116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 25\n",
            "tensor(0.3086, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 26\n",
            "tensor(0.3276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 27\n",
            "tensor(0.3490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 28\n",
            "tensor(0.3243, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 29\n",
            "tensor(0.3102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 30\n",
            "tensor(0.3279, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 31\n",
            "tensor(0.3195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 32\n",
            "tensor(0.3304, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 33\n",
            "tensor(0.3218, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 34\n",
            "tensor(0.3048, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 35\n",
            "tensor(0.3195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 36\n",
            "tensor(0.3073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 37\n",
            "tensor(0.2818, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 0\n",
            "tensor(-67.8110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 1\n",
            "tensor(-68.0732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 2\n",
            "tensor(-67.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 3\n",
            "tensor(-68.0044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 4\n",
            "tensor(-67.9006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 5\n",
            "tensor(-68.1512, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 6\n",
            "tensor(-68.0652, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 7\n",
            "tensor(-67.8427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 8\n",
            "tensor(-67.9488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 9\n",
            "tensor(-67.9620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 10\n",
            "tensor(-68.0615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 11\n",
            "tensor(-68.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 12\n",
            "tensor(-67.9120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 13\n",
            "tensor(-67.6837, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 14\n",
            "tensor(-68.1143, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 15\n",
            "tensor(-68.1814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 16\n",
            "tensor(-68.2052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 17\n",
            "tensor(-67.9193, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 18\n",
            "tensor(-68.1300, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 19\n",
            "tensor(-68.1062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 20\n",
            "tensor(-67.8402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 21\n",
            "tensor(-67.9820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 22\n",
            "tensor(-68.0680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 23\n",
            "tensor(-67.9749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 24\n",
            "tensor(-67.8885, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 25\n",
            "tensor(-68.1089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 26\n",
            "tensor(-68.0982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 27\n",
            "tensor(-67.8515, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 28\n",
            "tensor(-68.1178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 29\n",
            "tensor(-68.0540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 30\n",
            "tensor(-67.9109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 31\n",
            "tensor(-67.9676, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 32\n",
            "tensor(-67.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 33\n",
            "tensor(-67.9176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 34\n",
            "tensor(-67.9786, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 35\n",
            "tensor(-67.8669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 36\n",
            "tensor(-67.9979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  20 Batch: 37\n",
            "tensor(-67.8735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 0\n",
            "tensor(-68.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 1\n",
            "tensor(-67.7610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 2\n",
            "tensor(-67.7665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 3\n",
            "tensor(-68.1311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 4\n",
            "tensor(-67.9281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 5\n",
            "tensor(-67.9674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 6\n",
            "tensor(-68.0584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 7\n",
            "tensor(-67.9331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 8\n",
            "tensor(-68.0888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 9\n",
            "tensor(-67.8520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 10\n",
            "tensor(-67.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 11\n",
            "tensor(-68.1371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 12\n",
            "tensor(-67.9046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 13\n",
            "tensor(-67.9605, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 14\n",
            "tensor(-68.0954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 15\n",
            "tensor(-68.1749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 16\n",
            "tensor(-68.2538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 17\n",
            "tensor(-68.0845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 18\n",
            "tensor(-68.0663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 19\n",
            "tensor(-67.8905, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 20\n",
            "tensor(-67.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 21\n",
            "tensor(-68.0669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 22\n",
            "tensor(-67.9385, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 23\n",
            "tensor(-67.9869, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 24\n",
            "tensor(-68.0407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 25\n",
            "tensor(-67.8852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 26\n",
            "tensor(-67.9995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 27\n",
            "tensor(-68.0709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 28\n",
            "tensor(-67.8622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 29\n",
            "tensor(-67.8859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 30\n",
            "tensor(-67.9431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 31\n",
            "tensor(-67.9334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 32\n",
            "tensor(-68.0308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 33\n",
            "tensor(-68.0648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 34\n",
            "tensor(-67.9860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 35\n",
            "tensor(-67.8962, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 36\n",
            "tensor(-67.9233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  21 Batch: 37\n",
            "tensor(-68.0264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 0\n",
            "tensor(-67.8050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 1\n",
            "tensor(-68.0270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 2\n",
            "tensor(-67.9706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 3\n",
            "tensor(-67.8330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 4\n",
            "tensor(-68.0128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 5\n",
            "tensor(-67.8357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 6\n",
            "tensor(-67.8716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 7\n",
            "tensor(-67.8303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 8\n",
            "tensor(-68.0085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 9\n",
            "tensor(-67.9209, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 10\n",
            "tensor(-68.0860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 11\n",
            "tensor(-68.0472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 12\n",
            "tensor(-67.8684, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 13\n",
            "tensor(-68.1085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 14\n",
            "tensor(-67.9735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 15\n",
            "tensor(-68.1802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 16\n",
            "tensor(-68.0210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 17\n",
            "tensor(-68.0080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 18\n",
            "tensor(-67.7057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 19\n",
            "tensor(-67.9808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 20\n",
            "tensor(-68.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 21\n",
            "tensor(-67.8807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 22\n",
            "tensor(-68.0326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 23\n",
            "tensor(-68.0390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 24\n",
            "tensor(-68.0051, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 25\n",
            "tensor(-68.0713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 26\n",
            "tensor(-68.1014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 27\n",
            "tensor(-68.0500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 28\n",
            "tensor(-67.9826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 29\n",
            "tensor(-68.0935, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 30\n",
            "tensor(-67.9291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 31\n",
            "tensor(-68.0699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 32\n",
            "tensor(-68.2696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 33\n",
            "tensor(-68.0927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 34\n",
            "tensor(-67.9975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 35\n",
            "tensor(-67.9869, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 36\n",
            "tensor(-68.0127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  22 Batch: 37\n",
            "tensor(-67.8860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 0\n",
            "tensor(-68.0285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 1\n",
            "tensor(-67.8928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 2\n",
            "tensor(-68.1770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 3\n",
            "tensor(-67.9719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 4\n",
            "tensor(-68.0486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 5\n",
            "tensor(-67.9763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 6\n",
            "tensor(-67.9155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 7\n",
            "tensor(-67.8989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 8\n",
            "tensor(-68.0673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 9\n",
            "tensor(-67.9205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 10\n",
            "tensor(-68.1846, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 11\n",
            "tensor(-67.9408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 12\n",
            "tensor(-67.9652, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 13\n",
            "tensor(-68.0735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 14\n",
            "tensor(-67.9001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 15\n",
            "tensor(-67.9471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 16\n",
            "tensor(-68.0403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 17\n",
            "tensor(-67.8897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 18\n",
            "tensor(-68.0549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 19\n",
            "tensor(-67.9098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 20\n",
            "tensor(-67.8606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 21\n",
            "tensor(-68.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 22\n",
            "tensor(-68.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 23\n",
            "tensor(-67.9994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 24\n",
            "tensor(-67.9712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 25\n",
            "tensor(-68.0467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 26\n",
            "tensor(-67.9840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 27\n",
            "tensor(-67.9135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 28\n",
            "tensor(-67.8927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 29\n",
            "tensor(-67.9580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 30\n",
            "tensor(-67.9759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 31\n",
            "tensor(-68.1591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 32\n",
            "tensor(-68.2085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 33\n",
            "tensor(-68.0678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 34\n",
            "tensor(-68.0398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 35\n",
            "tensor(-67.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 36\n",
            "tensor(-67.9714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  23 Batch: 37\n",
            "tensor(-67.8684, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 0\n",
            "tensor(-67.9139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 1\n",
            "tensor(-68.0125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 2\n",
            "tensor(-67.9401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 3\n",
            "tensor(-67.9937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 4\n",
            "tensor(-68.0559, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 5\n",
            "tensor(-68.0436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 6\n",
            "tensor(-67.8588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 7\n",
            "tensor(-68.0749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 8\n",
            "tensor(-67.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 9\n",
            "tensor(-68.0597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 10\n",
            "tensor(-67.9483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 11\n",
            "tensor(-68.0389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 12\n",
            "tensor(-68.0226, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 13\n",
            "tensor(-68.1128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 14\n",
            "tensor(-67.9911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 15\n",
            "tensor(-68.0335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 16\n",
            "tensor(-68.0899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 17\n",
            "tensor(-68.0341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 18\n",
            "tensor(-67.9888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 19\n",
            "tensor(-67.9689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 20\n",
            "tensor(-67.9400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 21\n",
            "tensor(-67.8239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 22\n",
            "tensor(-68.1432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 23\n",
            "tensor(-68.1252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 24\n",
            "tensor(-67.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 25\n",
            "tensor(-67.9628, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 26\n",
            "tensor(-68.0288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 27\n",
            "tensor(-67.9867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 28\n",
            "tensor(-68.0175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 29\n",
            "tensor(-67.9836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 30\n",
            "tensor(-68.0783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 31\n",
            "tensor(-67.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 32\n",
            "tensor(-67.7831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 33\n",
            "tensor(-68.0882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 34\n",
            "tensor(-67.9592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 35\n",
            "tensor(-68.0260, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 36\n",
            "tensor(-67.9583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  24 Batch: 37\n",
            "tensor(-67.9919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 0\n",
            "tensor(-68.0660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 1\n",
            "tensor(-67.9360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 2\n",
            "tensor(-67.9878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 3\n",
            "tensor(-68.1106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 4\n",
            "tensor(-68.2411, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 5\n",
            "tensor(-67.9634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 6\n",
            "tensor(-67.8681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 7\n",
            "tensor(-67.9189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 8\n",
            "tensor(-67.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 9\n",
            "tensor(-67.9913, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 10\n",
            "tensor(-68.1671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 11\n",
            "tensor(-68.0541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 12\n",
            "tensor(-67.9610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 13\n",
            "tensor(-67.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 14\n",
            "tensor(-68.0281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 15\n",
            "tensor(-68.1795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 16\n",
            "tensor(-67.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 17\n",
            "tensor(-67.9397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 18\n",
            "tensor(-67.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 19\n",
            "tensor(-67.9040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 20\n",
            "tensor(-68.2223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 21\n",
            "tensor(-68.0921, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 22\n",
            "tensor(-67.9181, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 23\n",
            "tensor(-67.8903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 24\n",
            "tensor(-67.8397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 25\n",
            "tensor(-67.9938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 26\n",
            "tensor(-67.8876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 27\n",
            "tensor(-67.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 28\n",
            "tensor(-68.0042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 29\n",
            "tensor(-68.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 30\n",
            "tensor(-68.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 31\n",
            "tensor(-68.0844, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 32\n",
            "tensor(-67.9505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 33\n",
            "tensor(-67.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 34\n",
            "tensor(-68.0287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 35\n",
            "tensor(-67.9405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 36\n",
            "tensor(-68.2042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  25 Batch: 37\n",
            "tensor(-67.9632, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 0\n",
            "tensor(-68.0222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 1\n",
            "tensor(-68.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 2\n",
            "tensor(-67.9517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 3\n",
            "tensor(-67.8360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 4\n",
            "tensor(-67.7915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 5\n",
            "tensor(-68.1852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 6\n",
            "tensor(-67.9058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 7\n",
            "tensor(-68.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 8\n",
            "tensor(-68.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 9\n",
            "tensor(-67.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 10\n",
            "tensor(-67.9312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 11\n",
            "tensor(-68.0787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 12\n",
            "tensor(-67.8855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 13\n",
            "tensor(-68.0642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 14\n",
            "tensor(-67.8521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 15\n",
            "tensor(-67.9399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 16\n",
            "tensor(-67.9789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 17\n",
            "tensor(-68.1168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 18\n",
            "tensor(-68.1476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 19\n",
            "tensor(-68.0483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 20\n",
            "tensor(-68.0511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 21\n",
            "tensor(-68.1957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 22\n",
            "tensor(-67.8661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 23\n",
            "tensor(-67.9237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 24\n",
            "tensor(-68.1671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 25\n",
            "tensor(-68.0046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 26\n",
            "tensor(-67.8308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 27\n",
            "tensor(-67.9665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 28\n",
            "tensor(-68.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 29\n",
            "tensor(-67.9259, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 30\n",
            "tensor(-68.0561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 31\n",
            "tensor(-67.8699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 32\n",
            "tensor(-68.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 33\n",
            "tensor(-67.9025, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 34\n",
            "tensor(-68.0768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 35\n",
            "tensor(-68.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 36\n",
            "tensor(-67.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  26 Batch: 37\n",
            "tensor(-67.8693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 0\n",
            "tensor(-68.0340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 1\n",
            "tensor(-68.0206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 2\n",
            "tensor(-68.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 3\n",
            "tensor(-68.0592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 4\n",
            "tensor(-67.8939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 5\n",
            "tensor(-68.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 6\n",
            "tensor(-68.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 7\n",
            "tensor(-67.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 8\n",
            "tensor(-67.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 9\n",
            "tensor(-67.9170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 10\n",
            "tensor(-67.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 11\n",
            "tensor(-67.9091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 12\n",
            "tensor(-68.1288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 13\n",
            "tensor(-67.8277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 14\n",
            "tensor(-68.1433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 15\n",
            "tensor(-68.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 16\n",
            "tensor(-68.0382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 17\n",
            "tensor(-67.9990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 18\n",
            "tensor(-68.0855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 19\n",
            "tensor(-67.8756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 20\n",
            "tensor(-67.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 21\n",
            "tensor(-68.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 22\n",
            "tensor(-67.8557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 23\n",
            "tensor(-67.9106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 24\n",
            "tensor(-68.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 25\n",
            "tensor(-67.9472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 26\n",
            "tensor(-68.0119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 27\n",
            "tensor(-67.8820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 28\n",
            "tensor(-68.1352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 29\n",
            "tensor(-68.0964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 30\n",
            "tensor(-67.7647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 31\n",
            "tensor(-68.1764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 32\n",
            "tensor(-68.0522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 33\n",
            "tensor(-68.1154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 34\n",
            "tensor(-67.9994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 35\n",
            "tensor(-67.9497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 36\n",
            "tensor(-67.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  27 Batch: 37\n",
            "tensor(-67.9035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 0\n",
            "tensor(-67.7323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 1\n",
            "tensor(-67.8393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 2\n",
            "tensor(-67.8391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 3\n",
            "tensor(-67.9580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 4\n",
            "tensor(-68.0986, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 5\n",
            "tensor(-68.1466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 6\n",
            "tensor(-67.9870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 7\n",
            "tensor(-67.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 8\n",
            "tensor(-68.2024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 9\n",
            "tensor(-68.0953, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 10\n",
            "tensor(-68.0511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 11\n",
            "tensor(-68.0231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 12\n",
            "tensor(-67.9942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 13\n",
            "tensor(-67.9657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 14\n",
            "tensor(-68.0316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 15\n",
            "tensor(-68.2001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 16\n",
            "tensor(-67.9793, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 17\n",
            "tensor(-67.9075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 18\n",
            "tensor(-67.8271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 19\n",
            "tensor(-67.8970, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 20\n",
            "tensor(-67.8669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 21\n",
            "tensor(-67.9604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 22\n",
            "tensor(-68.0597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 23\n",
            "tensor(-67.9221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 24\n",
            "tensor(-68.1202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 25\n",
            "tensor(-67.9801, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 26\n",
            "tensor(-67.9655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 27\n",
            "tensor(-68.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 28\n",
            "tensor(-68.1551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 29\n",
            "tensor(-67.9120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 30\n",
            "tensor(-68.0966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 31\n",
            "tensor(-68.0616, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 32\n",
            "tensor(-68.0716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 33\n",
            "tensor(-67.9809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 34\n",
            "tensor(-67.9969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 35\n",
            "tensor(-67.9657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 36\n",
            "tensor(-67.9725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  28 Batch: 37\n",
            "tensor(-67.9783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 0\n",
            "tensor(-68.0710, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 1\n",
            "tensor(-67.8735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 2\n",
            "tensor(-68.0454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 3\n",
            "tensor(-67.9376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 4\n",
            "tensor(-67.7799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 5\n",
            "tensor(-68.2027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 6\n",
            "tensor(-67.9527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 7\n",
            "tensor(-67.9025, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 8\n",
            "tensor(-67.8286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 9\n",
            "tensor(-68.0909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 10\n",
            "tensor(-67.8849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 11\n",
            "tensor(-68.2052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 12\n",
            "tensor(-68.1003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 13\n",
            "tensor(-67.9503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 14\n",
            "tensor(-67.8793, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 15\n",
            "tensor(-67.8794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 16\n",
            "tensor(-68.0693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 17\n",
            "tensor(-68.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 18\n",
            "tensor(-67.9421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 19\n",
            "tensor(-68.0513, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 20\n",
            "tensor(-67.9841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 21\n",
            "tensor(-67.9842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 22\n",
            "tensor(-67.9612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 23\n",
            "tensor(-68.1297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 24\n",
            "tensor(-67.9287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 25\n",
            "tensor(-68.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 26\n",
            "tensor(-67.9738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 27\n",
            "tensor(-68.0520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 28\n",
            "tensor(-68.0839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 29\n",
            "tensor(-68.1358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 30\n",
            "tensor(-67.9282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 31\n",
            "tensor(-67.8437, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 32\n",
            "tensor(-67.8332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 33\n",
            "tensor(-67.9583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 34\n",
            "tensor(-68.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 35\n",
            "tensor(-68.1811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 36\n",
            "tensor(-68.0630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  29 Batch: 37\n",
            "tensor(-68.1124, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 0\n",
            "tensor(-67.8541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 1\n",
            "tensor(-68.1215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 2\n",
            "tensor(-68.0249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 3\n",
            "tensor(-68.0066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 4\n",
            "tensor(-67.9496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 5\n",
            "tensor(-68.0847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 6\n",
            "tensor(-67.9524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 7\n",
            "tensor(-68.1212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 8\n",
            "tensor(-68.0308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 9\n",
            "tensor(-68.0877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 10\n",
            "tensor(-67.9202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 11\n",
            "tensor(-68.1571, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 12\n",
            "tensor(-67.8464, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 13\n",
            "tensor(-68.0535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 14\n",
            "tensor(-67.9407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 15\n",
            "tensor(-68.0106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 16\n",
            "tensor(-68.1029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 17\n",
            "tensor(-67.9936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 18\n",
            "tensor(-67.9272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 19\n",
            "tensor(-68.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 20\n",
            "tensor(-68.1215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 21\n",
            "tensor(-67.8689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 22\n",
            "tensor(-68.1325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 23\n",
            "tensor(-68.0412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 24\n",
            "tensor(-68.0087, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 25\n",
            "tensor(-67.8428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 26\n",
            "tensor(-68.1461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 27\n",
            "tensor(-68.0490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 28\n",
            "tensor(-68.0534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 29\n",
            "tensor(-67.8654, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 30\n",
            "tensor(-67.9627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 31\n",
            "tensor(-67.9826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 32\n",
            "tensor(-67.9819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 33\n",
            "tensor(-67.8643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 34\n",
            "tensor(-67.9633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 35\n",
            "tensor(-68.0321, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 36\n",
            "tensor(-67.8924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  30 Batch: 37\n",
            "tensor(-67.9451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  31 Batch: 0\n",
            "tensor(-68.1421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  31 Batch: 1\n",
            "tensor(-67.9641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  31 Batch: 2\n",
            "tensor(-68.0379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  31 Batch: 3\n",
            "tensor(-68.0812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch:  31 Batch: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ecd378c8106c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0moptimizer_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mSpred_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_NN_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYpred_var0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mlossS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpred_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0moptimizer_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2958\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2960\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXXC70YhR3z7"
      },
      "source": [
        "table = [0,0,0,0,0,0,0,0]\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBuVY_BIVl52"
      },
      "source": [
        "table=pd.read_csv(\"/content/Adult_AdelFairness\", sep=\" \", header=None)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io18J4eHhsBE",
        "outputId": "cc889cb3-2dc3-4c51-be1d-a6485757638d"
      },
      "source": [
        "\n",
        "for k in range(20):\n",
        "    # split into train/test set\n",
        "    X_train, X_test, XNC_train, XNC_test, y_train, y_test, S_train, S_test, G_train, G_test = train_test_split(X, XNC, y, S, G.values, test_size=0.2, random_state=7)\n",
        "\n",
        "    # standardize the data\n",
        "    scaler = MinMaxScaler().fit(X_train)\n",
        "    scale_df = lambda df, scaler: pd.DataFrame(scaler.transform(df), columns=df.columns, index=df.index)\n",
        "\n",
        "    scalerNC = MinMaxScaler().fit(XNC_train)\n",
        "    scale_dfNC = lambda df, scaler: pd.DataFrame(scalerNC.transform(df), columns=df.columns, index=df.index)\n",
        "\n",
        "    X_train, X_test = X_train.pipe(scale_df, scaler), X_test.pipe(scale_df, scaler)\n",
        "    XNC_train, XNC_test = XNC_train.pipe(scale_dfNC, scaler), XNC_test.pipe(scale_dfNC, scalerNC)\n",
        "    X_train, X_test, XNC_train, XNC_test, y_train, y_test = X_train.values, X_test.values, XNC_train.values, XNC_test.values, y_train.values, y_test.values\n",
        "\n",
        "    S_train, S_test =S_train.values, S_test.values  \n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    H = 15\n",
        "    H2 = 15\n",
        "    epochs_hgr=50\n",
        "\n",
        "    batch_size = 512\n",
        "    num_epochs = 25\n",
        "    learning_rate = 0.001\n",
        "    batch_no = len(X_train) // batch_size\n",
        "    #X_train_inv = recon_X_batch_a.data.numpy()\n",
        "    #Y_train_inv = recon_Y_batch_a.data.numpy()\n",
        "\n",
        "    from sklearn.utils import shuffle\n",
        "    from torch.autograd import Variable\n",
        "    criterionMSE = nn.MSELoss()\n",
        "    import math\n",
        "    nb_a=200\n",
        "    from torch.nn import functional as F\n",
        "    def sigmoid(x):\n",
        "      output = [1 / (1 + math.exp(-x)) for x in x]\n",
        "      return output\n",
        "\n",
        "    class NN_b(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN_b, self).__init__()\n",
        "            self.fc1_s = nn.Linear(16, 8)\n",
        "            self.fc2_s = nn.Linear(8, 8)\n",
        "            self.fc3_s = nn.Linear(8, 1)\n",
        "            #self.fc4_s = nn.Linear(16, 1)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.fc1_s(x)\n",
        "            x = torch.relu(x)\n",
        "            x = self.fc2_s(x)\n",
        "            x = torch.relu(x)\n",
        "            x = self.fc3_s(x)\n",
        "            #x = torch.relu(x)\n",
        "            #x = self.fc4_s(x)\n",
        "            return x\n",
        "\n",
        "\n",
        "\n",
        "    class NN_z(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN_z, self).__init__()\n",
        "            self.fc1 = nn.Linear(99, 64)\n",
        "            self.fc2 = nn.Linear(64, 32)\n",
        "            self.fc3 = nn.Linear(32, 16)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.fc1(x)\n",
        "            x = torch.relu(x)\n",
        "            x = self.fc2(x)\n",
        "            x = torch.relu(x)\n",
        "            x = self.fc3(x)\n",
        "            return x\n",
        "\n",
        "\n",
        "    class NN_s(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN_s, self).__init__()\n",
        "            self.fc1_s = nn.Linear(16, 8)\n",
        "            self.fc2_s = nn.Linear(8, 8)\n",
        "            self.fc3_s = nn.Linear(8, 1)\n",
        "            #self.fc4_s = nn.Linear(16, 1)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.fc1_s(x)\n",
        "            x = torch.relu(x)\n",
        "            x = self.fc2_s(x)\n",
        "            x = torch.relu(x)\n",
        "            x = self.fc3_s(x)\n",
        "            #x = torch.relu(x)\n",
        "            #x = self.fc4_s(x)\n",
        "            return x\n",
        "\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    m_NN_s = NN_s().to(device)\n",
        "    optimizer_s = torch.optim.Adam(m_NN_s.parameters(), lr=learning_rate)\n",
        "\n",
        "    m_NN_z = NN_z().to(device)\n",
        "    optimizer_z = torch.optim.Adam(m_NN_z.parameters(), lr=learning_rate)\n",
        "\n",
        "    model_Y_b = NN_b().cuda()\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "    optimizer_Y = torch.optim.Adam(model_Y_b.parameters(), lr=learning_rate)\n",
        "    criterion_ADV =  nn.MSELoss()\n",
        "    #A0 = sensitive.mean() + sensitive.std()*Variable(torch.randn(data.shape[0]*nb_a, 1),requires_grad=False)\n",
        "    #recon_X_batch_a0, z_a0, recon_Y_batch_a0, mu_a0, logvar_a0 = model(data.repeat(nb_a,1).view(-1, 33),A0)\n",
        "    #recon_x, recon_xNC, S, U,  recon_y, mu, logvar = model(x_var, x_varNC, y_var,s_var)\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    X_trainCUDA = Variable(torch.FloatTensor(X_train)).cuda()\n",
        "    XNC_trainCUDA = Variable(torch.FloatTensor(XNC_train)).cuda()\n",
        "    y_trainCUDA = Variable(torch.FloatTensor(np.expand_dims(y_train,axis = 1))).cuda()\n",
        "\n",
        "    X_testCUDA = Variable(torch.FloatTensor(X_test)).cuda()\n",
        "    XNC_testCUDA = Variable(torch.FloatTensor(XNC_test)).cuda()\n",
        "    y_testCUDA = Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).cuda()\n",
        "\n",
        "\n",
        "    G_trainCUDA = Variable(torch.FloatTensor(G_train)).cuda()\n",
        "    G_testCUDA =  Variable(torch.FloatTensor(G_test)).cuda()\n",
        "    for epoch in range(num_epochs):\n",
        "        lambda_ADV =k+18\n",
        "        #if epoch % 50 != 0:\n",
        "            #x_train = Variable(torch.FloatTensor(X_train.values),requires_grad=True)\n",
        "            #x_test = Variable(torch.FloatTensor(X_test.values),requires_grad=True)\n",
        "            #print('Epoch {}'.format(epoch+1))\n",
        "            \n",
        "            #y_predX= model(x_train).data.numpy().T\n",
        "            #y_predXinv= model(recon_X_batch_a0).data.numpy().T\n",
        "\n",
        "            #accuracy = (y_train-np.squeeze(y_predX)).pow(2).sum()     \n",
        "            #accuracycount = accuracy_score(Y_train_inv.squeeze(1), np.squeeze(y_predXinv))\n",
        "            #print (\"Train Accuracy:\", accuracy)#,\"Train Accuracy Count:\", accuracycount, \"CLP:\", np.mean(logit_y_predX-logit_y_predXinv)**2)\n",
        "        x_train, x_trainNC, ytrain, sens_train, gtrain = shuffle(X_train, XNC_train, np.expand_dims(y_train,axis = 1),  S_train, G_train)\n",
        "\n",
        "        #A = s_var.mean() + s_var.std()*Variable(torch.randn(batch_size*nb_a, 1),requires_grad=False)\n",
        "        # Mini batch learning\n",
        "        for i in range(batch_no):\n",
        "            print('Epoch: ', epoch, 'Batch:',i)\n",
        "            start = i * batch_size\n",
        "            end = start + batch_size\n",
        "\n",
        "            x_var = Variable(torch.FloatTensor(x_train[start:end])).cuda()\n",
        "            xNC_var = Variable(torch.FloatTensor(x_trainNC[start:end])).cuda()\n",
        "            y_var = Variable(torch.FloatTensor(ytrain[start:end])).cuda()\n",
        "            s_var = Variable(torch.FloatTensor(sens_train[start:end])).cuda()\n",
        "            # Forward + Backward + Optimize\n",
        "            Ypred_var0 = model_Y_b(torch.cat([xNC_var.view(-1, 43),x_var.view(-1, x_var.shape[1])],1)).detach()\n",
        "\n",
        "\n",
        "            Z0 = m_NN_z(torch.cat([xNC_var.view(-1, 43),x_var.view(-1, x_var.shape[1])],1)).detach()\n",
        "\n",
        "            for e in range(10):\n",
        "                optimizer_Y.zero_grad()\n",
        "                Ypred_var = model_Y_b(Z0)\n",
        "                lossY = criterion(Ypred_var, y_var)\n",
        "                lossY.backward()\n",
        "                optimizer_Y.step()\n",
        "\n",
        "            if epoch >= 10 :\n",
        "                if (epoch ==50) & (i<=3):\n",
        "                    for l in range(200):\n",
        "                        optimizer_s.zero_grad()\n",
        "                        Spred_var = m_NN_s(Z0)\n",
        "                        lossS = criterion(Spred_var, s_var)\n",
        "                        lossS.backward()\n",
        "                        optimizer_s.step()\n",
        "                for l in range(20):\n",
        "                    optimizer_s.zero_grad()\n",
        "                    Spred_var = m_NN_s(Z0)\n",
        "                    lossS = criterion(Spred_var, s_var)\n",
        "                    lossS.backward()\n",
        "                    optimizer_s.step()\n",
        "\n",
        "            optimizer_z.zero_grad()\n",
        "            Ypred_var = model_Y_b(m_NN_z(torch.cat([xNC_var.view(-1, 43),x_var.view(-1, x_var.shape[1])],1)))\n",
        "            Spred_var = m_NN_s(m_NN_z(torch.cat([xNC_var.view(-1, 43),x_var.view(-1, x_var.shape[1])],1)))\n",
        "            lossS = criterion(Spred_var, s_var)\n",
        "            lossY = criterion(Ypred_var, y_var)\n",
        "            loss =  lossY\n",
        "            if epoch >= 10:\n",
        "                loss =  - lambda_ADV * lossS + lossY\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer_z.step()\n",
        "            print('Loss: ', loss, 'lossS:',lossS, 'lossY:',lossY)\n",
        "            #if epoch % 10 == 0:\n",
        "\n",
        "    Ypred = torch.sigmoid(model_Y_b(m_NN_z(torch.cat([XNC_trainCUDA.view(-1, 43),X_trainCUDA.view(-1, X_trainCUDA.shape[1])],1))))>0.5\n",
        "    Ho = (S_train==1)\n",
        "    Fe = (S_train==0)\n",
        "    odds=Ypred.float()[Ho].mean()/ Ypred.float()[Fe].mean()\n",
        "    PRULE= min(odds, 1/odds)\n",
        "\n",
        "    Ypredtest = torch.sigmoid(model_Y_b(m_NN_z(torch.cat([XNC_testCUDA.view(-1, 43),X_testCUDA.view(-1, X_testCUDA.shape[1] )],1))))>0.5\n",
        "    Ho = (S_test==1)\n",
        "    Fe = (S_test==0)\n",
        "    odds=Ypredtest.float()[Ho].mean()/ Ypredtest.float()[Fe].mean()\n",
        "    PRULEtest= min(odds, 1/odds)\n",
        "\n",
        "    print('ACC Train',(Ypred==y_trainCUDA).sum()/X_train.shape[0], 'PRULE',PRULE, 'ACC Test',(Ypredtest==y_testCUDA).sum()/X_test.shape[0],'PRULEtest',PRULEtest)\n",
        "    table = np.vstack([table,[num_epochs, lambda_ADV, (Ypred.cpu().data.numpy()==y_trainCUDA.cpu().data.numpy()).sum()/X_train.shape[0]*100,PRULE.cpu().data.numpy(),lossS.cpu().data.numpy(), \n",
        "                            (Ypredtest.cpu().data.numpy()==y_testCUDA.cpu().data.numpy()).sum()/X_test.shape[0]*100,PRULEtest.cpu().data.numpy(),lossS.cpu().data.numpy()]])\n",
        "    np.savetxt('/content/drive/MyDrive/Withoutdemo2/Adult_AdelFairness', table[1:,])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Epoch:  3 Batch: 66\n",
            "Loss:  tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7227, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 67\n",
            "Loss:  tensor(0.2934, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2934, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 68\n",
            "Loss:  tensor(0.3296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 69\n",
            "Loss:  tensor(0.3066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 70\n",
            "Loss:  tensor(0.3058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 71\n",
            "Loss:  tensor(0.3558, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3558, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 72\n",
            "Loss:  tensor(0.3112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 73\n",
            "Loss:  tensor(0.3469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 74\n",
            "Loss:  tensor(0.3528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 75\n",
            "Loss:  tensor(0.3612, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3612, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 0\n",
            "Loss:  tensor(0.3065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 1\n",
            "Loss:  tensor(0.3356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 2\n",
            "Loss:  tensor(0.3249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 3\n",
            "Loss:  tensor(0.3032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 4\n",
            "Loss:  tensor(0.2922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 5\n",
            "Loss:  tensor(0.3244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 6\n",
            "Loss:  tensor(0.3483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 7\n",
            "Loss:  tensor(0.3038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 8\n",
            "Loss:  tensor(0.3389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 9\n",
            "Loss:  tensor(0.2907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 10\n",
            "Loss:  tensor(0.3551, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3551, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 11\n",
            "Loss:  tensor(0.3059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 12\n",
            "Loss:  tensor(0.3156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 13\n",
            "Loss:  tensor(0.3328, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3328, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 14\n",
            "Loss:  tensor(0.3339, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3339, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 15\n",
            "Loss:  tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 16\n",
            "Loss:  tensor(0.3549, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3549, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 17\n",
            "Loss:  tensor(0.3223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 18\n",
            "Loss:  tensor(0.3278, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3278, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 19\n",
            "Loss:  tensor(0.3254, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3254, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 20\n",
            "Loss:  tensor(0.2927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 21\n",
            "Loss:  tensor(0.2662, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2662, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 22\n",
            "Loss:  tensor(0.3418, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3418, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 23\n",
            "Loss:  tensor(0.2658, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2658, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 24\n",
            "Loss:  tensor(0.2956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7221, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 25\n",
            "Loss:  tensor(0.3486, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3486, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 26\n",
            "Loss:  tensor(0.3467, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3467, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 27\n",
            "Loss:  tensor(0.2613, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2613, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 28\n",
            "Loss:  tensor(0.3015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 29\n",
            "Loss:  tensor(0.2856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 30\n",
            "Loss:  tensor(0.2992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 31\n",
            "Loss:  tensor(0.3244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 32\n",
            "Loss:  tensor(0.2686, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2686, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 33\n",
            "Loss:  tensor(0.2489, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2489, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 34\n",
            "Loss:  tensor(0.3437, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3437, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 35\n",
            "Loss:  tensor(0.3145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 36\n",
            "Loss:  tensor(0.3409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 37\n",
            "Loss:  tensor(0.3061, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3061, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 38\n",
            "Loss:  tensor(0.2965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 39\n",
            "Loss:  tensor(0.2996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 40\n",
            "Loss:  tensor(0.3281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 41\n",
            "Loss:  tensor(0.2983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 42\n",
            "Loss:  tensor(0.3374, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3374, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 43\n",
            "Loss:  tensor(0.3322, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3322, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 44\n",
            "Loss:  tensor(0.3215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 45\n",
            "Loss:  tensor(0.3153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 46\n",
            "Loss:  tensor(0.2891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 47\n",
            "Loss:  tensor(0.3063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 48\n",
            "Loss:  tensor(0.3124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 49\n",
            "Loss:  tensor(0.3353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 50\n",
            "Loss:  tensor(0.3785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 51\n",
            "Loss:  tensor(0.3210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 52\n",
            "Loss:  tensor(0.2893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 53\n",
            "Loss:  tensor(0.2968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 54\n",
            "Loss:  tensor(0.3293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 55\n",
            "Loss:  tensor(0.3283, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3283, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 56\n",
            "Loss:  tensor(0.3389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 57\n",
            "Loss:  tensor(0.3178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 58\n",
            "Loss:  tensor(0.3256, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3256, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 59\n",
            "Loss:  tensor(0.2713, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2713, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 60\n",
            "Loss:  tensor(0.3381, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3381, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 61\n",
            "Loss:  tensor(0.2810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 62\n",
            "Loss:  tensor(0.2626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 63\n",
            "Loss:  tensor(0.3235, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3235, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 64\n",
            "Loss:  tensor(0.3388, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3388, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 65\n",
            "Loss:  tensor(0.3404, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3404, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 66\n",
            "Loss:  tensor(0.3213, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3213, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 67\n",
            "Loss:  tensor(0.3057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 68\n",
            "Loss:  tensor(0.2947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 69\n",
            "Loss:  tensor(0.2981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7198, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 70\n",
            "Loss:  tensor(0.3325, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3325, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 71\n",
            "Loss:  tensor(0.2999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 72\n",
            "Loss:  tensor(0.3132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 73\n",
            "Loss:  tensor(0.3365, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3365, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 74\n",
            "Loss:  tensor(0.2776, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2776, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 75\n",
            "Loss:  tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 0\n",
            "Loss:  tensor(0.3582, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3582, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 1\n",
            "Loss:  tensor(0.3023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 2\n",
            "Loss:  tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 3\n",
            "Loss:  tensor(0.3087, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3087, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 4\n",
            "Loss:  tensor(0.2791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 5\n",
            "Loss:  tensor(0.3323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 6\n",
            "Loss:  tensor(0.2976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 7\n",
            "Loss:  tensor(0.3164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 8\n",
            "Loss:  tensor(0.2882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 9\n",
            "Loss:  tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 10\n",
            "Loss:  tensor(0.3365, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3365, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 11\n",
            "Loss:  tensor(0.2898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 12\n",
            "Loss:  tensor(0.3133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 13\n",
            "Loss:  tensor(0.3178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 14\n",
            "Loss:  tensor(0.3465, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3465, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 15\n",
            "Loss:  tensor(0.2894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 16\n",
            "Loss:  tensor(0.3114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 17\n",
            "Loss:  tensor(0.3086, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3086, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 18\n",
            "Loss:  tensor(0.2919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 19\n",
            "Loss:  tensor(0.3359, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3359, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 20\n",
            "Loss:  tensor(0.3154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 21\n",
            "Loss:  tensor(0.3368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 22\n",
            "Loss:  tensor(0.3078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 23\n",
            "Loss:  tensor(0.3359, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3359, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 24\n",
            "Loss:  tensor(0.3260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 25\n",
            "Loss:  tensor(0.2768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 26\n",
            "Loss:  tensor(0.2891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 27\n",
            "Loss:  tensor(0.2943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 28\n",
            "Loss:  tensor(0.2844, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2844, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 29\n",
            "Loss:  tensor(0.3057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 30\n",
            "Loss:  tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 31\n",
            "Loss:  tensor(0.3024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 32\n",
            "Loss:  tensor(0.3279, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3279, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 33\n",
            "Loss:  tensor(0.3191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 34\n",
            "Loss:  tensor(0.3140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 35\n",
            "Loss:  tensor(0.3040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 36\n",
            "Loss:  tensor(0.3073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 37\n",
            "Loss:  tensor(0.3334, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3334, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 38\n",
            "Loss:  tensor(0.2850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 39\n",
            "Loss:  tensor(0.2925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 40\n",
            "Loss:  tensor(0.2883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 41\n",
            "Loss:  tensor(0.2967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 42\n",
            "Loss:  tensor(0.2926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 43\n",
            "Loss:  tensor(0.3293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 44\n",
            "Loss:  tensor(0.3218, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3218, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 45\n",
            "Loss:  tensor(0.2894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 46\n",
            "Loss:  tensor(0.3081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 47\n",
            "Loss:  tensor(0.3160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 48\n",
            "Loss:  tensor(0.2722, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2722, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 49\n",
            "Loss:  tensor(0.3002, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3002, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 50\n",
            "Loss:  tensor(0.2691, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2691, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 51\n",
            "Loss:  tensor(0.3055, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3055, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 52\n",
            "Loss:  tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 53\n",
            "Loss:  tensor(0.3277, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7200, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3277, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 54\n",
            "Loss:  tensor(0.2942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 55\n",
            "Loss:  tensor(0.2770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 56\n",
            "Loss:  tensor(0.3155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 57\n",
            "Loss:  tensor(0.2997, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2997, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 58\n",
            "Loss:  tensor(0.3013, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3013, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 59\n",
            "Loss:  tensor(0.2761, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2761, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 60\n",
            "Loss:  tensor(0.3098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 61\n",
            "Loss:  tensor(0.2883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 62\n",
            "Loss:  tensor(0.2829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 63\n",
            "Loss:  tensor(0.2981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 64\n",
            "Loss:  tensor(0.3090, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3090, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 65\n",
            "Loss:  tensor(0.2893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 66\n",
            "Loss:  tensor(0.2976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 67\n",
            "Loss:  tensor(0.3014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7212, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 68\n",
            "Loss:  tensor(0.3213, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3213, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 69\n",
            "Loss:  tensor(0.3099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 70\n",
            "Loss:  tensor(0.3336, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3336, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 71\n",
            "Loss:  tensor(0.3268, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3268, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 72\n",
            "Loss:  tensor(0.3510, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3510, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 73\n",
            "Loss:  tensor(0.3298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 74\n",
            "Loss:  tensor(0.3364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 75\n",
            "Loss:  tensor(0.3244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 0\n",
            "Loss:  tensor(0.3199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 1\n",
            "Loss:  tensor(0.3164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7219, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 2\n",
            "Loss:  tensor(0.2882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 3\n",
            "Loss:  tensor(0.3085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 4\n",
            "Loss:  tensor(0.2726, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2726, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 5\n",
            "Loss:  tensor(0.2575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 6\n",
            "Loss:  tensor(0.3142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 7\n",
            "Loss:  tensor(0.3165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 8\n",
            "Loss:  tensor(0.2749, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7198, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2749, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 9\n",
            "Loss:  tensor(0.3049, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3049, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 10\n",
            "Loss:  tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 11\n",
            "Loss:  tensor(0.2821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 12\n",
            "Loss:  tensor(0.3104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 13\n",
            "Loss:  tensor(0.2988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 14\n",
            "Loss:  tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 15\n",
            "Loss:  tensor(0.3156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 16\n",
            "Loss:  tensor(0.3212, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7200, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3212, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 17\n",
            "Loss:  tensor(0.3010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 18\n",
            "Loss:  tensor(0.2920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 19\n",
            "Loss:  tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 20\n",
            "Loss:  tensor(0.2834, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2834, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 21\n",
            "Loss:  tensor(0.3209, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3209, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 22\n",
            "Loss:  tensor(0.2851, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7213, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2851, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 23\n",
            "Loss:  tensor(0.3138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 24\n",
            "Loss:  tensor(0.2883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 25\n",
            "Loss:  tensor(0.3196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 26\n",
            "Loss:  tensor(0.3007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 27\n",
            "Loss:  tensor(0.3158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 28\n",
            "Loss:  tensor(0.2760, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2760, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 29\n",
            "Loss:  tensor(0.3318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 30\n",
            "Loss:  tensor(0.2782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 31\n",
            "Loss:  tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 32\n",
            "Loss:  tensor(0.2935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 33\n",
            "Loss:  tensor(0.3104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 34\n",
            "Loss:  tensor(0.3627, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7209, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3627, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 35\n",
            "Loss:  tensor(0.3174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7217, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 36\n",
            "Loss:  tensor(0.3110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 37\n",
            "Loss:  tensor(0.2758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 38\n",
            "Loss:  tensor(0.3431, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3431, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 39\n",
            "Loss:  tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 40\n",
            "Loss:  tensor(0.3073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 41\n",
            "Loss:  tensor(0.2846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 42\n",
            "Loss:  tensor(0.2990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7198, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 43\n",
            "Loss:  tensor(0.3329, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3329, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 44\n",
            "Loss:  tensor(0.3096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 45\n",
            "Loss:  tensor(0.2996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 46\n",
            "Loss:  tensor(0.2597, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2597, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 47\n",
            "Loss:  tensor(0.2851, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2851, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 48\n",
            "Loss:  tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 49\n",
            "Loss:  tensor(0.3405, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3405, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 50\n",
            "Loss:  tensor(0.2861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 51\n",
            "Loss:  tensor(0.3185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 52\n",
            "Loss:  tensor(0.3038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 53\n",
            "Loss:  tensor(0.2905, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2905, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 54\n",
            "Loss:  tensor(0.2947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 55\n",
            "Loss:  tensor(0.2895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 56\n",
            "Loss:  tensor(0.3521, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3521, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 57\n",
            "Loss:  tensor(0.3251, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3251, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 58\n",
            "Loss:  tensor(0.2789, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2789, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 59\n",
            "Loss:  tensor(0.2971, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2971, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 60\n",
            "Loss:  tensor(0.3131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 61\n",
            "Loss:  tensor(0.2989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 62\n",
            "Loss:  tensor(0.2476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 63\n",
            "Loss:  tensor(0.2825, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2825, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 64\n",
            "Loss:  tensor(0.2785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 65\n",
            "Loss:  tensor(0.3575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 66\n",
            "Loss:  tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 67\n",
            "Loss:  tensor(0.3064, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3064, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 68\n",
            "Loss:  tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 69\n",
            "Loss:  tensor(0.3066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 70\n",
            "Loss:  tensor(0.3009, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3009, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 71\n",
            "Loss:  tensor(0.2945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 72\n",
            "Loss:  tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 73\n",
            "Loss:  tensor(0.3239, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3239, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 74\n",
            "Loss:  tensor(0.2964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 75\n",
            "Loss:  tensor(0.2770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 0\n",
            "Loss:  tensor(0.3206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 1\n",
            "Loss:  tensor(0.3150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 2\n",
            "Loss:  tensor(0.2979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 3\n",
            "Loss:  tensor(0.3059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 4\n",
            "Loss:  tensor(0.3081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 5\n",
            "Loss:  tensor(0.3024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 6\n",
            "Loss:  tensor(0.2605, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2605, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 7\n",
            "Loss:  tensor(0.3027, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3027, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 8\n",
            "Loss:  tensor(0.2901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7214, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 9\n",
            "Loss:  tensor(0.2959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 10\n",
            "Loss:  tensor(0.2962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 11\n",
            "Loss:  tensor(0.2656, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2656, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 12\n",
            "Loss:  tensor(0.3342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 13\n",
            "Loss:  tensor(0.3044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 14\n",
            "Loss:  tensor(0.3163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7224, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 15\n",
            "Loss:  tensor(0.2858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 16\n",
            "Loss:  tensor(0.3500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 17\n",
            "Loss:  tensor(0.2833, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2833, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 18\n",
            "Loss:  tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 19\n",
            "Loss:  tensor(0.3368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 20\n",
            "Loss:  tensor(0.2591, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2591, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 21\n",
            "Loss:  tensor(0.2796, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2796, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 22\n",
            "Loss:  tensor(0.2588, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2588, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 23\n",
            "Loss:  tensor(0.2895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 24\n",
            "Loss:  tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 25\n",
            "Loss:  tensor(0.3290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 26\n",
            "Loss:  tensor(0.2855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 27\n",
            "Loss:  tensor(0.3288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 28\n",
            "Loss:  tensor(0.2700, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2700, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 29\n",
            "Loss:  tensor(0.2896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 30\n",
            "Loss:  tensor(0.3204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 31\n",
            "Loss:  tensor(0.3210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 32\n",
            "Loss:  tensor(0.2459, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2459, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 33\n",
            "Loss:  tensor(0.3074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 34\n",
            "Loss:  tensor(0.2585, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2585, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 35\n",
            "Loss:  tensor(0.2758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 36\n",
            "Loss:  tensor(0.3476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 37\n",
            "Loss:  tensor(0.2857, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2857, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 38\n",
            "Loss:  tensor(0.3267, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3267, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 39\n",
            "Loss:  tensor(0.2732, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2732, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 40\n",
            "Loss:  tensor(0.2682, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2682, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 41\n",
            "Loss:  tensor(0.3215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 42\n",
            "Loss:  tensor(0.3237, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3237, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 43\n",
            "Loss:  tensor(0.3045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 44\n",
            "Loss:  tensor(0.2625, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2625, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 45\n",
            "Loss:  tensor(0.3338, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3338, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 46\n",
            "Loss:  tensor(0.3368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 47\n",
            "Loss:  tensor(0.2565, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2565, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 48\n",
            "Loss:  tensor(0.2742, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2742, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 49\n",
            "Loss:  tensor(0.2817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 50\n",
            "Loss:  tensor(0.3419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 51\n",
            "Loss:  tensor(0.2948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 52\n",
            "Loss:  tensor(0.3111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 53\n",
            "Loss:  tensor(0.3298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 54\n",
            "Loss:  tensor(0.3168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7198, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 55\n",
            "Loss:  tensor(0.2894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 56\n",
            "Loss:  tensor(0.3120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 57\n",
            "Loss:  tensor(0.3033, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7214, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3033, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 58\n",
            "Loss:  tensor(0.2952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 59\n",
            "Loss:  tensor(0.3118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 60\n",
            "Loss:  tensor(0.2911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 61\n",
            "Loss:  tensor(0.2756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 62\n",
            "Loss:  tensor(0.2836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 63\n",
            "Loss:  tensor(0.2988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 64\n",
            "Loss:  tensor(0.3576, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7229, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3576, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 65\n",
            "Loss:  tensor(0.3053, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3053, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 66\n",
            "Loss:  tensor(0.3063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 67\n",
            "Loss:  tensor(0.2881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 68\n",
            "Loss:  tensor(0.3403, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3403, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 69\n",
            "Loss:  tensor(0.2965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 70\n",
            "Loss:  tensor(0.2676, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2676, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 71\n",
            "Loss:  tensor(0.2991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 72\n",
            "Loss:  tensor(0.3260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 73\n",
            "Loss:  tensor(0.3150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 74\n",
            "Loss:  tensor(0.3288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 75\n",
            "Loss:  tensor(0.3242, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3242, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 0\n",
            "Loss:  tensor(0.2890, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2890, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 1\n",
            "Loss:  tensor(0.2932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 2\n",
            "Loss:  tensor(0.2777, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7229, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2777, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 3\n",
            "Loss:  tensor(0.3058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 4\n",
            "Loss:  tensor(0.2848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 5\n",
            "Loss:  tensor(0.3020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 6\n",
            "Loss:  tensor(0.3280, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3280, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 7\n",
            "Loss:  tensor(0.2672, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2672, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 8\n",
            "Loss:  tensor(0.2964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 9\n",
            "Loss:  tensor(0.3102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 10\n",
            "Loss:  tensor(0.2942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 11\n",
            "Loss:  tensor(0.2906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 12\n",
            "Loss:  tensor(0.2791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 13\n",
            "Loss:  tensor(0.3035, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3035, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 14\n",
            "Loss:  tensor(0.2951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 15\n",
            "Loss:  tensor(0.3012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 16\n",
            "Loss:  tensor(0.2839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 17\n",
            "Loss:  tensor(0.3046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 18\n",
            "Loss:  tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 19\n",
            "Loss:  tensor(0.3047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 20\n",
            "Loss:  tensor(0.3224, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3224, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 21\n",
            "Loss:  tensor(0.2785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 22\n",
            "Loss:  tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 23\n",
            "Loss:  tensor(0.3418, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3418, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 24\n",
            "Loss:  tensor(0.3327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 25\n",
            "Loss:  tensor(0.2944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 26\n",
            "Loss:  tensor(0.3045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 27\n",
            "Loss:  tensor(0.2854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 28\n",
            "Loss:  tensor(0.3051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 29\n",
            "Loss:  tensor(0.2897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 30\n",
            "Loss:  tensor(0.2931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 31\n",
            "Loss:  tensor(0.2855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 32\n",
            "Loss:  tensor(0.3345, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7217, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3345, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 33\n",
            "Loss:  tensor(0.2888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 34\n",
            "Loss:  tensor(0.3178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 35\n",
            "Loss:  tensor(0.2837, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2837, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 36\n",
            "Loss:  tensor(0.3648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 37\n",
            "Loss:  tensor(0.2768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 38\n",
            "Loss:  tensor(0.2259, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7217, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2259, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 39\n",
            "Loss:  tensor(0.3274, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3274, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 40\n",
            "Loss:  tensor(0.3142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 41\n",
            "Loss:  tensor(0.3425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 42\n",
            "Loss:  tensor(0.3135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7235, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 43\n",
            "Loss:  tensor(0.2767, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2767, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 44\n",
            "Loss:  tensor(0.3243, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3243, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 45\n",
            "Loss:  tensor(0.3092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 46\n",
            "Loss:  tensor(0.2791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 47\n",
            "Loss:  tensor(0.2834, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2834, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 48\n",
            "Loss:  tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 49\n",
            "Loss:  tensor(0.3205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 50\n",
            "Loss:  tensor(0.2889, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2889, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 51\n",
            "Loss:  tensor(0.3116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 52\n",
            "Loss:  tensor(0.2658, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2658, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 53\n",
            "Loss:  tensor(0.3381, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3381, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 54\n",
            "Loss:  tensor(0.2879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 55\n",
            "Loss:  tensor(0.2863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 56\n",
            "Loss:  tensor(0.3029, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3029, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 57\n",
            "Loss:  tensor(0.2790, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2790, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 58\n",
            "Loss:  tensor(0.2756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 59\n",
            "Loss:  tensor(0.2923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 60\n",
            "Loss:  tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 61\n",
            "Loss:  tensor(0.2430, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2430, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 62\n",
            "Loss:  tensor(0.2826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 63\n",
            "Loss:  tensor(0.3061, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3061, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 64\n",
            "Loss:  tensor(0.2774, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2774, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 65\n",
            "Loss:  tensor(0.2826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 66\n",
            "Loss:  tensor(0.2970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 67\n",
            "Loss:  tensor(0.3165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 68\n",
            "Loss:  tensor(0.3033, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3033, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 69\n",
            "Loss:  tensor(0.3175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 70\n",
            "Loss:  tensor(0.3334, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3334, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 71\n",
            "Loss:  tensor(0.2854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 72\n",
            "Loss:  tensor(0.2925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 73\n",
            "Loss:  tensor(0.2955, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2955, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 74\n",
            "Loss:  tensor(0.2816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 75\n",
            "Loss:  tensor(0.2874, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2874, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 0\n",
            "Loss:  tensor(0.3424, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3424, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 1\n",
            "Loss:  tensor(0.3132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 2\n",
            "Loss:  tensor(0.2924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7208, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 3\n",
            "Loss:  tensor(0.2848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 4\n",
            "Loss:  tensor(0.2937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 5\n",
            "Loss:  tensor(0.3275, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3275, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 6\n",
            "Loss:  tensor(0.3239, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7209, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3239, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 7\n",
            "Loss:  tensor(0.3069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 8\n",
            "Loss:  tensor(0.3062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 9\n",
            "Loss:  tensor(0.3253, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3253, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 10\n",
            "Loss:  tensor(0.3084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 11\n",
            "Loss:  tensor(0.3210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 12\n",
            "Loss:  tensor(0.2804, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2804, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 13\n",
            "Loss:  tensor(0.2513, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2513, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 14\n",
            "Loss:  tensor(0.3140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 15\n",
            "Loss:  tensor(0.2840, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2840, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 16\n",
            "Loss:  tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 17\n",
            "Loss:  tensor(0.2494, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2494, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 18\n",
            "Loss:  tensor(0.2816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 19\n",
            "Loss:  tensor(0.2601, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2601, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 20\n",
            "Loss:  tensor(0.3095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 21\n",
            "Loss:  tensor(0.2808, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2808, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 22\n",
            "Loss:  tensor(0.2944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 23\n",
            "Loss:  tensor(0.3466, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3466, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 24\n",
            "Loss:  tensor(0.3109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 25\n",
            "Loss:  tensor(0.2724, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2724, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 26\n",
            "Loss:  tensor(0.2455, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2455, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 27\n",
            "Loss:  tensor(0.2853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 28\n",
            "Loss:  tensor(0.2745, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2745, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 29\n",
            "Loss:  tensor(0.2771, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2771, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 30\n",
            "Loss:  tensor(0.3436, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3436, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 31\n",
            "Loss:  tensor(0.2852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 32\n",
            "Loss:  tensor(0.2929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 33\n",
            "Loss:  tensor(0.2954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 34\n",
            "Loss:  tensor(0.3085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 35\n",
            "Loss:  tensor(0.3362, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3362, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 36\n",
            "Loss:  tensor(0.2973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 37\n",
            "Loss:  tensor(0.2866, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2866, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 38\n",
            "Loss:  tensor(0.2732, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2732, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 39\n",
            "Loss:  tensor(0.3337, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3337, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 40\n",
            "Loss:  tensor(0.2858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 41\n",
            "Loss:  tensor(0.2767, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2767, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 42\n",
            "Loss:  tensor(0.2958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 43\n",
            "Loss:  tensor(0.2775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 44\n",
            "Loss:  tensor(0.2510, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2510, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 45\n",
            "Loss:  tensor(0.3193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 46\n",
            "Loss:  tensor(0.3020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 47\n",
            "Loss:  tensor(0.3408, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3408, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 48\n",
            "Loss:  tensor(0.3237, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7213, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3237, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 49\n",
            "Loss:  tensor(0.2733, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2733, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 50\n",
            "Loss:  tensor(0.2877, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2877, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 51\n",
            "Loss:  tensor(0.3080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7208, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 52\n",
            "Loss:  tensor(0.3082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 53\n",
            "Loss:  tensor(0.2666, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2666, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 54\n",
            "Loss:  tensor(0.3323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 55\n",
            "Loss:  tensor(0.2807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 56\n",
            "Loss:  tensor(0.3023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 57\n",
            "Loss:  tensor(0.2566, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2566, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 58\n",
            "Loss:  tensor(0.3422, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3422, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 59\n",
            "Loss:  tensor(0.2986, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2986, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 60\n",
            "Loss:  tensor(0.2981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 61\n",
            "Loss:  tensor(0.3244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 62\n",
            "Loss:  tensor(0.2835, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2835, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 63\n",
            "Loss:  tensor(0.3004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 64\n",
            "Loss:  tensor(0.2754, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2754, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 65\n",
            "Loss:  tensor(0.3030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 66\n",
            "Loss:  tensor(0.3144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 67\n",
            "Loss:  tensor(0.2980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 68\n",
            "Loss:  tensor(0.3121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 69\n",
            "Loss:  tensor(0.3070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 70\n",
            "Loss:  tensor(0.2798, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2798, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 71\n",
            "Loss:  tensor(0.2730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 72\n",
            "Loss:  tensor(0.2918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 73\n",
            "Loss:  tensor(0.2954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 74\n",
            "Loss:  tensor(0.3132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 75\n",
            "Loss:  tensor(0.2720, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2720, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 0\n",
            "Loss:  tensor(-14.2618, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 1\n",
            "Loss:  tensor(-13.7054, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6670, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 2\n",
            "Loss:  tensor(-13.4820, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6557, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 3\n",
            "Loss:  tensor(-13.6499, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6635, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2843, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 4\n",
            "Loss:  tensor(-13.3385, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 5\n",
            "Loss:  tensor(-13.0620, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6376, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 6\n",
            "Loss:  tensor(-12.6086, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 7\n",
            "Loss:  tensor(-12.8634, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6269, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 8\n",
            "Loss:  tensor(-12.3188, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 9\n",
            "Loss:  tensor(-12.5304, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3437, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 10\n",
            "Loss:  tensor(-12.5635, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3254, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 11\n",
            "Loss:  tensor(-12.4854, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 12\n",
            "Loss:  tensor(-12.6662, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6267, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 13\n",
            "Loss:  tensor(-12.5126, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6234, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5780, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 14\n",
            "Loss:  tensor(-12.6389, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6289, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5688, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 15\n",
            "Loss:  tensor(-12.1057, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 16\n",
            "Loss:  tensor(-12.4660, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 17\n",
            "Loss:  tensor(-11.6773, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5422, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 18\n",
            "Loss:  tensor(-11.9938, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 19\n",
            "Loss:  tensor(-12.9118, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6375, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 20\n",
            "Loss:  tensor(-12.4897, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 21\n",
            "Loss:  tensor(-12.7180, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 22\n",
            "Loss:  tensor(-13.3011, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6554, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4617, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 23\n",
            "Loss:  tensor(-13.3837, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6563, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 24\n",
            "Loss:  tensor(-12.6310, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6229, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4497, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 25\n",
            "Loss:  tensor(-13.0283, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6415, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 26\n",
            "Loss:  tensor(-13.4345, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6595, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 27\n",
            "Loss:  tensor(-13.2452, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6501, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 28\n",
            "Loss:  tensor(-13.0869, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4061, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 29\n",
            "Loss:  tensor(-13.3365, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6525, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3659, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 30\n",
            "Loss:  tensor(-12.8913, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6328, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 31\n",
            "Loss:  tensor(-13.1837, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6452, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3665, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 32\n",
            "Loss:  tensor(-12.8896, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6312, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3647, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 33\n",
            "Loss:  tensor(-12.7708, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6266, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3885, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 34\n",
            "Loss:  tensor(-12.3815, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6067, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3587, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 35\n",
            "Loss:  tensor(-11.9423, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5874, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 36\n",
            "Loss:  tensor(-12.1276, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3429, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 37\n",
            "Loss:  tensor(-11.8558, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5835, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 38\n",
            "Loss:  tensor(-11.8593, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3657, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 39\n",
            "Loss:  tensor(-11.8308, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5788, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3230, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 40\n",
            "Loss:  tensor(-12.0904, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 41\n",
            "Loss:  tensor(-12.4481, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3385, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 42\n",
            "Loss:  tensor(-12.3729, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3568, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 43\n",
            "Loss:  tensor(-12.2499, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6013, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 44\n",
            "Loss:  tensor(-12.5728, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 45\n",
            "Loss:  tensor(-12.1700, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 46\n",
            "Loss:  tensor(-12.0119, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5910, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 47\n",
            "Loss:  tensor(-11.9638, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 48\n",
            "Loss:  tensor(-12.0704, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3969, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 49\n",
            "Loss:  tensor(-12.0228, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 50\n",
            "Loss:  tensor(-12.5517, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 51\n",
            "Loss:  tensor(-11.9229, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4568, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 52\n",
            "Loss:  tensor(-12.3972, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 53\n",
            "Loss:  tensor(-12.9360, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6360, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 54\n",
            "Loss:  tensor(-12.8124, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 55\n",
            "Loss:  tensor(-13.3491, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6525, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3538, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 56\n",
            "Loss:  tensor(-12.7614, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 57\n",
            "Loss:  tensor(-13.6674, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6687, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3759, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 58\n",
            "Loss:  tensor(-13.5148, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6639, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 59\n",
            "Loss:  tensor(-12.5368, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 60\n",
            "Loss:  tensor(-12.4985, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 61\n",
            "Loss:  tensor(-13.5973, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6663, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 62\n",
            "Loss:  tensor(-13.7944, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3410, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 63\n",
            "Loss:  tensor(-13.3204, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3887, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 64\n",
            "Loss:  tensor(-13.0644, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6401, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3783, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 65\n",
            "Loss:  tensor(-12.4198, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 66\n",
            "Loss:  tensor(-12.7731, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6258, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3685, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 67\n",
            "Loss:  tensor(-12.4746, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3487, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 68\n",
            "Loss:  tensor(-12.6866, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6211, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 69\n",
            "Loss:  tensor(-12.4516, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3354, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 70\n",
            "Loss:  tensor(-10.9230, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5363, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3394, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 71\n",
            "Loss:  tensor(-10.2126, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3707, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 72\n",
            "Loss:  tensor(-9.3768, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.4648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 73\n",
            "Loss:  tensor(-9.9432, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.4915, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3774, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 74\n",
            "Loss:  tensor(-9.5639, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.4727, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3622, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 75\n",
            "Loss:  tensor(-10.6547, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3300, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 0\n",
            "Loss:  tensor(-10.1222, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.4998, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3729, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 1\n",
            "Loss:  tensor(-10.3694, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3349, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 2\n",
            "Loss:  tensor(-11.1303, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5470, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3557, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 3\n",
            "Loss:  tensor(-11.4939, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5640, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 4\n",
            "Loss:  tensor(-11.5663, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5679, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3587, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 5\n",
            "Loss:  tensor(-11.9590, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4006, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 6\n",
            "Loss:  tensor(-12.3549, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 7\n",
            "Loss:  tensor(-11.3956, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5607, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 8\n",
            "Loss:  tensor(-12.4740, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 9\n",
            "Loss:  tensor(-12.2764, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 10\n",
            "Loss:  tensor(-12.8721, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6321, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 11\n",
            "Loss:  tensor(-13.0449, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6466, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5330, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 12\n",
            "Loss:  tensor(-12.2433, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6067, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 13\n",
            "Loss:  tensor(-12.4741, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4351, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 14\n",
            "Loss:  tensor(-12.8444, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6313, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 15\n",
            "Loss:  tensor(-13.3360, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6562, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4432, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 16\n",
            "Loss:  tensor(-13.1067, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6460, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4597, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 17\n",
            "Loss:  tensor(-12.6453, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6239, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4572, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 18\n",
            "Loss:  tensor(-12.3865, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4450, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 19\n",
            "Loss:  tensor(-12.1342, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4560, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 20\n",
            "Loss:  tensor(-12.7515, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4048, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 21\n",
            "Loss:  tensor(-12.4549, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4418, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 22\n",
            "Loss:  tensor(-12.4943, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3705, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 23\n",
            "Loss:  tensor(-12.7953, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6280, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 24\n",
            "Loss:  tensor(-12.3164, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6068, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4257, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 25\n",
            "Loss:  tensor(-12.5957, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4218, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 26\n",
            "Loss:  tensor(-12.3387, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6050, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3667, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 27\n",
            "Loss:  tensor(-12.7816, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6268, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3813, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 28\n",
            "Loss:  tensor(-12.6357, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6209, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 29\n",
            "Loss:  tensor(-12.7859, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6280, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 30\n",
            "Loss:  tensor(-12.5833, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 31\n",
            "Loss:  tensor(-12.8425, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 32\n",
            "Loss:  tensor(-12.2245, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6022, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 33\n",
            "Loss:  tensor(-13.2339, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4200, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 34\n",
            "Loss:  tensor(-13.0991, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 35\n",
            "Loss:  tensor(-12.5246, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3544, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 36\n",
            "Loss:  tensor(-12.3606, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6086, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 37\n",
            "Loss:  tensor(-11.7396, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5764, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3641, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 38\n",
            "Loss:  tensor(-11.4307, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5649, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 39\n",
            "Loss:  tensor(-11.0225, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5438, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 40\n",
            "Loss:  tensor(-10.6361, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5266, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4224, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 41\n",
            "Loss:  tensor(-11.0012, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5436, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 42\n",
            "Loss:  tensor(-11.1111, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5477, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 43\n",
            "Loss:  tensor(-11.3915, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5608, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 44\n",
            "Loss:  tensor(-12.4143, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 45\n",
            "Loss:  tensor(-12.7055, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6241, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 46\n",
            "Loss:  tensor(-13.0960, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6418, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 47\n",
            "Loss:  tensor(-13.5197, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 48\n",
            "Loss:  tensor(-12.4167, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4492, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 49\n",
            "Loss:  tensor(-13.0311, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6393, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 50\n",
            "Loss:  tensor(-13.8897, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 51\n",
            "Loss:  tensor(-14.1091, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 52\n",
            "Loss:  tensor(-13.4320, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6592, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 53\n",
            "Loss:  tensor(-13.7241, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 54\n",
            "Loss:  tensor(-13.7567, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6767, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4542, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 55\n",
            "Loss:  tensor(-13.7877, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4393, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 56\n",
            "Loss:  tensor(-12.7034, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6275, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4741, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 57\n",
            "Loss:  tensor(-12.3249, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4675, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 58\n",
            "Loss:  tensor(-12.7937, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6299, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 59\n",
            "Loss:  tensor(-12.2471, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 60\n",
            "Loss:  tensor(-12.3905, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4674, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 61\n",
            "Loss:  tensor(-11.5682, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5733, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4711, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 62\n",
            "Loss:  tensor(-11.1777, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5548, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4727, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 63\n",
            "Loss:  tensor(-10.9069, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5439, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 64\n",
            "Loss:  tensor(-10.9579, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5445, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 65\n",
            "Loss:  tensor(-10.7221, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5337, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 66\n",
            "Loss:  tensor(-10.5028, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5227, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4734, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 67\n",
            "Loss:  tensor(-10.7119, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5312, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 68\n",
            "Loss:  tensor(-10.4409, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 69\n",
            "Loss:  tensor(-10.5581, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5093, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 70\n",
            "Loss:  tensor(-10.7525, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5357, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 71\n",
            "Loss:  tensor(-12.1820, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6029, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4783, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 72\n",
            "Loss:  tensor(-11.5707, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5720, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4408, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 73\n",
            "Loss:  tensor(-12.4446, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 74\n",
            "Loss:  tensor(-12.7734, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6305, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4661, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 75\n",
            "Loss:  tensor(-12.9257, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6381, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4742, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 0\n",
            "Loss:  tensor(-12.4709, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4533, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 1\n",
            "Loss:  tensor(-13.1081, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6453, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4430, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 2\n",
            "Loss:  tensor(-12.4480, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4719, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 3\n",
            "Loss:  tensor(-13.4831, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4719, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 4\n",
            "Loss:  tensor(-13.5874, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6684, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4498, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 5\n",
            "Loss:  tensor(-13.3424, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6582, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4802, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 6\n",
            "Loss:  tensor(-12.5582, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 7\n",
            "Loss:  tensor(-12.6533, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5033, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 8\n",
            "Loss:  tensor(-12.8172, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6305, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4236, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 9\n",
            "Loss:  tensor(-12.9061, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6361, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4512, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 10\n",
            "Loss:  tensor(-12.1470, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5997, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4460, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 11\n",
            "Loss:  tensor(-12.2984, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6053, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 12\n",
            "Loss:  tensor(-12.1757, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5998, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 13\n",
            "Loss:  tensor(-11.4217, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 14\n",
            "Loss:  tensor(-11.0932, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5486, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4277, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 15\n",
            "Loss:  tensor(-11.8750, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 16\n",
            "Loss:  tensor(-11.8144, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4311, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 17\n",
            "Loss:  tensor(-12.5141, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 18\n",
            "Loss:  tensor(-12.9074, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6325, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3745, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 19\n",
            "Loss:  tensor(-12.5732, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 20\n",
            "Loss:  tensor(-13.1000, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6436, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 21\n",
            "Loss:  tensor(-13.1508, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6427, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3457, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 22\n",
            "Loss:  tensor(-13.4451, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6590, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 23\n",
            "Loss:  tensor(-13.1269, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 24\n",
            "Loss:  tensor(-13.5186, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6600, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3414, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 25\n",
            "Loss:  tensor(-13.2559, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6503, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3998, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 26\n",
            "Loss:  tensor(-13.2992, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6530, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 27\n",
            "Loss:  tensor(-12.6240, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 28\n",
            "Loss:  tensor(-13.0848, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6404, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 29\n",
            "Loss:  tensor(-13.0872, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6435, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4267, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 30\n",
            "Loss:  tensor(-13.1483, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3504, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 31\n",
            "Loss:  tensor(-13.0999, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6430, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 32\n",
            "Loss:  tensor(-12.1726, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3386, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 33\n",
            "Loss:  tensor(-12.7284, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6221, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3357, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 34\n",
            "Loss:  tensor(-12.6390, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3587, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 35\n",
            "Loss:  tensor(-13.2430, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6478, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3602, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 36\n",
            "Loss:  tensor(-12.4379, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 37\n",
            "Loss:  tensor(-12.9130, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6365, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4537, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 38\n",
            "Loss:  tensor(-12.6218, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6200, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 39\n",
            "Loss:  tensor(-12.6035, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 40\n",
            "Loss:  tensor(-13.3235, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6553, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4382, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 41\n",
            "Loss:  tensor(-12.4956, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 42\n",
            "Loss:  tensor(-12.6906, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6261, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 43\n",
            "Loss:  tensor(-12.9779, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6386, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 44\n",
            "Loss:  tensor(-13.4316, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6587, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 45\n",
            "Loss:  tensor(-12.8015, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4300, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 46\n",
            "Loss:  tensor(-12.4476, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4259, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 47\n",
            "Loss:  tensor(-12.7037, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6262, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4459, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 48\n",
            "Loss:  tensor(-12.6476, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4639, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 49\n",
            "Loss:  tensor(-12.1206, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4671, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 50\n",
            "Loss:  tensor(-12.6357, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6216, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 51\n",
            "Loss:  tensor(-12.1810, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4672, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 52\n",
            "Loss:  tensor(-11.8459, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5838, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 53\n",
            "Loss:  tensor(-12.3944, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 54\n",
            "Loss:  tensor(-12.0321, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4358, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 55\n",
            "Loss:  tensor(-12.5678, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 56\n",
            "Loss:  tensor(-12.3531, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 57\n",
            "Loss:  tensor(-11.9839, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 58\n",
            "Loss:  tensor(-12.5718, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4501, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 59\n",
            "Loss:  tensor(-12.7704, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6274, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 60\n",
            "Loss:  tensor(-12.2230, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4415, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 61\n",
            "Loss:  tensor(-11.7524, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5781, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 62\n",
            "Loss:  tensor(-12.5915, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 63\n",
            "Loss:  tensor(-13.0420, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6406, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4107, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 64\n",
            "Loss:  tensor(-12.6248, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4651, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 65\n",
            "Loss:  tensor(-12.7531, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6272, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 66\n",
            "Loss:  tensor(-13.1118, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6430, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3915, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 67\n",
            "Loss:  tensor(-12.5934, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 68\n",
            "Loss:  tensor(-12.7633, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4406, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 69\n",
            "Loss:  tensor(-13.2830, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6519, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 70\n",
            "Loss:  tensor(-12.8493, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 71\n",
            "Loss:  tensor(-12.9457, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6338, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3649, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 72\n",
            "Loss:  tensor(-12.9829, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3580, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 73\n",
            "Loss:  tensor(-12.4929, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3538, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 74\n",
            "Loss:  tensor(-12.8217, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  12 Batch: 75\n",
            "Loss:  tensor(-12.7225, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6228, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3558, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 0\n",
            "Loss:  tensor(-13.4102, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6548, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3413, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 1\n",
            "Loss:  tensor(-13.5060, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6608, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3714, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 2\n",
            "Loss:  tensor(-12.8016, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6272, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3686, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 3\n",
            "Loss:  tensor(-12.5238, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3729, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 4\n",
            "Loss:  tensor(-12.5844, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3586, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 5\n",
            "Loss:  tensor(-12.8425, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 6\n",
            "Loss:  tensor(-13.3819, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6553, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 7\n",
            "Loss:  tensor(-12.8523, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6278, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3319, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 8\n",
            "Loss:  tensor(-13.2198, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6474, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3752, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 9\n",
            "Loss:  tensor(-12.8346, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6300, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 10\n",
            "Loss:  tensor(-12.7567, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6262, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 11\n",
            "Loss:  tensor(-12.7151, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6239, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3877, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 12\n",
            "Loss:  tensor(-12.8421, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3624, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 13\n",
            "Loss:  tensor(-11.8083, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5809, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 14\n",
            "Loss:  tensor(-12.0616, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 15\n",
            "Loss:  tensor(-12.8260, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6309, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 16\n",
            "Loss:  tensor(-12.9643, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6359, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 17\n",
            "Loss:  tensor(-12.5634, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4042, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 18\n",
            "Loss:  tensor(-12.5380, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3857, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 19\n",
            "Loss:  tensor(-12.5976, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 20\n",
            "Loss:  tensor(-13.2568, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6511, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 21\n",
            "Loss:  tensor(-12.5154, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4457, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 22\n",
            "Loss:  tensor(-12.4334, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4050, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 23\n",
            "Loss:  tensor(-12.6285, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3780, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 24\n",
            "Loss:  tensor(-11.7204, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 25\n",
            "Loss:  tensor(-12.4582, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 26\n",
            "Loss:  tensor(-11.9408, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 27\n",
            "Loss:  tensor(-12.2599, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6054, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4543, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 28\n",
            "Loss:  tensor(-12.3628, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3887, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 29\n",
            "Loss:  tensor(-11.8479, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4497, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 30\n",
            "Loss:  tensor(-12.6671, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3834, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 31\n",
            "Loss:  tensor(-12.2172, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4043, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 32\n",
            "Loss:  tensor(-11.7147, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5790, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4445, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 33\n",
            "Loss:  tensor(-12.7225, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 34\n",
            "Loss:  tensor(-11.7774, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 35\n",
            "Loss:  tensor(-12.5097, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4683, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 36\n",
            "Loss:  tensor(-12.3620, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 37\n",
            "Loss:  tensor(-12.4040, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 38\n",
            "Loss:  tensor(-12.1920, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 39\n",
            "Loss:  tensor(-12.5578, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 40\n",
            "Loss:  tensor(-12.6518, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6245, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4629, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 41\n",
            "Loss:  tensor(-13.0134, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6426, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 42\n",
            "Loss:  tensor(-12.6722, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6235, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4212, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 43\n",
            "Loss:  tensor(-13.1256, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6452, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4247, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 44\n",
            "Loss:  tensor(-12.6775, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6247, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4420, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 45\n",
            "Loss:  tensor(-13.0990, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6448, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4413, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 46\n",
            "Loss:  tensor(-13.2819, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6546, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 47\n",
            "Loss:  tensor(-12.9535, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6358, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 48\n",
            "Loss:  tensor(-12.7051, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 49\n",
            "Loss:  tensor(-13.6783, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6718, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4304, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 50\n",
            "Loss:  tensor(-12.6597, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4295, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 51\n",
            "Loss:  tensor(-13.2890, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6543, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4508, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 52\n",
            "Loss:  tensor(-12.6458, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6239, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4560, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 53\n",
            "Loss:  tensor(-12.9458, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 54\n",
            "Loss:  tensor(-12.0594, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4551, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 55\n",
            "Loss:  tensor(-12.7281, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6287, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4739, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 56\n",
            "Loss:  tensor(-13.1397, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4452, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 57\n",
            "Loss:  tensor(-12.7363, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4433, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 58\n",
            "Loss:  tensor(-12.3887, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4320, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 59\n",
            "Loss:  tensor(-12.9500, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 60\n",
            "Loss:  tensor(-12.5886, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4463, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 61\n",
            "Loss:  tensor(-12.5711, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4505, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 62\n",
            "Loss:  tensor(-12.6847, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6248, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4355, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 63\n",
            "Loss:  tensor(-12.4773, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 64\n",
            "Loss:  tensor(-12.4851, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4443, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 65\n",
            "Loss:  tensor(-12.5955, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 66\n",
            "Loss:  tensor(-11.8906, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5845, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3847, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 67\n",
            "Loss:  tensor(-11.9073, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 68\n",
            "Loss:  tensor(-11.9590, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4499, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 69\n",
            "Loss:  tensor(-12.2963, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4363, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 70\n",
            "Loss:  tensor(-11.7700, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5808, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4273, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 71\n",
            "Loss:  tensor(-11.6178, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 72\n",
            "Loss:  tensor(-11.8150, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 73\n",
            "Loss:  tensor(-12.5820, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 74\n",
            "Loss:  tensor(-12.1997, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6022, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  13 Batch: 75\n",
            "Loss:  tensor(-12.3508, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6087, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4320, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 0\n",
            "Loss:  tensor(-12.5162, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4378, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 1\n",
            "Loss:  tensor(-12.2118, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6035, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 2\n",
            "Loss:  tensor(-12.4162, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 3\n",
            "Loss:  tensor(-12.9117, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 4\n",
            "Loss:  tensor(-12.8624, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6343, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4583, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 5\n",
            "Loss:  tensor(-13.6548, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6686, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 6\n",
            "Loss:  tensor(-13.3372, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6529, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3733, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 7\n",
            "Loss:  tensor(-13.7549, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6749, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 8\n",
            "Loss:  tensor(-13.5784, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6649, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3842, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 9\n",
            "Loss:  tensor(-13.0198, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6383, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3843, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 10\n",
            "Loss:  tensor(-13.0669, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6434, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4452, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 11\n",
            "Loss:  tensor(-12.9710, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6344, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3516, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 12\n",
            "Loss:  tensor(-12.0590, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5917, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3675, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 13\n",
            "Loss:  tensor(-12.8593, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6305, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 14\n",
            "Loss:  tensor(-12.7894, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6279, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 15\n",
            "Loss:  tensor(-12.1081, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 16\n",
            "Loss:  tensor(-12.0981, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3912, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 17\n",
            "Loss:  tensor(-12.2724, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 18\n",
            "Loss:  tensor(-11.1913, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5530, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4219, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 19\n",
            "Loss:  tensor(-11.4995, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5660, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3862, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 20\n",
            "Loss:  tensor(-11.0526, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5445, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3813, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 21\n",
            "Loss:  tensor(-10.7025, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5302, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4308, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 22\n",
            "Loss:  tensor(-11.1781, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5522, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 23\n",
            "Loss:  tensor(-10.6532, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5262, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 24\n",
            "Loss:  tensor(-11.1769, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5495, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3625, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 25\n",
            "Loss:  tensor(-10.9008, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5378, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3934, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 26\n",
            "Loss:  tensor(-11.5677, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5696, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 27\n",
            "Loss:  tensor(-10.9467, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5400, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 28\n",
            "Loss:  tensor(-11.2399, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5562, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4400, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 29\n",
            "Loss:  tensor(-12.1189, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 30\n",
            "Loss:  tensor(-11.2324, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5555, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4337, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 31\n",
            "Loss:  tensor(-12.3905, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 32\n",
            "Loss:  tensor(-11.7409, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5784, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 33\n",
            "Loss:  tensor(-12.0765, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3837, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 34\n",
            "Loss:  tensor(-12.5097, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 35\n",
            "Loss:  tensor(-12.8324, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6295, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 36\n",
            "Loss:  tensor(-12.4470, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 37\n",
            "Loss:  tensor(-12.7954, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6310, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4552, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 38\n",
            "Loss:  tensor(-12.7685, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 39\n",
            "Loss:  tensor(-12.8303, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6316, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 40\n",
            "Loss:  tensor(-13.2274, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6478, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3759, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 41\n",
            "Loss:  tensor(-13.2555, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 42\n",
            "Loss:  tensor(-13.1904, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6479, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 43\n",
            "Loss:  tensor(-13.4611, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6616, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4330, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 44\n",
            "Loss:  tensor(-12.6629, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6239, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4380, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 45\n",
            "Loss:  tensor(-13.0158, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6395, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 46\n",
            "Loss:  tensor(-12.5270, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 47\n",
            "Loss:  tensor(-12.5272, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4243, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 48\n",
            "Loss:  tensor(-12.9431, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 49\n",
            "Loss:  tensor(-12.6093, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3800, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 50\n",
            "Loss:  tensor(-12.9675, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 51\n",
            "Loss:  tensor(-12.5682, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4387, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 52\n",
            "Loss:  tensor(-12.4032, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 53\n",
            "Loss:  tensor(-12.3203, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 54\n",
            "Loss:  tensor(-12.4866, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4340, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 55\n",
            "Loss:  tensor(-12.7191, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 56\n",
            "Loss:  tensor(-12.5880, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4042, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 57\n",
            "Loss:  tensor(-12.5451, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 58\n",
            "Loss:  tensor(-12.7932, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6302, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4405, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 59\n",
            "Loss:  tensor(-12.8025, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 60\n",
            "Loss:  tensor(-12.7685, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 61\n",
            "Loss:  tensor(-12.4533, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 62\n",
            "Loss:  tensor(-12.7718, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6292, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4418, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 63\n",
            "Loss:  tensor(-12.0444, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 64\n",
            "Loss:  tensor(-12.8471, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6306, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 65\n",
            "Loss:  tensor(-12.6001, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6222, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4653, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 66\n",
            "Loss:  tensor(-12.9485, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6374, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4376, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 67\n",
            "Loss:  tensor(-12.7731, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6286, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 68\n",
            "Loss:  tensor(-11.7865, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5799, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 69\n",
            "Loss:  tensor(-12.9907, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6386, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 70\n",
            "Loss:  tensor(-12.9744, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4320, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 71\n",
            "Loss:  tensor(-12.3353, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4319, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 72\n",
            "Loss:  tensor(-13.0070, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6379, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 73\n",
            "Loss:  tensor(-12.4385, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 74\n",
            "Loss:  tensor(-12.6169, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6200, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  14 Batch: 75\n",
            "Loss:  tensor(-13.0337, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6433, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4751, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 0\n",
            "Loss:  tensor(-12.7224, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4439, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 1\n",
            "Loss:  tensor(-12.6948, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6225, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 2\n",
            "Loss:  tensor(-13.0798, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6415, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 3\n",
            "Loss:  tensor(-13.0184, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6418, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4587, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 4\n",
            "Loss:  tensor(-12.6902, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6239, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 5\n",
            "Loss:  tensor(-12.7941, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6305, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4473, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 6\n",
            "Loss:  tensor(-12.9874, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3779, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 7\n",
            "Loss:  tensor(-12.7504, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6279, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4362, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 8\n",
            "Loss:  tensor(-12.6840, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6225, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 9\n",
            "Loss:  tensor(-12.3758, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 10\n",
            "Loss:  tensor(-12.8373, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6300, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3934, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 11\n",
            "Loss:  tensor(-12.9664, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6344, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3560, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 12\n",
            "Loss:  tensor(-12.6140, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 13\n",
            "Loss:  tensor(-12.5759, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 14\n",
            "Loss:  tensor(-12.2137, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 15\n",
            "Loss:  tensor(-12.1428, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 16\n",
            "Loss:  tensor(-13.0839, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6421, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 17\n",
            "Loss:  tensor(-12.8423, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6315, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 18\n",
            "Loss:  tensor(-12.8595, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6311, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 19\n",
            "Loss:  tensor(-12.8559, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 20\n",
            "Loss:  tensor(-12.6309, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 21\n",
            "Loss:  tensor(-12.4556, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 22\n",
            "Loss:  tensor(-12.3022, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6067, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4388, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 23\n",
            "Loss:  tensor(-13.2088, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 24\n",
            "Loss:  tensor(-12.3619, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4242, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 25\n",
            "Loss:  tensor(-12.3631, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6067, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 26\n",
            "Loss:  tensor(-13.0778, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6417, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 27\n",
            "Loss:  tensor(-12.6303, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6208, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 28\n",
            "Loss:  tensor(-12.9527, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6365, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 29\n",
            "Loss:  tensor(-13.0258, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6386, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 30\n",
            "Loss:  tensor(-13.3717, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6556, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 31\n",
            "Loss:  tensor(-12.8022, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 32\n",
            "Loss:  tensor(-12.9486, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6351, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 33\n",
            "Loss:  tensor(-13.0778, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6404, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3716, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 34\n",
            "Loss:  tensor(-12.5791, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3667, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 35\n",
            "Loss:  tensor(-13.0941, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 36\n",
            "Loss:  tensor(-12.9709, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6360, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3851, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 37\n",
            "Loss:  tensor(-12.6583, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6211, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 38\n",
            "Loss:  tensor(-12.7824, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6271, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 39\n",
            "Loss:  tensor(-13.3488, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6540, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3844, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 40\n",
            "Loss:  tensor(-12.9597, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6379, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 41\n",
            "Loss:  tensor(-13.3353, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6518, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3520, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 42\n",
            "Loss:  tensor(-13.0125, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6393, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 43\n",
            "Loss:  tensor(-13.0405, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6413, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 44\n",
            "Loss:  tensor(-13.4426, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6601, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 45\n",
            "Loss:  tensor(-12.8795, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4013, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 46\n",
            "Loss:  tensor(-12.4997, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 47\n",
            "Loss:  tensor(-13.0098, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 48\n",
            "Loss:  tensor(-12.7839, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3734, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 49\n",
            "Loss:  tensor(-11.9069, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 50\n",
            "Loss:  tensor(-12.3330, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4508, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 51\n",
            "Loss:  tensor(-12.9880, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6383, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 52\n",
            "Loss:  tensor(-13.6264, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6669, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 53\n",
            "Loss:  tensor(-12.7411, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6262, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 54\n",
            "Loss:  tensor(-12.3726, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3784, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 55\n",
            "Loss:  tensor(-13.1244, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6424, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3669, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 56\n",
            "Loss:  tensor(-13.2658, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6518, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 57\n",
            "Loss:  tensor(-12.9648, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6355, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 58\n",
            "Loss:  tensor(-12.5356, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3665, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 59\n",
            "Loss:  tensor(-12.8242, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3796, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 60\n",
            "Loss:  tensor(-12.8470, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6310, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4033, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 61\n",
            "Loss:  tensor(-12.7855, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6273, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 62\n",
            "Loss:  tensor(-12.8294, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6309, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 63\n",
            "Loss:  tensor(-13.0499, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3677, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 64\n",
            "Loss:  tensor(-12.6548, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6217, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 65\n",
            "Loss:  tensor(-13.0255, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6385, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 66\n",
            "Loss:  tensor(-13.3250, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6523, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3727, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 67\n",
            "Loss:  tensor(-12.2644, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6035, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 68\n",
            "Loss:  tensor(-12.4735, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3844, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 69\n",
            "Loss:  tensor(-12.5407, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3779, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 70\n",
            "Loss:  tensor(-12.4253, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 71\n",
            "Loss:  tensor(-12.6170, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 72\n",
            "Loss:  tensor(-12.8118, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6302, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4214, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 73\n",
            "Loss:  tensor(-12.9925, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6363, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3704, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 74\n",
            "Loss:  tensor(-12.4323, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  15 Batch: 75\n",
            "Loss:  tensor(-13.2732, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 0\n",
            "Loss:  tensor(-12.5638, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 1\n",
            "Loss:  tensor(-12.3952, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 2\n",
            "Loss:  tensor(-12.7672, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3884, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 3\n",
            "Loss:  tensor(-12.4949, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 4\n",
            "Loss:  tensor(-13.0269, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6393, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 5\n",
            "Loss:  tensor(-12.7489, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 6\n",
            "Loss:  tensor(-12.1801, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 7\n",
            "Loss:  tensor(-12.7575, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6269, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 8\n",
            "Loss:  tensor(-12.7829, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6274, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 9\n",
            "Loss:  tensor(-12.2718, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3793, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 10\n",
            "Loss:  tensor(-12.6995, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4052, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 11\n",
            "Loss:  tensor(-12.5642, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4021, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 12\n",
            "Loss:  tensor(-12.7466, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4048, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 13\n",
            "Loss:  tensor(-12.6005, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3771, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 14\n",
            "Loss:  tensor(-12.4681, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3577, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 15\n",
            "Loss:  tensor(-12.5408, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3776, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 16\n",
            "Loss:  tensor(-12.8770, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6313, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3800, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 17\n",
            "Loss:  tensor(-12.4724, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 18\n",
            "Loss:  tensor(-11.9293, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 19\n",
            "Loss:  tensor(-12.1126, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3507, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 20\n",
            "Loss:  tensor(-12.7144, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6241, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 21\n",
            "Loss:  tensor(-12.3816, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 22\n",
            "Loss:  tensor(-11.9566, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4463, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 23\n",
            "Loss:  tensor(-12.6785, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6236, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 24\n",
            "Loss:  tensor(-12.4483, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 25\n",
            "Loss:  tensor(-12.4991, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 26\n",
            "Loss:  tensor(-13.1801, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6464, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 27\n",
            "Loss:  tensor(-12.9926, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3857, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 28\n",
            "Loss:  tensor(-12.7110, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 29\n",
            "Loss:  tensor(-12.6153, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4093, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 30\n",
            "Loss:  tensor(-13.2697, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6497, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3736, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 31\n",
            "Loss:  tensor(-12.8924, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6329, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3978, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 32\n",
            "Loss:  tensor(-13.2671, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6504, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 33\n",
            "Loss:  tensor(-12.7744, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6269, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 34\n",
            "Loss:  tensor(-13.1802, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6472, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 35\n",
            "Loss:  tensor(-11.9466, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4258, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 36\n",
            "Loss:  tensor(-13.0830, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6399, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3557, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 37\n",
            "Loss:  tensor(-12.7254, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6272, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4457, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 38\n",
            "Loss:  tensor(-13.1354, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6452, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 39\n",
            "Loss:  tensor(-12.4878, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4617, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 40\n",
            "Loss:  tensor(-13.1651, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6449, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3776, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 41\n",
            "Loss:  tensor(-12.9132, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6352, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 42\n",
            "Loss:  tensor(-13.0837, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4043, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 43\n",
            "Loss:  tensor(-12.7482, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6275, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 44\n",
            "Loss:  tensor(-13.1904, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6464, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3830, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 45\n",
            "Loss:  tensor(-12.9460, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4250, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 46\n",
            "Loss:  tensor(-12.8510, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 47\n",
            "Loss:  tensor(-12.9938, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3767, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 48\n",
            "Loss:  tensor(-13.0148, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6385, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 49\n",
            "Loss:  tensor(-12.7903, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6291, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4213, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 50\n",
            "Loss:  tensor(-12.8842, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 51\n",
            "Loss:  tensor(-12.5803, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 52\n",
            "Loss:  tensor(-13.2562, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6494, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3818, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 53\n",
            "Loss:  tensor(-13.1593, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6447, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3787, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 54\n",
            "Loss:  tensor(-12.3532, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3969, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 55\n",
            "Loss:  tensor(-13.4207, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3838, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 56\n",
            "Loss:  tensor(-13.1452, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6441, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 57\n",
            "Loss:  tensor(-12.9687, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6361, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 58\n",
            "Loss:  tensor(-12.5338, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4303, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 59\n",
            "Loss:  tensor(-13.0315, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6394, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 60\n",
            "Loss:  tensor(-12.6619, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6214, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3884, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 61\n",
            "Loss:  tensor(-12.8609, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3612, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 62\n",
            "Loss:  tensor(-12.9396, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6378, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4545, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 63\n",
            "Loss:  tensor(-11.8624, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4325, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 64\n",
            "Loss:  tensor(-13.0190, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6383, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3844, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 65\n",
            "Loss:  tensor(-13.2837, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6518, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4043, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 66\n",
            "Loss:  tensor(-12.7624, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6277, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 67\n",
            "Loss:  tensor(-12.4284, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 68\n",
            "Loss:  tensor(-13.2612, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6520, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4312, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 69\n",
            "Loss:  tensor(-12.9316, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6359, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4216, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 70\n",
            "Loss:  tensor(-12.7829, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3701, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 71\n",
            "Loss:  tensor(-12.7374, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6258, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 72\n",
            "Loss:  tensor(-12.8998, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 73\n",
            "Loss:  tensor(-13.4384, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6592, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 74\n",
            "Loss:  tensor(-13.2094, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6512, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4656, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  16 Batch: 75\n",
            "Loss:  tensor(-12.9617, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4451, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 0\n",
            "Loss:  tensor(-12.9202, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6334, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3815, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 1\n",
            "Loss:  tensor(-13.4013, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6587, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4315, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 2\n",
            "Loss:  tensor(-12.2996, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4454, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 3\n",
            "Loss:  tensor(-12.9667, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 4\n",
            "Loss:  tensor(-13.1445, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6447, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 5\n",
            "Loss:  tensor(-12.6494, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6230, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4330, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 6\n",
            "Loss:  tensor(-12.9481, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 7\n",
            "Loss:  tensor(-13.1769, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6466, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 8\n",
            "Loss:  tensor(-12.2114, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6006, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 9\n",
            "Loss:  tensor(-12.6736, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6229, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 10\n",
            "Loss:  tensor(-12.6443, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 11\n",
            "Loss:  tensor(-13.3404, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6533, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3793, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 12\n",
            "Loss:  tensor(-12.5991, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3778, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 13\n",
            "Loss:  tensor(-12.6661, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6245, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4486, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 14\n",
            "Loss:  tensor(-13.1831, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6467, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 15\n",
            "Loss:  tensor(-12.8348, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 16\n",
            "Loss:  tensor(-12.5134, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 17\n",
            "Loss:  tensor(-13.0081, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6388, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 18\n",
            "Loss:  tensor(-12.8887, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 19\n",
            "Loss:  tensor(-12.6279, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4061, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 20\n",
            "Loss:  tensor(-12.7289, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6261, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 21\n",
            "Loss:  tensor(-12.7101, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6248, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 22\n",
            "Loss:  tensor(-12.6458, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6218, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 23\n",
            "Loss:  tensor(-11.8825, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 24\n",
            "Loss:  tensor(-13.1131, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6432, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 25\n",
            "Loss:  tensor(-12.6133, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 26\n",
            "Loss:  tensor(-12.9097, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6355, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 27\n",
            "Loss:  tensor(-12.3182, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6064, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 28\n",
            "Loss:  tensor(-12.5613, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4261, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 29\n",
            "Loss:  tensor(-12.5487, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 30\n",
            "Loss:  tensor(-12.9692, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6375, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 31\n",
            "Loss:  tensor(-12.8574, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4017, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 32\n",
            "Loss:  tensor(-12.9365, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6347, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 33\n",
            "Loss:  tensor(-12.8364, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6289, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3706, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 34\n",
            "Loss:  tensor(-12.6998, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4234, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 35\n",
            "Loss:  tensor(-13.5910, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6663, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 36\n",
            "Loss:  tensor(-12.7491, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6274, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4258, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 37\n",
            "Loss:  tensor(-12.7488, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6269, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 38\n",
            "Loss:  tensor(-13.0148, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 39\n",
            "Loss:  tensor(-12.9229, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6336, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3827, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 40\n",
            "Loss:  tensor(-12.8628, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6338, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4470, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 41\n",
            "Loss:  tensor(-12.7957, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6291, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 42\n",
            "Loss:  tensor(-13.1589, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6456, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 43\n",
            "Loss:  tensor(-12.7054, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6257, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4335, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 44\n",
            "Loss:  tensor(-13.1054, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6436, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 45\n",
            "Loss:  tensor(-12.4829, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3665, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 46\n",
            "Loss:  tensor(-13.0924, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6446, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4442, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 47\n",
            "Loss:  tensor(-12.6345, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6222, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4311, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 48\n",
            "Loss:  tensor(-12.5224, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 49\n",
            "Loss:  tensor(-13.1180, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 50\n",
            "Loss:  tensor(-12.4447, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4615, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 51\n",
            "Loss:  tensor(-13.3023, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6517, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3830, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 52\n",
            "Loss:  tensor(-12.9227, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6345, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4011, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 53\n",
            "Loss:  tensor(-13.3845, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6578, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 54\n",
            "Loss:  tensor(-12.8716, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6311, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 55\n",
            "Loss:  tensor(-12.6671, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6219, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 56\n",
            "Loss:  tensor(-12.3690, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 57\n",
            "Loss:  tensor(-12.8440, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4355, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 58\n",
            "Loss:  tensor(-13.1866, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6475, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 59\n",
            "Loss:  tensor(-12.7596, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6271, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 60\n",
            "Loss:  tensor(-12.8488, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3663, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 61\n",
            "Loss:  tensor(-12.3825, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 62\n",
            "Loss:  tensor(-12.7975, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6302, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 63\n",
            "Loss:  tensor(-12.9925, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3721, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 64\n",
            "Loss:  tensor(-13.0713, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6431, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 65\n",
            "Loss:  tensor(-12.9132, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3643, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 66\n",
            "Loss:  tensor(-13.1795, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6466, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 67\n",
            "Loss:  tensor(-12.8685, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6317, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 68\n",
            "Loss:  tensor(-13.1809, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6450, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3636, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 69\n",
            "Loss:  tensor(-12.4243, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 70\n",
            "Loss:  tensor(-13.0492, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6396, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 71\n",
            "Loss:  tensor(-13.6826, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6722, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 72\n",
            "Loss:  tensor(-12.5478, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 73\n",
            "Loss:  tensor(-13.1737, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6479, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 74\n",
            "Loss:  tensor(-12.9539, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3628, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  17 Batch: 75\n",
            "Loss:  tensor(-12.4259, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 0\n",
            "Loss:  tensor(-12.8793, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4398, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 1\n",
            "Loss:  tensor(-12.3897, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6091, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4016, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 2\n",
            "Loss:  tensor(-13.3576, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6543, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 3\n",
            "Loss:  tensor(-12.4132, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 4\n",
            "Loss:  tensor(-12.3274, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4369, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 5\n",
            "Loss:  tensor(-12.9599, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 6\n",
            "Loss:  tensor(-12.9127, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6321, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3620, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 7\n",
            "Loss:  tensor(-13.1246, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6437, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3941, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 8\n",
            "Loss:  tensor(-13.2703, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6514, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 9\n",
            "Loss:  tensor(-12.7480, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3754, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 10\n",
            "Loss:  tensor(-12.6132, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4009, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 11\n",
            "Loss:  tensor(-12.9905, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6391, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4315, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 12\n",
            "Loss:  tensor(-13.3193, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6519, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3700, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 13\n",
            "Loss:  tensor(-13.0728, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6415, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 14\n",
            "Loss:  tensor(-12.6514, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6232, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4362, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 15\n",
            "Loss:  tensor(-12.5956, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3638, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 16\n",
            "Loss:  tensor(-12.7846, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6269, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3798, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 17\n",
            "Loss:  tensor(-12.8699, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4286, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 18\n",
            "Loss:  tensor(-13.4297, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6590, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 19\n",
            "Loss:  tensor(-13.2111, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4041, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 20\n",
            "Loss:  tensor(-12.8825, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6329, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 21\n",
            "Loss:  tensor(-13.0542, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6401, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 22\n",
            "Loss:  tensor(-12.7933, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 23\n",
            "Loss:  tensor(-12.7761, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6291, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 24\n",
            "Loss:  tensor(-13.1629, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6473, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4310, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 25\n",
            "Loss:  tensor(-12.8875, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4548, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 26\n",
            "Loss:  tensor(-12.7969, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6300, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4330, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 27\n",
            "Loss:  tensor(-12.2101, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 28\n",
            "Loss:  tensor(-12.8951, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6339, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 29\n",
            "Loss:  tensor(-12.6740, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 30\n",
            "Loss:  tensor(-12.9267, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 31\n",
            "Loss:  tensor(-12.7194, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6266, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4383, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 32\n",
            "Loss:  tensor(-13.0053, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6394, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4227, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 33\n",
            "Loss:  tensor(-12.3805, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 34\n",
            "Loss:  tensor(-12.9949, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6390, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4237, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 35\n",
            "Loss:  tensor(-12.6764, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6230, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 36\n",
            "Loss:  tensor(-12.7739, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6285, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4253, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 37\n",
            "Loss:  tensor(-12.9651, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6382, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4370, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 38\n",
            "Loss:  tensor(-13.2246, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6497, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 39\n",
            "Loss:  tensor(-12.8733, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6338, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4369, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 40\n",
            "Loss:  tensor(-12.6659, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6237, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 41\n",
            "Loss:  tensor(-13.3919, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 42\n",
            "Loss:  tensor(-12.8523, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6307, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 43\n",
            "Loss:  tensor(-13.1729, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6468, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 44\n",
            "Loss:  tensor(-12.9971, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6398, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4378, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 45\n",
            "Loss:  tensor(-12.8828, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 46\n",
            "Loss:  tensor(-13.1253, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6446, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 47\n",
            "Loss:  tensor(-13.2339, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6505, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4257, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 48\n",
            "Loss:  tensor(-12.6443, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6208, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 49\n",
            "Loss:  tensor(-12.9711, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6382, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4308, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 50\n",
            "Loss:  tensor(-12.9060, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6349, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4272, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 51\n",
            "Loss:  tensor(-13.3270, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6536, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 52\n",
            "Loss:  tensor(-12.7741, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6259, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3691, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 53\n",
            "Loss:  tensor(-12.3118, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4200, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 54\n",
            "Loss:  tensor(-12.9732, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6377, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 55\n",
            "Loss:  tensor(-12.8460, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4329, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 56\n",
            "Loss:  tensor(-12.4856, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 57\n",
            "Loss:  tensor(-12.6014, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 58\n",
            "Loss:  tensor(-13.0940, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6443, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 59\n",
            "Loss:  tensor(-11.7958, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4055, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 60\n",
            "Loss:  tensor(-12.7256, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 61\n",
            "Loss:  tensor(-12.4955, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 62\n",
            "Loss:  tensor(-13.0430, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6403, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4042, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 63\n",
            "Loss:  tensor(-12.5347, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4478, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 64\n",
            "Loss:  tensor(-12.7276, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6267, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4322, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 65\n",
            "Loss:  tensor(-13.1725, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6467, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4091, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 66\n",
            "Loss:  tensor(-13.0596, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6410, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 67\n",
            "Loss:  tensor(-12.9113, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4060, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 68\n",
            "Loss:  tensor(-12.3448, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4392, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 69\n",
            "Loss:  tensor(-12.7792, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4424, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 70\n",
            "Loss:  tensor(-13.3611, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6539, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3711, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 71\n",
            "Loss:  tensor(-13.2664, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6494, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3706, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 72\n",
            "Loss:  tensor(-12.7289, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 73\n",
            "Loss:  tensor(-12.9627, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6375, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4258, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 74\n",
            "Loss:  tensor(-13.3517, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6558, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  18 Batch: 75\n",
            "Loss:  tensor(-12.8165, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 0\n",
            "Loss:  tensor(-13.0190, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6396, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 1\n",
            "Loss:  tensor(-13.2459, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6473, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 2\n",
            "Loss:  tensor(-13.0259, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6378, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3688, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 3\n",
            "Loss:  tensor(-13.3144, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6530, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 4\n",
            "Loss:  tensor(-13.6185, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6678, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4049, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 5\n",
            "Loss:  tensor(-12.8222, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4043, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 6\n",
            "Loss:  tensor(-13.0569, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6410, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4042, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 7\n",
            "Loss:  tensor(-12.6838, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6229, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 8\n",
            "Loss:  tensor(-12.6907, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3987, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 9\n",
            "Loss:  tensor(-12.8486, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6305, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 10\n",
            "Loss:  tensor(-12.9532, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 11\n",
            "Loss:  tensor(-12.8664, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3921, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 12\n",
            "Loss:  tensor(-13.4620, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6597, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 13\n",
            "Loss:  tensor(-12.4879, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 14\n",
            "Loss:  tensor(-12.8381, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6295, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 15\n",
            "Loss:  tensor(-13.1865, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 16\n",
            "Loss:  tensor(-13.5065, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6612, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 17\n",
            "Loss:  tensor(-12.8664, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6316, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 18\n",
            "Loss:  tensor(-12.4676, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 19\n",
            "Loss:  tensor(-12.8743, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 20\n",
            "Loss:  tensor(-12.8915, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 21\n",
            "Loss:  tensor(-13.1620, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6442, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3669, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 22\n",
            "Loss:  tensor(-12.9503, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6362, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 23\n",
            "Loss:  tensor(-13.1501, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6443, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 24\n",
            "Loss:  tensor(-12.7433, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6251, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3841, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 25\n",
            "Loss:  tensor(-13.1743, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6450, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3700, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 26\n",
            "Loss:  tensor(-13.0567, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6413, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 27\n",
            "Loss:  tensor(-13.1859, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6491, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4447, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 28\n",
            "Loss:  tensor(-12.6833, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 29\n",
            "Loss:  tensor(-12.5460, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 30\n",
            "Loss:  tensor(-12.4219, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 31\n",
            "Loss:  tensor(-13.2932, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6503, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 32\n",
            "Loss:  tensor(-12.5669, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 33\n",
            "Loss:  tensor(-12.8788, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 34\n",
            "Loss:  tensor(-12.7788, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6254, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3538, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 35\n",
            "Loss:  tensor(-12.4318, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3727, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 36\n",
            "Loss:  tensor(-13.0866, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6416, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 37\n",
            "Loss:  tensor(-12.8816, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 38\n",
            "Loss:  tensor(-13.2769, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6519, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 39\n",
            "Loss:  tensor(-12.7220, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3678, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 40\n",
            "Loss:  tensor(-12.5269, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3598, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 41\n",
            "Loss:  tensor(-12.6274, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 42\n",
            "Loss:  tensor(-12.9616, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6365, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4041, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 43\n",
            "Loss:  tensor(-13.1251, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6429, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3763, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 44\n",
            "Loss:  tensor(-12.8412, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6304, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 45\n",
            "Loss:  tensor(-12.8573, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6297, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3671, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 46\n",
            "Loss:  tensor(-12.6882, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3809, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 47\n",
            "Loss:  tensor(-12.6609, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 48\n",
            "Loss:  tensor(-12.2335, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 49\n",
            "Loss:  tensor(-13.0235, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6386, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 50\n",
            "Loss:  tensor(-12.5349, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 51\n",
            "Loss:  tensor(-13.3990, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6563, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3834, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 52\n",
            "Loss:  tensor(-13.4956, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 53\n",
            "Loss:  tensor(-12.7430, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6256, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 54\n",
            "Loss:  tensor(-13.0587, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4011, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 55\n",
            "Loss:  tensor(-12.8937, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3867, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 56\n",
            "Loss:  tensor(-12.2593, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6002, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3450, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 57\n",
            "Loss:  tensor(-12.9411, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 58\n",
            "Loss:  tensor(-12.5870, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 59\n",
            "Loss:  tensor(-12.8965, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4028, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 60\n",
            "Loss:  tensor(-12.9885, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6361, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3690, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 61\n",
            "Loss:  tensor(-12.8228, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 62\n",
            "Loss:  tensor(-12.8128, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6275, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3652, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 63\n",
            "Loss:  tensor(-13.0577, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6397, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3751, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 64\n",
            "Loss:  tensor(-12.5743, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4242, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 65\n",
            "Loss:  tensor(-12.4094, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 66\n",
            "Loss:  tensor(-12.3666, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 67\n",
            "Loss:  tensor(-12.7564, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 68\n",
            "Loss:  tensor(-12.9895, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6369, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 69\n",
            "Loss:  tensor(-12.8785, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6328, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 70\n",
            "Loss:  tensor(-12.6453, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 71\n",
            "Loss:  tensor(-12.1397, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3764, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 72\n",
            "Loss:  tensor(-13.0622, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 73\n",
            "Loss:  tensor(-11.9578, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 74\n",
            "Loss:  tensor(-13.0349, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6403, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  19 Batch: 75\n",
            "Loss:  tensor(-13.1133, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 0\n",
            "Loss:  tensor(-12.8810, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6338, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4280, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 1\n",
            "Loss:  tensor(-13.2309, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6491, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 2\n",
            "Loss:  tensor(-12.7612, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6261, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 3\n",
            "Loss:  tensor(-12.4586, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 4\n",
            "Loss:  tensor(-12.6721, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6218, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3867, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 5\n",
            "Loss:  tensor(-12.9931, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 6\n",
            "Loss:  tensor(-12.9480, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6355, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 7\n",
            "Loss:  tensor(-12.8997, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3588, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 8\n",
            "Loss:  tensor(-12.6930, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6224, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 9\n",
            "Loss:  tensor(-12.2426, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 10\n",
            "Loss:  tensor(-12.4214, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 11\n",
            "Loss:  tensor(-12.7445, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6254, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 12\n",
            "Loss:  tensor(-12.7993, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 13\n",
            "Loss:  tensor(-12.6153, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 14\n",
            "Loss:  tensor(-12.8373, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3712, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 15\n",
            "Loss:  tensor(-12.5609, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 16\n",
            "Loss:  tensor(-12.9115, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6329, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3800, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 17\n",
            "Loss:  tensor(-13.2960, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6524, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 18\n",
            "Loss:  tensor(-12.2190, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6011, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 19\n",
            "Loss:  tensor(-13.2166, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6472, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3752, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 20\n",
            "Loss:  tensor(-13.3332, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6529, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3781, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 21\n",
            "Loss:  tensor(-13.2816, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6493, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3543, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 22\n",
            "Loss:  tensor(-12.7449, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6243, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3653, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 23\n",
            "Loss:  tensor(-12.7255, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6266, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 24\n",
            "Loss:  tensor(-12.9007, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6302, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3344, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 25\n",
            "Loss:  tensor(-12.8045, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6282, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 26\n",
            "Loss:  tensor(-12.7969, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6269, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3674, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 27\n",
            "Loss:  tensor(-13.3391, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6531, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3765, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 28\n",
            "Loss:  tensor(-13.1805, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6440, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3434, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 29\n",
            "Loss:  tensor(-12.6542, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3799, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 30\n",
            "Loss:  tensor(-13.0934, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3660, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 31\n",
            "Loss:  tensor(-13.2028, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 32\n",
            "Loss:  tensor(-12.9358, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6346, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3917, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 33\n",
            "Loss:  tensor(-13.0447, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6403, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 34\n",
            "Loss:  tensor(-12.9906, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3512, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 35\n",
            "Loss:  tensor(-12.8075, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 36\n",
            "Loss:  tensor(-13.1521, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6462, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 37\n",
            "Loss:  tensor(-13.2781, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3724, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 38\n",
            "Loss:  tensor(-12.6664, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 39\n",
            "Loss:  tensor(-13.5110, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6597, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3429, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 40\n",
            "Loss:  tensor(-12.6990, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6224, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3705, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 41\n",
            "Loss:  tensor(-12.5688, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 42\n",
            "Loss:  tensor(-12.6987, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6234, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 43\n",
            "Loss:  tensor(-12.4732, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3847, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 44\n",
            "Loss:  tensor(-12.2281, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3833, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 45\n",
            "Loss:  tensor(-12.6288, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 46\n",
            "Loss:  tensor(-13.1111, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6430, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 47\n",
            "Loss:  tensor(-13.0953, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3707, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 48\n",
            "Loss:  tensor(-13.1680, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6480, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4395, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 49\n",
            "Loss:  tensor(-13.3039, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6532, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 50\n",
            "Loss:  tensor(-13.0386, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6398, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 51\n",
            "Loss:  tensor(-12.6419, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6208, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 52\n",
            "Loss:  tensor(-12.9219, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 53\n",
            "Loss:  tensor(-12.7233, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6236, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 54\n",
            "Loss:  tensor(-13.0822, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6429, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 55\n",
            "Loss:  tensor(-13.2829, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6511, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 56\n",
            "Loss:  tensor(-12.7482, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3813, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 57\n",
            "Loss:  tensor(-12.1169, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4347, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 58\n",
            "Loss:  tensor(-12.4773, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 59\n",
            "Loss:  tensor(-12.7848, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6283, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 60\n",
            "Loss:  tensor(-12.6184, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3744, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 61\n",
            "Loss:  tensor(-12.7560, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6272, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 62\n",
            "Loss:  tensor(-12.8253, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6280, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3621, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 63\n",
            "Loss:  tensor(-12.8969, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6315, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3644, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 64\n",
            "Loss:  tensor(-12.9937, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6358, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3585, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 65\n",
            "Loss:  tensor(-12.9801, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6379, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 66\n",
            "Loss:  tensor(-12.8804, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6307, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 67\n",
            "Loss:  tensor(-13.2785, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6484, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3373, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 68\n",
            "Loss:  tensor(-12.9766, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6369, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 69\n",
            "Loss:  tensor(-12.9420, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3571, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 70\n",
            "Loss:  tensor(-12.8589, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6307, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3867, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 71\n",
            "Loss:  tensor(-12.7518, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6251, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3761, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 72\n",
            "Loss:  tensor(-13.1123, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 73\n",
            "Loss:  tensor(-12.6948, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6227, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 74\n",
            "Loss:  tensor(-12.5703, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  20 Batch: 75\n",
            "Loss:  tensor(-12.7402, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3592, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 0\n",
            "Loss:  tensor(-13.1532, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6439, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3690, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 1\n",
            "Loss:  tensor(-12.9226, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6319, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 2\n",
            "Loss:  tensor(-12.7632, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6262, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 3\n",
            "Loss:  tensor(-12.8694, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6289, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3365, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 4\n",
            "Loss:  tensor(-13.3925, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6552, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3657, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 5\n",
            "Loss:  tensor(-12.8971, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6317, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3678, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 6\n",
            "Loss:  tensor(-12.6431, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 7\n",
            "Loss:  tensor(-12.7813, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6251, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3455, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 8\n",
            "Loss:  tensor(-12.9829, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6358, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3680, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 9\n",
            "Loss:  tensor(-12.8086, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6274, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3661, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 10\n",
            "Loss:  tensor(-12.9213, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 11\n",
            "Loss:  tensor(-12.9444, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 12\n",
            "Loss:  tensor(-13.0494, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6377, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3429, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 13\n",
            "Loss:  tensor(-12.7590, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6272, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 14\n",
            "Loss:  tensor(-13.4028, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6565, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3828, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 15\n",
            "Loss:  tensor(-12.4336, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 16\n",
            "Loss:  tensor(-13.5328, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6619, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3677, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 17\n",
            "Loss:  tensor(-13.3775, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6541, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3593, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 18\n",
            "Loss:  tensor(-12.5386, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3492, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 19\n",
            "Loss:  tensor(-13.0059, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3639, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 20\n",
            "Loss:  tensor(-12.4475, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6091, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3442, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 21\n",
            "Loss:  tensor(-12.9327, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6322, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3441, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 22\n",
            "Loss:  tensor(-12.8549, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6306, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 23\n",
            "Loss:  tensor(-12.9471, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 24\n",
            "Loss:  tensor(-12.6223, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6198, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 25\n",
            "Loss:  tensor(-12.3889, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 26\n",
            "Loss:  tensor(-12.5514, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 27\n",
            "Loss:  tensor(-12.6160, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 28\n",
            "Loss:  tensor(-12.3344, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 29\n",
            "Loss:  tensor(-12.9958, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 30\n",
            "Loss:  tensor(-12.8836, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3851, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 31\n",
            "Loss:  tensor(-13.2445, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3688, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 32\n",
            "Loss:  tensor(-13.0361, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6374, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3492, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 33\n",
            "Loss:  tensor(-13.1491, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6437, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3686, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 34\n",
            "Loss:  tensor(-12.9142, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3712, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 35\n",
            "Loss:  tensor(-12.5622, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 36\n",
            "Loss:  tensor(-12.9744, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6375, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 37\n",
            "Loss:  tensor(-12.9562, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6335, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3467, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 38\n",
            "Loss:  tensor(-13.2252, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6468, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 39\n",
            "Loss:  tensor(-13.4598, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6576, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 40\n",
            "Loss:  tensor(-12.7393, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6237, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3583, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 41\n",
            "Loss:  tensor(-12.6714, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3630, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 42\n",
            "Loss:  tensor(-13.1342, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6436, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3825, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 43\n",
            "Loss:  tensor(-12.9194, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6320, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3534, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 44\n",
            "Loss:  tensor(-12.5346, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3248, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 45\n",
            "Loss:  tensor(-12.9697, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6351, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3672, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 46\n",
            "Loss:  tensor(-13.1884, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6465, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3887, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 47\n",
            "Loss:  tensor(-12.6935, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6226, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 48\n",
            "Loss:  tensor(-12.7723, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6246, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3452, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 49\n",
            "Loss:  tensor(-13.0741, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6395, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3556, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 50\n",
            "Loss:  tensor(-13.0598, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3567, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 51\n",
            "Loss:  tensor(-13.2015, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6451, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3446, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 52\n",
            "Loss:  tensor(-12.5226, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3564, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 53\n",
            "Loss:  tensor(-12.7864, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6259, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3581, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 54\n",
            "Loss:  tensor(-13.1518, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6432, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3549, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 55\n",
            "Loss:  tensor(-13.1538, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3396, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 56\n",
            "Loss:  tensor(-13.0193, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3540, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 57\n",
            "Loss:  tensor(-13.1237, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6413, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3427, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 58\n",
            "Loss:  tensor(-13.1012, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6404, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3480, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 59\n",
            "Loss:  tensor(-12.7627, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 60\n",
            "Loss:  tensor(-12.9805, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6345, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3433, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 61\n",
            "Loss:  tensor(-13.2685, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6494, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3683, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 62\n",
            "Loss:  tensor(-12.7183, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3501, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 63\n",
            "Loss:  tensor(-13.1210, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6390, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 64\n",
            "Loss:  tensor(-12.6610, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3701, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 65\n",
            "Loss:  tensor(-12.7294, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3592, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 66\n",
            "Loss:  tensor(-11.9770, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3518, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 67\n",
            "Loss:  tensor(-12.7515, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6208, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2862, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 68\n",
            "Loss:  tensor(-12.8897, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6303, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3471, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 69\n",
            "Loss:  tensor(-12.7594, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6243, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3509, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 70\n",
            "Loss:  tensor(-12.5360, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3484, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 71\n",
            "Loss:  tensor(-12.8338, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 72\n",
            "Loss:  tensor(-12.6532, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 73\n",
            "Loss:  tensor(-13.0655, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 74\n",
            "Loss:  tensor(-12.7668, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3467, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  21 Batch: 75\n",
            "Loss:  tensor(-12.5235, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3590, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 0\n",
            "Loss:  tensor(-13.0229, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3554, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 1\n",
            "Loss:  tensor(-12.9653, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6360, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 2\n",
            "Loss:  tensor(-12.8132, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 3\n",
            "Loss:  tensor(-13.0296, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6383, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3743, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 4\n",
            "Loss:  tensor(-12.4137, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3429, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 5\n",
            "Loss:  tensor(-11.9754, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3644, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 6\n",
            "Loss:  tensor(-11.9390, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4009, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 7\n",
            "Loss:  tensor(-12.3113, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3542, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 8\n",
            "Loss:  tensor(-12.9805, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6370, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 9\n",
            "Loss:  tensor(-13.2203, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6460, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3460, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 10\n",
            "Loss:  tensor(-12.5116, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 11\n",
            "Loss:  tensor(-13.1652, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6464, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 12\n",
            "Loss:  tensor(-13.2510, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6495, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3890, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 13\n",
            "Loss:  tensor(-13.2339, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6488, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3915, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 14\n",
            "Loss:  tensor(-12.5767, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3683, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 15\n",
            "Loss:  tensor(-12.8783, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 16\n",
            "Loss:  tensor(-13.1434, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6453, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4087, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 17\n",
            "Loss:  tensor(-12.4768, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4025, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 18\n",
            "Loss:  tensor(-13.2358, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6480, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3713, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 19\n",
            "Loss:  tensor(-12.5893, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 20\n",
            "Loss:  tensor(-12.6743, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6248, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4458, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 21\n",
            "Loss:  tensor(-12.7905, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6294, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4266, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 22\n",
            "Loss:  tensor(-12.9592, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6370, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 23\n",
            "Loss:  tensor(-12.8103, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6306, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4329, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 24\n",
            "Loss:  tensor(-13.3106, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6516, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3729, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 25\n",
            "Loss:  tensor(-13.1945, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6487, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 26\n",
            "Loss:  tensor(-13.1508, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6460, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 27\n",
            "Loss:  tensor(-13.1551, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6457, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4052, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 28\n",
            "Loss:  tensor(-12.9364, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6363, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4250, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 29\n",
            "Loss:  tensor(-12.7739, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 30\n",
            "Loss:  tensor(-13.2748, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3540, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 31\n",
            "Loss:  tensor(-12.6997, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6242, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4093, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 32\n",
            "Loss:  tensor(-12.8761, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6305, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3641, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 33\n",
            "Loss:  tensor(-12.7423, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 34\n",
            "Loss:  tensor(-13.3189, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6527, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3887, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 35\n",
            "Loss:  tensor(-12.9173, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6337, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 36\n",
            "Loss:  tensor(-13.2049, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6504, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4545, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 37\n",
            "Loss:  tensor(-12.9164, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4255, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 38\n",
            "Loss:  tensor(-13.3028, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6515, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 39\n",
            "Loss:  tensor(-13.4649, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6599, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 40\n",
            "Loss:  tensor(-12.8518, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6295, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3674, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 41\n",
            "Loss:  tensor(-13.0532, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6413, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 42\n",
            "Loss:  tensor(-13.2317, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4219, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 43\n",
            "Loss:  tensor(-12.8680, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 44\n",
            "Loss:  tensor(-13.0123, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6387, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3998, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 45\n",
            "Loss:  tensor(-12.5662, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4002, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 46\n",
            "Loss:  tensor(-13.1677, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6454, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 47\n",
            "Loss:  tensor(-12.4158, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4506, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 48\n",
            "Loss:  tensor(-12.6725, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6236, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4224, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 49\n",
            "Loss:  tensor(-12.6068, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 50\n",
            "Loss:  tensor(-12.9878, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6381, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 51\n",
            "Loss:  tensor(-13.5378, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 52\n",
            "Loss:  tensor(-12.8803, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6334, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 53\n",
            "Loss:  tensor(-12.8871, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 54\n",
            "Loss:  tensor(-13.2546, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6509, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 55\n",
            "Loss:  tensor(-12.6648, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6215, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 56\n",
            "Loss:  tensor(-12.2964, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6049, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4060, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 57\n",
            "Loss:  tensor(-12.8178, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3723, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 58\n",
            "Loss:  tensor(-13.0642, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 59\n",
            "Loss:  tensor(-13.2519, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6492, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 60\n",
            "Loss:  tensor(-13.1202, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6427, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 61\n",
            "Loss:  tensor(-12.7800, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 62\n",
            "Loss:  tensor(-12.8644, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3444, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 63\n",
            "Loss:  tensor(-12.5717, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4033, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 64\n",
            "Loss:  tensor(-12.3395, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3804, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 65\n",
            "Loss:  tensor(-12.8293, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6294, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 66\n",
            "Loss:  tensor(-12.8912, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6325, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 67\n",
            "Loss:  tensor(-12.6128, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 68\n",
            "Loss:  tensor(-12.7830, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6255, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3527, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 69\n",
            "Loss:  tensor(-12.8869, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6309, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3610, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 70\n",
            "Loss:  tensor(-12.9665, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6347, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3614, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 71\n",
            "Loss:  tensor(-13.1355, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6442, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 72\n",
            "Loss:  tensor(-13.0093, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6343, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 73\n",
            "Loss:  tensor(-13.1963, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6463, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3754, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 74\n",
            "Loss:  tensor(-13.3029, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3507, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  22 Batch: 75\n",
            "Loss:  tensor(-12.4625, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 0\n",
            "Loss:  tensor(-12.5923, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3571, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 1\n",
            "Loss:  tensor(-13.2442, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6474, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3510, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 2\n",
            "Loss:  tensor(-13.0271, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6394, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3998, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 3\n",
            "Loss:  tensor(-12.3106, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6055, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 4\n",
            "Loss:  tensor(-12.7352, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 5\n",
            "Loss:  tensor(-12.7430, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6247, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3760, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 6\n",
            "Loss:  tensor(-12.2880, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 7\n",
            "Loss:  tensor(-13.2070, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6455, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3492, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 8\n",
            "Loss:  tensor(-13.0818, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3843, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 9\n",
            "Loss:  tensor(-12.9583, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4198, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 10\n",
            "Loss:  tensor(-13.1559, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6438, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 11\n",
            "Loss:  tensor(-12.9957, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3385, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 12\n",
            "Loss:  tensor(-12.8194, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6279, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3657, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 13\n",
            "Loss:  tensor(-12.8346, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6295, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3840, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 14\n",
            "Loss:  tensor(-12.8833, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 15\n",
            "Loss:  tensor(-12.4774, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 16\n",
            "Loss:  tensor(-12.7472, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3536, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 17\n",
            "Loss:  tensor(-12.9182, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6345, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 18\n",
            "Loss:  tensor(-12.6658, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6211, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 19\n",
            "Loss:  tensor(-12.9426, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3438, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 20\n",
            "Loss:  tensor(-12.7598, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3449, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 21\n",
            "Loss:  tensor(-13.3878, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6558, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 22\n",
            "Loss:  tensor(-13.1890, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6462, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 23\n",
            "Loss:  tensor(-13.4146, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6555, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3507, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 24\n",
            "Loss:  tensor(-13.1410, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6430, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3616, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 25\n",
            "Loss:  tensor(-12.8107, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6277, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 26\n",
            "Loss:  tensor(-12.7152, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6248, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 27\n",
            "Loss:  tensor(-12.8900, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6297, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3336, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 28\n",
            "Loss:  tensor(-12.8587, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6304, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3788, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 29\n",
            "Loss:  tensor(-12.7896, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6283, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 30\n",
            "Loss:  tensor(-12.7112, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6219, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3495, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 31\n",
            "Loss:  tensor(-12.1684, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3557, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 32\n",
            "Loss:  tensor(-13.1805, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6463, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 33\n",
            "Loss:  tensor(-12.3863, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3859, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 34\n",
            "Loss:  tensor(-12.5256, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 35\n",
            "Loss:  tensor(-13.0584, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6395, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3717, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 36\n",
            "Loss:  tensor(-12.7262, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6246, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 37\n",
            "Loss:  tensor(-12.6341, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3519, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 38\n",
            "Loss:  tensor(-12.8050, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 39\n",
            "Loss:  tensor(-13.2466, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6486, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3748, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 40\n",
            "Loss:  tensor(-13.6359, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6674, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3797, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 41\n",
            "Loss:  tensor(-13.0064, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 42\n",
            "Loss:  tensor(-12.9204, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 43\n",
            "Loss:  tensor(-13.2962, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6510, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3746, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 44\n",
            "Loss:  tensor(-12.7524, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6239, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3503, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 45\n",
            "Loss:  tensor(-13.1757, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6462, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 46\n",
            "Loss:  tensor(-13.0936, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 47\n",
            "Loss:  tensor(-13.0220, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6392, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 48\n",
            "Loss:  tensor(-12.7223, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3773, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 49\n",
            "Loss:  tensor(-12.8912, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6322, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 50\n",
            "Loss:  tensor(-12.7230, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3619, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 51\n",
            "Loss:  tensor(-12.6400, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6211, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4026, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 52\n",
            "Loss:  tensor(-12.8590, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 53\n",
            "Loss:  tensor(-13.5296, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 54\n",
            "Loss:  tensor(-13.2175, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6473, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3767, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 55\n",
            "Loss:  tensor(-12.4737, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 56\n",
            "Loss:  tensor(-12.9353, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3997, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 57\n",
            "Loss:  tensor(-12.8479, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6295, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3720, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 58\n",
            "Loss:  tensor(-12.8874, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6328, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 59\n",
            "Loss:  tensor(-12.6546, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6198, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3619, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 60\n",
            "Loss:  tensor(-13.1536, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6454, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 61\n",
            "Loss:  tensor(-12.4731, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3691, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 62\n",
            "Loss:  tensor(-13.7319, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6714, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3685, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 63\n",
            "Loss:  tensor(-13.2916, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6508, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 64\n",
            "Loss:  tensor(-12.8619, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6311, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3921, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 65\n",
            "Loss:  tensor(-12.4557, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 66\n",
            "Loss:  tensor(-13.2275, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6497, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 67\n",
            "Loss:  tensor(-12.0267, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 68\n",
            "Loss:  tensor(-13.2379, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6495, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4026, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 69\n",
            "Loss:  tensor(-13.2803, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3748, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 70\n",
            "Loss:  tensor(-12.3851, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3890, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 71\n",
            "Loss:  tensor(-13.3297, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6523, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3696, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 72\n",
            "Loss:  tensor(-12.9859, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6375, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 73\n",
            "Loss:  tensor(-13.2033, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3809, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 74\n",
            "Loss:  tensor(-13.4168, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3877, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  23 Batch: 75\n",
            "Loss:  tensor(-12.7610, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6272, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 0\n",
            "Loss:  tensor(-12.9389, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3383, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 1\n",
            "Loss:  tensor(-12.5827, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6185, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 2\n",
            "Loss:  tensor(-12.9962, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6398, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4396, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 3\n",
            "Loss:  tensor(-12.9703, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6348, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3608, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 4\n",
            "Loss:  tensor(-13.0081, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6359, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3464, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 5\n",
            "Loss:  tensor(-12.9932, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6376, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 6\n",
            "Loss:  tensor(-12.6155, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 7\n",
            "Loss:  tensor(-12.4001, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4340, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 8\n",
            "Loss:  tensor(-13.1151, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6410, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3465, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 9\n",
            "Loss:  tensor(-12.6227, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4009, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 10\n",
            "Loss:  tensor(-12.7901, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 11\n",
            "Loss:  tensor(-12.8365, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6285, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3627, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 12\n",
            "Loss:  tensor(-12.6597, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3759, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 13\n",
            "Loss:  tensor(-12.7521, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 14\n",
            "Loss:  tensor(-13.0608, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3985, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 15\n",
            "Loss:  tensor(-12.7690, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 16\n",
            "Loss:  tensor(-13.1644, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6451, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 17\n",
            "Loss:  tensor(-13.0043, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6358, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3479, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 18\n",
            "Loss:  tensor(-13.1046, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6436, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 19\n",
            "Loss:  tensor(-12.6946, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6218, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3640, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 20\n",
            "Loss:  tensor(-13.3098, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6513, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3666, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 21\n",
            "Loss:  tensor(-13.3092, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6512, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3654, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 22\n",
            "Loss:  tensor(-12.9503, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6366, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 23\n",
            "Loss:  tensor(-12.8717, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6304, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3674, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 24\n",
            "Loss:  tensor(-13.0587, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4295, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 25\n",
            "Loss:  tensor(-12.5512, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3749, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 26\n",
            "Loss:  tensor(-13.0437, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6401, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3984, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 27\n",
            "Loss:  tensor(-12.3730, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 28\n",
            "Loss:  tensor(-12.7319, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 29\n",
            "Loss:  tensor(-12.5624, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4235, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 30\n",
            "Loss:  tensor(-12.9772, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 31\n",
            "Loss:  tensor(-12.7409, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 32\n",
            "Loss:  tensor(-12.7210, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6272, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4496, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 33\n",
            "Loss:  tensor(-12.6901, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6253, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 34\n",
            "Loss:  tensor(-12.7884, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6289, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 35\n",
            "Loss:  tensor(-12.8215, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6349, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 36\n",
            "Loss:  tensor(-13.4320, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6596, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 37\n",
            "Loss:  tensor(-12.5351, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4462, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 38\n",
            "Loss:  tensor(-12.9577, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6378, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4363, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 39\n",
            "Loss:  tensor(-12.3514, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 40\n",
            "Loss:  tensor(-12.6993, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4477, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 41\n",
            "Loss:  tensor(-13.1498, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6481, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4597, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 42\n",
            "Loss:  tensor(-13.0003, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 43\n",
            "Loss:  tensor(-12.9378, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6387, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4742, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 44\n",
            "Loss:  tensor(-12.4652, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4230, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 45\n",
            "Loss:  tensor(-12.1998, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6011, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4224, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 46\n",
            "Loss:  tensor(-12.1254, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4532, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 47\n",
            "Loss:  tensor(-12.5403, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4437, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 48\n",
            "Loss:  tensor(-12.3116, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6052, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 49\n",
            "Loss:  tensor(-12.6742, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6232, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 50\n",
            "Loss:  tensor(-12.7857, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6303, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4506, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 51\n",
            "Loss:  tensor(-13.2606, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6508, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4067, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 52\n",
            "Loss:  tensor(-12.9555, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6379, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4398, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 53\n",
            "Loss:  tensor(-13.3177, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6553, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 54\n",
            "Loss:  tensor(-12.9636, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6387, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4495, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 55\n",
            "Loss:  tensor(-12.6102, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6200, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 56\n",
            "Loss:  tensor(-13.0504, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6416, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4222, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 57\n",
            "Loss:  tensor(-13.3529, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6554, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 58\n",
            "Loss:  tensor(-13.3052, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6527, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 59\n",
            "Loss:  tensor(-13.3068, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6529, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 60\n",
            "Loss:  tensor(-12.8359, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6299, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 61\n",
            "Loss:  tensor(-12.3062, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6064, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 62\n",
            "Loss:  tensor(-13.3992, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6590, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4397, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 63\n",
            "Loss:  tensor(-13.0610, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6417, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 64\n",
            "Loss:  tensor(-13.0103, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6376, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3790, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 65\n",
            "Loss:  tensor(-13.3044, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6546, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4431, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 66\n",
            "Loss:  tensor(-12.7887, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4087, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 67\n",
            "Loss:  tensor(-12.8750, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6319, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 68\n",
            "Loss:  tensor(-13.5336, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6640, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 69\n",
            "Loss:  tensor(-12.7699, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 70\n",
            "Loss:  tensor(-12.7987, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6308, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4480, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 71\n",
            "Loss:  tensor(-12.9330, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6337, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3744, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 72\n",
            "Loss:  tensor(-12.5543, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4068, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 73\n",
            "Loss:  tensor(-13.2215, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6475, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3751, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 74\n",
            "Loss:  tensor(-13.2239, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6479, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  24 Batch: 75\n",
            "Loss:  tensor(-13.2691, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6508, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "ACC Train tensor(0.8180, device='cuda:0') PRULE tensor(0.5284, device='cuda:0') ACC Test tensor(0.8171, device='cuda:0') PRULEtest tensor(0.5140, device='cuda:0')\n",
            "Epoch:  0 Batch: 0\n",
            "Loss:  tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 1\n",
            "Loss:  tensor(0.6741, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.6741, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 2\n",
            "Loss:  tensor(0.6647, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.6647, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 3\n",
            "Loss:  tensor(0.6524, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.6524, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 4\n",
            "Loss:  tensor(0.6519, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.6519, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 5\n",
            "Loss:  tensor(0.6399, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.6399, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 6\n",
            "Loss:  tensor(0.6334, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.6334, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 7\n",
            "Loss:  tensor(0.6238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.6238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 8\n",
            "Loss:  tensor(0.6263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.6263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 9\n",
            "Loss:  tensor(0.6102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.6102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 10\n",
            "Loss:  tensor(0.5906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 11\n",
            "Loss:  tensor(0.5945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 12\n",
            "Loss:  tensor(0.5907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 13\n",
            "Loss:  tensor(0.5792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 14\n",
            "Loss:  tensor(0.5645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7107, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 15\n",
            "Loss:  tensor(0.5599, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5599, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 16\n",
            "Loss:  tensor(0.5419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 17\n",
            "Loss:  tensor(0.5352, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5352, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 18\n",
            "Loss:  tensor(0.4960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 19\n",
            "Loss:  tensor(0.5301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 20\n",
            "Loss:  tensor(0.5318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 21\n",
            "Loss:  tensor(0.5412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 22\n",
            "Loss:  tensor(0.5131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 23\n",
            "Loss:  tensor(0.5420, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5420, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 24\n",
            "Loss:  tensor(0.5422, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5422, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 25\n",
            "Loss:  tensor(0.5539, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5539, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 26\n",
            "Loss:  tensor(0.5141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 27\n",
            "Loss:  tensor(0.4960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 28\n",
            "Loss:  tensor(0.5138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 29\n",
            "Loss:  tensor(0.4642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 30\n",
            "Loss:  tensor(0.4801, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4801, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 31\n",
            "Loss:  tensor(0.4729, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4729, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 32\n",
            "Loss:  tensor(0.4828, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4828, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 33\n",
            "Loss:  tensor(0.4797, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4797, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 34\n",
            "Loss:  tensor(0.4448, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4448, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 35\n",
            "Loss:  tensor(0.4544, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4544, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 36\n",
            "Loss:  tensor(0.4350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 37\n",
            "Loss:  tensor(0.4354, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4354, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 38\n",
            "Loss:  tensor(0.4231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 39\n",
            "Loss:  tensor(0.3792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 40\n",
            "Loss:  tensor(0.3908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 41\n",
            "Loss:  tensor(0.3985, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3985, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 42\n",
            "Loss:  tensor(0.3959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 43\n",
            "Loss:  tensor(0.4125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 44\n",
            "Loss:  tensor(0.4373, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4373, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 45\n",
            "Loss:  tensor(0.4162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 46\n",
            "Loss:  tensor(0.3831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 47\n",
            "Loss:  tensor(0.3978, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3978, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 48\n",
            "Loss:  tensor(0.3861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 49\n",
            "Loss:  tensor(0.3869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 50\n",
            "Loss:  tensor(0.3903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 51\n",
            "Loss:  tensor(0.3808, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3808, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 52\n",
            "Loss:  tensor(0.3449, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3449, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 53\n",
            "Loss:  tensor(0.4101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 54\n",
            "Loss:  tensor(0.3637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 55\n",
            "Loss:  tensor(0.3846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 56\n",
            "Loss:  tensor(0.3732, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3732, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 57\n",
            "Loss:  tensor(0.3740, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3740, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 58\n",
            "Loss:  tensor(0.3508, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3508, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 59\n",
            "Loss:  tensor(0.4065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 60\n",
            "Loss:  tensor(0.3401, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3401, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 61\n",
            "Loss:  tensor(0.3298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 62\n",
            "Loss:  tensor(0.3852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 63\n",
            "Loss:  tensor(0.3882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 64\n",
            "Loss:  tensor(0.3883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 65\n",
            "Loss:  tensor(0.3856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 66\n",
            "Loss:  tensor(0.3646, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3646, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 67\n",
            "Loss:  tensor(0.3314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 68\n",
            "Loss:  tensor(0.3858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 69\n",
            "Loss:  tensor(0.3791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 70\n",
            "Loss:  tensor(0.3562, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3562, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 71\n",
            "Loss:  tensor(0.3830, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3830, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 72\n",
            "Loss:  tensor(0.3517, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3517, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 73\n",
            "Loss:  tensor(0.3136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 74\n",
            "Loss:  tensor(0.3528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  0 Batch: 75\n",
            "Loss:  tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 0\n",
            "Loss:  tensor(0.3608, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3608, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 1\n",
            "Loss:  tensor(0.3640, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3640, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 2\n",
            "Loss:  tensor(0.3314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 3\n",
            "Loss:  tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 4\n",
            "Loss:  tensor(0.3730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 5\n",
            "Loss:  tensor(0.3453, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3453, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 6\n",
            "Loss:  tensor(0.3574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 7\n",
            "Loss:  tensor(0.3551, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3551, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 8\n",
            "Loss:  tensor(0.3097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 9\n",
            "Loss:  tensor(0.3392, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3392, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 10\n",
            "Loss:  tensor(0.3380, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3380, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 11\n",
            "Loss:  tensor(0.3695, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3695, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 12\n",
            "Loss:  tensor(0.3552, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3552, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 13\n",
            "Loss:  tensor(0.3559, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3559, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 14\n",
            "Loss:  tensor(0.3474, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3474, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 15\n",
            "Loss:  tensor(0.3439, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3439, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 16\n",
            "Loss:  tensor(0.4065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 17\n",
            "Loss:  tensor(0.3812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 18\n",
            "Loss:  tensor(0.3466, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3466, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 19\n",
            "Loss:  tensor(0.3442, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3442, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 20\n",
            "Loss:  tensor(0.3279, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3279, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 21\n",
            "Loss:  tensor(0.3471, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3471, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 22\n",
            "Loss:  tensor(0.3584, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3584, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 23\n",
            "Loss:  tensor(0.3161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 24\n",
            "Loss:  tensor(0.3296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 25\n",
            "Loss:  tensor(0.3829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 26\n",
            "Loss:  tensor(0.3616, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3616, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 27\n",
            "Loss:  tensor(0.3718, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3718, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 28\n",
            "Loss:  tensor(0.3522, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3522, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 29\n",
            "Loss:  tensor(0.3284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 30\n",
            "Loss:  tensor(0.3555, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3555, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 31\n",
            "Loss:  tensor(0.3513, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3513, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 32\n",
            "Loss:  tensor(0.3684, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3684, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 33\n",
            "Loss:  tensor(0.3853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 34\n",
            "Loss:  tensor(0.3485, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3485, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 35\n",
            "Loss:  tensor(0.3907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 36\n",
            "Loss:  tensor(0.3432, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3432, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 37\n",
            "Loss:  tensor(0.3346, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3346, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 38\n",
            "Loss:  tensor(0.3401, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3401, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 39\n",
            "Loss:  tensor(0.3275, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7079, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3275, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 40\n",
            "Loss:  tensor(0.3537, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3537, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 41\n",
            "Loss:  tensor(0.3635, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3635, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 42\n",
            "Loss:  tensor(0.3745, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3745, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 43\n",
            "Loss:  tensor(0.3424, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3424, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 44\n",
            "Loss:  tensor(0.3306, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3306, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 45\n",
            "Loss:  tensor(0.3496, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3496, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 46\n",
            "Loss:  tensor(0.3392, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3392, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 47\n",
            "Loss:  tensor(0.3756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 48\n",
            "Loss:  tensor(0.3406, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3406, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 49\n",
            "Loss:  tensor(0.3613, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3613, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 50\n",
            "Loss:  tensor(0.3903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 51\n",
            "Loss:  tensor(0.3562, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3562, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 52\n",
            "Loss:  tensor(0.3317, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3317, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 53\n",
            "Loss:  tensor(0.3464, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3464, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 54\n",
            "Loss:  tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 55\n",
            "Loss:  tensor(0.3169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 56\n",
            "Loss:  tensor(0.3014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7107, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 57\n",
            "Loss:  tensor(0.3733, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3733, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 58\n",
            "Loss:  tensor(0.3490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 59\n",
            "Loss:  tensor(0.3388, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3388, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 60\n",
            "Loss:  tensor(0.3537, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3537, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 61\n",
            "Loss:  tensor(0.3342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 62\n",
            "Loss:  tensor(0.3489, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3489, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 63\n",
            "Loss:  tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 64\n",
            "Loss:  tensor(0.3503, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3503, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 65\n",
            "Loss:  tensor(0.3140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 66\n",
            "Loss:  tensor(0.3204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 67\n",
            "Loss:  tensor(0.3536, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3536, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 68\n",
            "Loss:  tensor(0.2925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 69\n",
            "Loss:  tensor(0.3023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 70\n",
            "Loss:  tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 71\n",
            "Loss:  tensor(0.3134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 72\n",
            "Loss:  tensor(0.3231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 73\n",
            "Loss:  tensor(0.3591, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3591, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 74\n",
            "Loss:  tensor(0.3446, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3446, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  1 Batch: 75\n",
            "Loss:  tensor(0.3512, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3512, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 0\n",
            "Loss:  tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 1\n",
            "Loss:  tensor(0.3645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 2\n",
            "Loss:  tensor(0.3441, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3441, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 3\n",
            "Loss:  tensor(0.2879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 4\n",
            "Loss:  tensor(0.3724, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3724, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 5\n",
            "Loss:  tensor(0.3260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 6\n",
            "Loss:  tensor(0.3155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 7\n",
            "Loss:  tensor(0.2865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 8\n",
            "Loss:  tensor(0.3462, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3462, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 9\n",
            "Loss:  tensor(0.3324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 10\n",
            "Loss:  tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 11\n",
            "Loss:  tensor(0.3390, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3390, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 12\n",
            "Loss:  tensor(0.3146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 13\n",
            "Loss:  tensor(0.3478, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3478, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 14\n",
            "Loss:  tensor(0.3697, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3697, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 15\n",
            "Loss:  tensor(0.3309, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3309, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 16\n",
            "Loss:  tensor(0.3901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 17\n",
            "Loss:  tensor(0.3228, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3228, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 18\n",
            "Loss:  tensor(0.3464, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3464, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 19\n",
            "Loss:  tensor(0.3509, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3509, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 20\n",
            "Loss:  tensor(0.3370, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3370, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 21\n",
            "Loss:  tensor(0.3379, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3379, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 22\n",
            "Loss:  tensor(0.3195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 23\n",
            "Loss:  tensor(0.2962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 24\n",
            "Loss:  tensor(0.3490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 25\n",
            "Loss:  tensor(0.3501, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3501, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 26\n",
            "Loss:  tensor(0.3569, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3569, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 27\n",
            "Loss:  tensor(0.3320, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3320, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 28\n",
            "Loss:  tensor(0.3717, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3717, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 29\n",
            "Loss:  tensor(0.3395, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3395, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 30\n",
            "Loss:  tensor(0.3550, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3550, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 31\n",
            "Loss:  tensor(0.3554, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3554, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 32\n",
            "Loss:  tensor(0.2961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 33\n",
            "Loss:  tensor(0.3288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3288, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 34\n",
            "Loss:  tensor(0.3326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 35\n",
            "Loss:  tensor(0.3172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 36\n",
            "Loss:  tensor(0.3489, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7186, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3489, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 37\n",
            "Loss:  tensor(0.3184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 38\n",
            "Loss:  tensor(0.2940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 39\n",
            "Loss:  tensor(0.2957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 40\n",
            "Loss:  tensor(0.3127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 41\n",
            "Loss:  tensor(0.3136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 42\n",
            "Loss:  tensor(0.3467, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3467, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 43\n",
            "Loss:  tensor(0.3637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 44\n",
            "Loss:  tensor(0.3500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 45\n",
            "Loss:  tensor(0.3221, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3221, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 46\n",
            "Loss:  tensor(0.3018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 47\n",
            "Loss:  tensor(0.3075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 48\n",
            "Loss:  tensor(0.3725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 49\n",
            "Loss:  tensor(0.3620, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3620, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 50\n",
            "Loss:  tensor(0.2958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 51\n",
            "Loss:  tensor(0.3366, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3366, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 52\n",
            "Loss:  tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 53\n",
            "Loss:  tensor(0.3425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 54\n",
            "Loss:  tensor(0.3140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 55\n",
            "Loss:  tensor(0.3148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 56\n",
            "Loss:  tensor(0.3423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 57\n",
            "Loss:  tensor(0.3366, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3366, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 58\n",
            "Loss:  tensor(0.3550, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3550, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 59\n",
            "Loss:  tensor(0.3298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 60\n",
            "Loss:  tensor(0.3414, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3414, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 61\n",
            "Loss:  tensor(0.3257, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3257, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 62\n",
            "Loss:  tensor(0.3071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 63\n",
            "Loss:  tensor(0.3639, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3639, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 64\n",
            "Loss:  tensor(0.3115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 65\n",
            "Loss:  tensor(0.3302, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3302, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 66\n",
            "Loss:  tensor(0.2914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7093, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 67\n",
            "Loss:  tensor(0.3777, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3777, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 68\n",
            "Loss:  tensor(0.3241, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3241, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 69\n",
            "Loss:  tensor(0.3019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7079, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 70\n",
            "Loss:  tensor(0.3712, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3712, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 71\n",
            "Loss:  tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 72\n",
            "Loss:  tensor(0.3116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 73\n",
            "Loss:  tensor(0.3000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 74\n",
            "Loss:  tensor(0.3207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  2 Batch: 75\n",
            "Loss:  tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 0\n",
            "Loss:  tensor(0.2938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7107, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 1\n",
            "Loss:  tensor(0.3478, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3478, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 2\n",
            "Loss:  tensor(0.3153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 3\n",
            "Loss:  tensor(0.3558, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3558, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 4\n",
            "Loss:  tensor(0.3347, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3347, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 5\n",
            "Loss:  tensor(0.3169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 6\n",
            "Loss:  tensor(0.3450, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3450, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 7\n",
            "Loss:  tensor(0.3819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 8\n",
            "Loss:  tensor(0.3077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 9\n",
            "Loss:  tensor(0.3489, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3489, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 10\n",
            "Loss:  tensor(0.3444, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3444, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 11\n",
            "Loss:  tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 12\n",
            "Loss:  tensor(0.2716, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2716, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 13\n",
            "Loss:  tensor(0.3765, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3765, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 14\n",
            "Loss:  tensor(0.2924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 15\n",
            "Loss:  tensor(0.3468, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3468, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 16\n",
            "Loss:  tensor(0.3227, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3227, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 17\n",
            "Loss:  tensor(0.3199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 18\n",
            "Loss:  tensor(0.3083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 19\n",
            "Loss:  tensor(0.3062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 20\n",
            "Loss:  tensor(0.3072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 21\n",
            "Loss:  tensor(0.3292, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3292, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 22\n",
            "Loss:  tensor(0.2944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 23\n",
            "Loss:  tensor(0.3168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 24\n",
            "Loss:  tensor(0.3263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 25\n",
            "Loss:  tensor(0.3097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 26\n",
            "Loss:  tensor(0.2744, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2744, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 27\n",
            "Loss:  tensor(0.3567, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7198, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3567, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 28\n",
            "Loss:  tensor(0.3150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 29\n",
            "Loss:  tensor(0.2731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 30\n",
            "Loss:  tensor(0.3096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 31\n",
            "Loss:  tensor(0.2983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 32\n",
            "Loss:  tensor(0.3246, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3246, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 33\n",
            "Loss:  tensor(0.3613, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3613, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 34\n",
            "Loss:  tensor(0.2897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 35\n",
            "Loss:  tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 36\n",
            "Loss:  tensor(0.2956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 37\n",
            "Loss:  tensor(0.2746, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2746, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 38\n",
            "Loss:  tensor(0.3103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 39\n",
            "Loss:  tensor(0.3183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 40\n",
            "Loss:  tensor(0.3353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 41\n",
            "Loss:  tensor(0.3792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 42\n",
            "Loss:  tensor(0.3648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 43\n",
            "Loss:  tensor(0.3375, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3375, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 44\n",
            "Loss:  tensor(0.3389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 45\n",
            "Loss:  tensor(0.3204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 46\n",
            "Loss:  tensor(0.3409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 47\n",
            "Loss:  tensor(0.3144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 48\n",
            "Loss:  tensor(0.3310, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3310, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 49\n",
            "Loss:  tensor(0.3081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 50\n",
            "Loss:  tensor(0.3040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 51\n",
            "Loss:  tensor(0.3273, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3273, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 52\n",
            "Loss:  tensor(0.3266, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3266, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 53\n",
            "Loss:  tensor(0.3522, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3522, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 54\n",
            "Loss:  tensor(0.3182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 55\n",
            "Loss:  tensor(0.3957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 56\n",
            "Loss:  tensor(0.3104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 57\n",
            "Loss:  tensor(0.3299, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3299, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 58\n",
            "Loss:  tensor(0.3148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 59\n",
            "Loss:  tensor(0.2953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 60\n",
            "Loss:  tensor(0.3287, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3287, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 61\n",
            "Loss:  tensor(0.2924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 62\n",
            "Loss:  tensor(0.3465, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3465, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 63\n",
            "Loss:  tensor(0.3297, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3297, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 64\n",
            "Loss:  tensor(0.3342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 65\n",
            "Loss:  tensor(0.3128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 66\n",
            "Loss:  tensor(0.3044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 67\n",
            "Loss:  tensor(0.3331, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3331, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 68\n",
            "Loss:  tensor(0.3225, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3225, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 69\n",
            "Loss:  tensor(0.3180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 70\n",
            "Loss:  tensor(0.3500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 71\n",
            "Loss:  tensor(0.3588, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3588, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 72\n",
            "Loss:  tensor(0.3105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 73\n",
            "Loss:  tensor(0.2913, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2913, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 74\n",
            "Loss:  tensor(0.2820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  3 Batch: 75\n",
            "Loss:  tensor(0.3037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 0\n",
            "Loss:  tensor(0.2589, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2589, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 1\n",
            "Loss:  tensor(0.2929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 2\n",
            "Loss:  tensor(0.2966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 3\n",
            "Loss:  tensor(0.3364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 4\n",
            "Loss:  tensor(0.3465, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3465, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 5\n",
            "Loss:  tensor(0.3604, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3604, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 6\n",
            "Loss:  tensor(0.2892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 7\n",
            "Loss:  tensor(0.3139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 8\n",
            "Loss:  tensor(0.3112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 9\n",
            "Loss:  tensor(0.3124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 10\n",
            "Loss:  tensor(0.3410, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3410, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 11\n",
            "Loss:  tensor(0.3096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 12\n",
            "Loss:  tensor(0.3487, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3487, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 13\n",
            "Loss:  tensor(0.3364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 14\n",
            "Loss:  tensor(0.3353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 15\n",
            "Loss:  tensor(0.3351, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3351, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 16\n",
            "Loss:  tensor(0.3057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 17\n",
            "Loss:  tensor(0.3354, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3354, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 18\n",
            "Loss:  tensor(0.2697, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2697, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 19\n",
            "Loss:  tensor(0.2960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 20\n",
            "Loss:  tensor(0.2836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 21\n",
            "Loss:  tensor(0.3088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 22\n",
            "Loss:  tensor(0.3028, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3028, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 23\n",
            "Loss:  tensor(0.3174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 24\n",
            "Loss:  tensor(0.2755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 25\n",
            "Loss:  tensor(0.3084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 26\n",
            "Loss:  tensor(0.3007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 27\n",
            "Loss:  tensor(0.3284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 28\n",
            "Loss:  tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 29\n",
            "Loss:  tensor(0.2921, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2921, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 30\n",
            "Loss:  tensor(0.2847, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2847, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 31\n",
            "Loss:  tensor(0.3043, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3043, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 32\n",
            "Loss:  tensor(0.2780, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2780, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 33\n",
            "Loss:  tensor(0.3194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 34\n",
            "Loss:  tensor(0.2805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 35\n",
            "Loss:  tensor(0.2953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 36\n",
            "Loss:  tensor(0.3590, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3590, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 37\n",
            "Loss:  tensor(0.2991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 38\n",
            "Loss:  tensor(0.3570, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3570, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 39\n",
            "Loss:  tensor(0.3154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 40\n",
            "Loss:  tensor(0.3385, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3385, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 41\n",
            "Loss:  tensor(0.3401, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3401, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 42\n",
            "Loss:  tensor(0.3102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 43\n",
            "Loss:  tensor(0.2899, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2899, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 44\n",
            "Loss:  tensor(0.3024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 45\n",
            "Loss:  tensor(0.3423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 46\n",
            "Loss:  tensor(0.3122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 47\n",
            "Loss:  tensor(0.3676, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3676, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 48\n",
            "Loss:  tensor(0.3089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 49\n",
            "Loss:  tensor(0.3321, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3321, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 50\n",
            "Loss:  tensor(0.3333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 51\n",
            "Loss:  tensor(0.3151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 52\n",
            "Loss:  tensor(0.3178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 53\n",
            "Loss:  tensor(0.3089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 54\n",
            "Loss:  tensor(0.2945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 55\n",
            "Loss:  tensor(0.2993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 56\n",
            "Loss:  tensor(0.3127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 57\n",
            "Loss:  tensor(0.3005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 58\n",
            "Loss:  tensor(0.3245, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3245, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 59\n",
            "Loss:  tensor(0.3349, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3349, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 60\n",
            "Loss:  tensor(0.2935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 61\n",
            "Loss:  tensor(0.3109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 62\n",
            "Loss:  tensor(0.3095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 63\n",
            "Loss:  tensor(0.3265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 64\n",
            "Loss:  tensor(0.3008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 65\n",
            "Loss:  tensor(0.3157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 66\n",
            "Loss:  tensor(0.3103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 67\n",
            "Loss:  tensor(0.3286, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3286, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 68\n",
            "Loss:  tensor(0.3074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 69\n",
            "Loss:  tensor(0.3228, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3228, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 70\n",
            "Loss:  tensor(0.3258, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3258, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 71\n",
            "Loss:  tensor(0.2862, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2862, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 72\n",
            "Loss:  tensor(0.2999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 73\n",
            "Loss:  tensor(0.3908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 74\n",
            "Loss:  tensor(0.3128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  4 Batch: 75\n",
            "Loss:  tensor(0.3429, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3429, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 0\n",
            "Loss:  tensor(0.3469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 1\n",
            "Loss:  tensor(0.2981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 2\n",
            "Loss:  tensor(0.3351, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3351, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 3\n",
            "Loss:  tensor(0.2879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 4\n",
            "Loss:  tensor(0.3166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 5\n",
            "Loss:  tensor(0.3066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 6\n",
            "Loss:  tensor(0.3260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 7\n",
            "Loss:  tensor(0.3118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 8\n",
            "Loss:  tensor(0.3095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 9\n",
            "Loss:  tensor(0.3062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 10\n",
            "Loss:  tensor(0.3100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 11\n",
            "Loss:  tensor(0.3420, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3420, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 12\n",
            "Loss:  tensor(0.3250, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3250, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 13\n",
            "Loss:  tensor(0.3056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 14\n",
            "Loss:  tensor(0.3171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 15\n",
            "Loss:  tensor(0.2920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 16\n",
            "Loss:  tensor(0.2970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 17\n",
            "Loss:  tensor(0.3303, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3303, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 18\n",
            "Loss:  tensor(0.2902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 19\n",
            "Loss:  tensor(0.2881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 20\n",
            "Loss:  tensor(0.2825, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2825, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 21\n",
            "Loss:  tensor(0.3184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 22\n",
            "Loss:  tensor(0.3530, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3530, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 23\n",
            "Loss:  tensor(0.2655, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2655, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 24\n",
            "Loss:  tensor(0.3079, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3079, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 25\n",
            "Loss:  tensor(0.3043, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3043, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 26\n",
            "Loss:  tensor(0.3286, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3286, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 27\n",
            "Loss:  tensor(0.2939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 28\n",
            "Loss:  tensor(0.2753, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2753, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 29\n",
            "Loss:  tensor(0.3252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 30\n",
            "Loss:  tensor(0.3220, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3220, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 31\n",
            "Loss:  tensor(0.2815, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2815, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 32\n",
            "Loss:  tensor(0.2841, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2841, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 33\n",
            "Loss:  tensor(0.3127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 34\n",
            "Loss:  tensor(0.2999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 35\n",
            "Loss:  tensor(0.3479, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3479, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 36\n",
            "Loss:  tensor(0.3174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 37\n",
            "Loss:  tensor(0.3377, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3377, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 38\n",
            "Loss:  tensor(0.2827, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2827, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 39\n",
            "Loss:  tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 40\n",
            "Loss:  tensor(0.3100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 41\n",
            "Loss:  tensor(0.2822, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2822, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 42\n",
            "Loss:  tensor(0.2857, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2857, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 43\n",
            "Loss:  tensor(0.3454, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3454, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 44\n",
            "Loss:  tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 45\n",
            "Loss:  tensor(0.3112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 46\n",
            "Loss:  tensor(0.3154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 47\n",
            "Loss:  tensor(0.3333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 48\n",
            "Loss:  tensor(0.3075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 49\n",
            "Loss:  tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7087, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 50\n",
            "Loss:  tensor(0.3184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 51\n",
            "Loss:  tensor(0.2792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 52\n",
            "Loss:  tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 53\n",
            "Loss:  tensor(0.3419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 54\n",
            "Loss:  tensor(0.3311, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3311, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 55\n",
            "Loss:  tensor(0.2959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 56\n",
            "Loss:  tensor(0.2995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 57\n",
            "Loss:  tensor(0.3220, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3220, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 58\n",
            "Loss:  tensor(0.2882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 59\n",
            "Loss:  tensor(0.2916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 60\n",
            "Loss:  tensor(0.3138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 61\n",
            "Loss:  tensor(0.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 62\n",
            "Loss:  tensor(0.3201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7162, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 63\n",
            "Loss:  tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 64\n",
            "Loss:  tensor(0.2863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 65\n",
            "Loss:  tensor(0.2957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 66\n",
            "Loss:  tensor(0.3265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 67\n",
            "Loss:  tensor(0.3301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 68\n",
            "Loss:  tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 69\n",
            "Loss:  tensor(0.3039, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3039, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 70\n",
            "Loss:  tensor(0.3141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 71\n",
            "Loss:  tensor(0.3331, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3331, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 72\n",
            "Loss:  tensor(0.3167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 73\n",
            "Loss:  tensor(0.2949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 74\n",
            "Loss:  tensor(0.3182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  5 Batch: 75\n",
            "Loss:  tensor(0.3040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 0\n",
            "Loss:  tensor(0.3136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 1\n",
            "Loss:  tensor(0.3074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 2\n",
            "Loss:  tensor(0.3120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 3\n",
            "Loss:  tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 4\n",
            "Loss:  tensor(0.2978, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2978, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 5\n",
            "Loss:  tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 6\n",
            "Loss:  tensor(0.2937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 7\n",
            "Loss:  tensor(0.3137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 8\n",
            "Loss:  tensor(0.2876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 9\n",
            "Loss:  tensor(0.3364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7112, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 10\n",
            "Loss:  tensor(0.2950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 11\n",
            "Loss:  tensor(0.3192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 12\n",
            "Loss:  tensor(0.2664, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2664, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 13\n",
            "Loss:  tensor(0.3443, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3443, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 14\n",
            "Loss:  tensor(0.3051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 15\n",
            "Loss:  tensor(0.3342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3342, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 16\n",
            "Loss:  tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 17\n",
            "Loss:  tensor(0.2873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 18\n",
            "Loss:  tensor(0.3372, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3372, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 19\n",
            "Loss:  tensor(0.2895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 20\n",
            "Loss:  tensor(0.3459, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3459, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 21\n",
            "Loss:  tensor(0.3092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 22\n",
            "Loss:  tensor(0.2805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 23\n",
            "Loss:  tensor(0.2936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 24\n",
            "Loss:  tensor(0.2849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 25\n",
            "Loss:  tensor(0.3269, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3269, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 26\n",
            "Loss:  tensor(0.3165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 27\n",
            "Loss:  tensor(0.2924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 28\n",
            "Loss:  tensor(0.3067, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3067, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 29\n",
            "Loss:  tensor(0.2906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 30\n",
            "Loss:  tensor(0.3010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 31\n",
            "Loss:  tensor(0.3419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 32\n",
            "Loss:  tensor(0.2476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 33\n",
            "Loss:  tensor(0.3368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 34\n",
            "Loss:  tensor(0.2631, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2631, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 35\n",
            "Loss:  tensor(0.2748, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2748, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 36\n",
            "Loss:  tensor(0.3231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 37\n",
            "Loss:  tensor(0.2769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 38\n",
            "Loss:  tensor(0.2982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 39\n",
            "Loss:  tensor(0.3432, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3432, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 40\n",
            "Loss:  tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 41\n",
            "Loss:  tensor(0.2738, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2738, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 42\n",
            "Loss:  tensor(0.3058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 43\n",
            "Loss:  tensor(0.2848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 44\n",
            "Loss:  tensor(0.3142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 45\n",
            "Loss:  tensor(0.3383, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3383, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 46\n",
            "Loss:  tensor(0.3396, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3396, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 47\n",
            "Loss:  tensor(0.3056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 48\n",
            "Loss:  tensor(0.3089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 49\n",
            "Loss:  tensor(0.2849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 50\n",
            "Loss:  tensor(0.3044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 51\n",
            "Loss:  tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 52\n",
            "Loss:  tensor(0.2822, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2822, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 53\n",
            "Loss:  tensor(0.3347, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3347, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 54\n",
            "Loss:  tensor(0.2889, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2889, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 55\n",
            "Loss:  tensor(0.3037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 56\n",
            "Loss:  tensor(0.3063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 57\n",
            "Loss:  tensor(0.2937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 58\n",
            "Loss:  tensor(0.2840, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2840, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 59\n",
            "Loss:  tensor(0.2858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 60\n",
            "Loss:  tensor(0.3109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 61\n",
            "Loss:  tensor(0.3548, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3548, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 62\n",
            "Loss:  tensor(0.3155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 63\n",
            "Loss:  tensor(0.3217, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3217, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 64\n",
            "Loss:  tensor(0.3433, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3433, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 65\n",
            "Loss:  tensor(0.2938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 66\n",
            "Loss:  tensor(0.2675, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2675, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 67\n",
            "Loss:  tensor(0.3255, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3255, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 68\n",
            "Loss:  tensor(0.2893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 69\n",
            "Loss:  tensor(0.3070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 70\n",
            "Loss:  tensor(0.2949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 71\n",
            "Loss:  tensor(0.3238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 72\n",
            "Loss:  tensor(0.2807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 73\n",
            "Loss:  tensor(0.3233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 74\n",
            "Loss:  tensor(0.3133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  6 Batch: 75\n",
            "Loss:  tensor(0.3305, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3305, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 0\n",
            "Loss:  tensor(0.3110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 1\n",
            "Loss:  tensor(0.2916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 2\n",
            "Loss:  tensor(0.3098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 3\n",
            "Loss:  tensor(0.2644, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2644, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 4\n",
            "Loss:  tensor(0.3206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 5\n",
            "Loss:  tensor(0.2837, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2837, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 6\n",
            "Loss:  tensor(0.3167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 7\n",
            "Loss:  tensor(0.2739, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2739, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 8\n",
            "Loss:  tensor(0.2993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 9\n",
            "Loss:  tensor(0.3075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 10\n",
            "Loss:  tensor(0.2807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 11\n",
            "Loss:  tensor(0.3084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 12\n",
            "Loss:  tensor(0.2933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 13\n",
            "Loss:  tensor(0.2682, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2682, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 14\n",
            "Loss:  tensor(0.2643, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2643, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 15\n",
            "Loss:  tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7093, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 16\n",
            "Loss:  tensor(0.3371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 17\n",
            "Loss:  tensor(0.2727, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2727, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 18\n",
            "Loss:  tensor(0.2737, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2737, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 19\n",
            "Loss:  tensor(0.3440, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3440, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 20\n",
            "Loss:  tensor(0.3287, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3287, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 21\n",
            "Loss:  tensor(0.3490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 22\n",
            "Loss:  tensor(0.2785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7165, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 23\n",
            "Loss:  tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 24\n",
            "Loss:  tensor(0.2962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 25\n",
            "Loss:  tensor(0.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 26\n",
            "Loss:  tensor(0.3150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 27\n",
            "Loss:  tensor(0.2792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 28\n",
            "Loss:  tensor(0.3636, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3636, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 29\n",
            "Loss:  tensor(0.3118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 30\n",
            "Loss:  tensor(0.2782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 31\n",
            "Loss:  tensor(0.3029, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3029, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 32\n",
            "Loss:  tensor(0.2821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 33\n",
            "Loss:  tensor(0.3308, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7107, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3308, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 34\n",
            "Loss:  tensor(0.2753, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2753, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 35\n",
            "Loss:  tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 36\n",
            "Loss:  tensor(0.3034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 37\n",
            "Loss:  tensor(0.3201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 38\n",
            "Loss:  tensor(0.3090, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3090, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 39\n",
            "Loss:  tensor(0.2758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 40\n",
            "Loss:  tensor(0.2969, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2969, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 41\n",
            "Loss:  tensor(0.2576, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2576, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 42\n",
            "Loss:  tensor(0.3246, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3246, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 43\n",
            "Loss:  tensor(0.3072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 44\n",
            "Loss:  tensor(0.3131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 45\n",
            "Loss:  tensor(0.3034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 46\n",
            "Loss:  tensor(0.3151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 47\n",
            "Loss:  tensor(0.2903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 48\n",
            "Loss:  tensor(0.3502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 49\n",
            "Loss:  tensor(0.3130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 50\n",
            "Loss:  tensor(0.2947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 51\n",
            "Loss:  tensor(0.2916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 52\n",
            "Loss:  tensor(0.2816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 53\n",
            "Loss:  tensor(0.2844, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2844, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 54\n",
            "Loss:  tensor(0.3278, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3278, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 55\n",
            "Loss:  tensor(0.3141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 56\n",
            "Loss:  tensor(0.2868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 57\n",
            "Loss:  tensor(0.2757, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2757, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 58\n",
            "Loss:  tensor(0.2951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 59\n",
            "Loss:  tensor(0.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 60\n",
            "Loss:  tensor(0.2868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 61\n",
            "Loss:  tensor(0.3047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 62\n",
            "Loss:  tensor(0.3051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 63\n",
            "Loss:  tensor(0.3164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 64\n",
            "Loss:  tensor(0.2787, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2787, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 65\n",
            "Loss:  tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 66\n",
            "Loss:  tensor(0.3031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 67\n",
            "Loss:  tensor(0.3103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 68\n",
            "Loss:  tensor(0.3225, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3225, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 69\n",
            "Loss:  tensor(0.3156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7172, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 70\n",
            "Loss:  tensor(0.3355, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3355, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 71\n",
            "Loss:  tensor(0.3024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 72\n",
            "Loss:  tensor(0.3564, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3564, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 73\n",
            "Loss:  tensor(0.2930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 74\n",
            "Loss:  tensor(0.3293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  7 Batch: 75\n",
            "Loss:  tensor(0.3233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3233, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 0\n",
            "Loss:  tensor(0.3047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 1\n",
            "Loss:  tensor(0.2957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 2\n",
            "Loss:  tensor(0.2986, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2986, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 3\n",
            "Loss:  tensor(0.3232, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3232, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 4\n",
            "Loss:  tensor(0.3059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 5\n",
            "Loss:  tensor(0.2788, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2788, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 6\n",
            "Loss:  tensor(0.3255, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3255, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 7\n",
            "Loss:  tensor(0.2725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 8\n",
            "Loss:  tensor(0.2786, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2786, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 9\n",
            "Loss:  tensor(0.3356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 10\n",
            "Loss:  tensor(0.2757, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2757, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 11\n",
            "Loss:  tensor(0.2883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 12\n",
            "Loss:  tensor(0.3323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 13\n",
            "Loss:  tensor(0.3287, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3287, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 14\n",
            "Loss:  tensor(0.3341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 15\n",
            "Loss:  tensor(0.2906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 16\n",
            "Loss:  tensor(0.2936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 17\n",
            "Loss:  tensor(0.2946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 18\n",
            "Loss:  tensor(0.3039, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3039, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 19\n",
            "Loss:  tensor(0.3309, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3309, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 20\n",
            "Loss:  tensor(0.2662, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2662, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 21\n",
            "Loss:  tensor(0.3386, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3386, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 22\n",
            "Loss:  tensor(0.3104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 23\n",
            "Loss:  tensor(0.2833, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2833, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 24\n",
            "Loss:  tensor(0.3167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3167, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 25\n",
            "Loss:  tensor(0.2810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 26\n",
            "Loss:  tensor(0.2855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 27\n",
            "Loss:  tensor(0.2630, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2630, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 28\n",
            "Loss:  tensor(0.2958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 29\n",
            "Loss:  tensor(0.3078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 30\n",
            "Loss:  tensor(0.2746, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2746, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 31\n",
            "Loss:  tensor(0.2742, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7107, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2742, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 32\n",
            "Loss:  tensor(0.2886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 33\n",
            "Loss:  tensor(0.3499, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3499, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 34\n",
            "Loss:  tensor(0.2648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 35\n",
            "Loss:  tensor(0.3261, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3261, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 36\n",
            "Loss:  tensor(0.3399, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7179, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3399, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 37\n",
            "Loss:  tensor(0.3092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 38\n",
            "Loss:  tensor(0.3206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 39\n",
            "Loss:  tensor(0.2809, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2809, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 40\n",
            "Loss:  tensor(0.3116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 41\n",
            "Loss:  tensor(0.2762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 42\n",
            "Loss:  tensor(0.2710, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2710, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 43\n",
            "Loss:  tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 44\n",
            "Loss:  tensor(0.2948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 45\n",
            "Loss:  tensor(0.2948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 46\n",
            "Loss:  tensor(0.2863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 47\n",
            "Loss:  tensor(0.3472, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3472, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 48\n",
            "Loss:  tensor(0.2950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 49\n",
            "Loss:  tensor(0.2893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 50\n",
            "Loss:  tensor(0.2483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 51\n",
            "Loss:  tensor(0.2483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 52\n",
            "Loss:  tensor(0.3332, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3332, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 53\n",
            "Loss:  tensor(0.3133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 54\n",
            "Loss:  tensor(0.2923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 55\n",
            "Loss:  tensor(0.3082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 56\n",
            "Loss:  tensor(0.2931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 57\n",
            "Loss:  tensor(0.2861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 58\n",
            "Loss:  tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 59\n",
            "Loss:  tensor(0.3046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 60\n",
            "Loss:  tensor(0.3007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 61\n",
            "Loss:  tensor(0.3232, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3232, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 62\n",
            "Loss:  tensor(0.3276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 63\n",
            "Loss:  tensor(0.3272, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3272, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 64\n",
            "Loss:  tensor(0.3059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 65\n",
            "Loss:  tensor(0.3001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 66\n",
            "Loss:  tensor(0.2940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 67\n",
            "Loss:  tensor(0.2850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 68\n",
            "Loss:  tensor(0.2944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 69\n",
            "Loss:  tensor(0.3197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 70\n",
            "Loss:  tensor(0.3171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 71\n",
            "Loss:  tensor(0.2864, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2864, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 72\n",
            "Loss:  tensor(0.3284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 73\n",
            "Loss:  tensor(0.3065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 74\n",
            "Loss:  tensor(0.2790, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2790, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  8 Batch: 75\n",
            "Loss:  tensor(0.2603, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2603, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 0\n",
            "Loss:  tensor(0.3040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 1\n",
            "Loss:  tensor(0.3194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 2\n",
            "Loss:  tensor(0.2911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 3\n",
            "Loss:  tensor(0.2373, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2373, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 4\n",
            "Loss:  tensor(0.2735, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2735, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 5\n",
            "Loss:  tensor(0.3081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 6\n",
            "Loss:  tensor(0.2937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 7\n",
            "Loss:  tensor(0.2642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7157, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 8\n",
            "Loss:  tensor(0.3204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 9\n",
            "Loss:  tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 10\n",
            "Loss:  tensor(0.2698, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2698, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 11\n",
            "Loss:  tensor(0.2856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 12\n",
            "Loss:  tensor(0.2704, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2704, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 13\n",
            "Loss:  tensor(0.2739, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2739, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 14\n",
            "Loss:  tensor(0.2513, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2513, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 15\n",
            "Loss:  tensor(0.2881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 16\n",
            "Loss:  tensor(0.3159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 17\n",
            "Loss:  tensor(0.3015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 18\n",
            "Loss:  tensor(0.3121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 19\n",
            "Loss:  tensor(0.2951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 20\n",
            "Loss:  tensor(0.2848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 21\n",
            "Loss:  tensor(0.3029, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3029, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 22\n",
            "Loss:  tensor(0.3324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 23\n",
            "Loss:  tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 24\n",
            "Loss:  tensor(0.2976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7093, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 25\n",
            "Loss:  tensor(0.2989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 26\n",
            "Loss:  tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 27\n",
            "Loss:  tensor(0.3131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 28\n",
            "Loss:  tensor(0.2946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 29\n",
            "Loss:  tensor(0.3209, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3209, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 30\n",
            "Loss:  tensor(0.2951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 31\n",
            "Loss:  tensor(0.2710, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2710, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 32\n",
            "Loss:  tensor(0.2670, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2670, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 33\n",
            "Loss:  tensor(0.3317, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3317, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 34\n",
            "Loss:  tensor(0.3041, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3041, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 35\n",
            "Loss:  tensor(0.3026, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3026, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 36\n",
            "Loss:  tensor(0.2862, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2862, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 37\n",
            "Loss:  tensor(0.2933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 38\n",
            "Loss:  tensor(0.3180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 39\n",
            "Loss:  tensor(0.2616, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2616, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 40\n",
            "Loss:  tensor(0.2762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 41\n",
            "Loss:  tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 42\n",
            "Loss:  tensor(0.2994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 43\n",
            "Loss:  tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 44\n",
            "Loss:  tensor(0.3154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 45\n",
            "Loss:  tensor(0.2815, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2815, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 46\n",
            "Loss:  tensor(0.2745, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2745, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 47\n",
            "Loss:  tensor(0.2900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 48\n",
            "Loss:  tensor(0.2778, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2778, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 49\n",
            "Loss:  tensor(0.3146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 50\n",
            "Loss:  tensor(0.2822, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2822, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 51\n",
            "Loss:  tensor(0.3481, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3481, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 52\n",
            "Loss:  tensor(0.3016, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3016, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 53\n",
            "Loss:  tensor(0.3323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 54\n",
            "Loss:  tensor(0.2878, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2878, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 55\n",
            "Loss:  tensor(0.3134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 56\n",
            "Loss:  tensor(0.3004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 57\n",
            "Loss:  tensor(0.3408, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3408, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 58\n",
            "Loss:  tensor(0.3008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 59\n",
            "Loss:  tensor(0.3015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 60\n",
            "Loss:  tensor(0.2885, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2885, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 61\n",
            "Loss:  tensor(0.3137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 62\n",
            "Loss:  tensor(0.2990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7113, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 63\n",
            "Loss:  tensor(0.3038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 64\n",
            "Loss:  tensor(0.3315, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3315, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 65\n",
            "Loss:  tensor(0.2775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 66\n",
            "Loss:  tensor(0.3451, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3451, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 67\n",
            "Loss:  tensor(0.2668, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2668, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 68\n",
            "Loss:  tensor(0.3374, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3374, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 69\n",
            "Loss:  tensor(0.2975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 70\n",
            "Loss:  tensor(0.2964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 71\n",
            "Loss:  tensor(0.2967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 72\n",
            "Loss:  tensor(0.2991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 73\n",
            "Loss:  tensor(0.2749, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2749, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 74\n",
            "Loss:  tensor(0.2965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  9 Batch: 75\n",
            "Loss:  tensor(0.3149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossS: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 0\n",
            "Loss:  tensor(-15.0327, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 1\n",
            "Loss:  tensor(-14.8570, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 2\n",
            "Loss:  tensor(-14.6133, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2714, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 3\n",
            "Loss:  tensor(-14.4613, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6705, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 4\n",
            "Loss:  tensor(-14.3723, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6664, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2887, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 5\n",
            "Loss:  tensor(-13.9447, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6485, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3232, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 6\n",
            "Loss:  tensor(-13.9532, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 7\n",
            "Loss:  tensor(-13.6703, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6344, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2862, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 8\n",
            "Loss:  tensor(-13.6152, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6306, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 9\n",
            "Loss:  tensor(-13.7879, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 10\n",
            "Loss:  tensor(-13.8109, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 11\n",
            "Loss:  tensor(-13.7945, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6415, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 12\n",
            "Loss:  tensor(-13.7048, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6380, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 13\n",
            "Loss:  tensor(-13.6038, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6346, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 14\n",
            "Loss:  tensor(-13.5485, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4608, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 15\n",
            "Loss:  tensor(-13.3688, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6289, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4660, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 16\n",
            "Loss:  tensor(-13.1310, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6175, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4541, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 17\n",
            "Loss:  tensor(-13.6223, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6380, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 18\n",
            "Loss:  tensor(-12.8434, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6021, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 19\n",
            "Loss:  tensor(-13.6581, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6385, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 20\n",
            "Loss:  tensor(-13.3015, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6207, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3538, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 21\n",
            "Loss:  tensor(-13.4388, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6269, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3530, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 22\n",
            "Loss:  tensor(-13.5864, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6314, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 23\n",
            "Loss:  tensor(-13.5650, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6302, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.2994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 24\n",
            "Loss:  tensor(-13.6927, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6386, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3569, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 25\n",
            "Loss:  tensor(-13.7779, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6405, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3130, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 26\n",
            "Loss:  tensor(-13.5844, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3261, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 27\n",
            "Loss:  tensor(-13.3849, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6245, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3543, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 28\n",
            "Loss:  tensor(-14.7415, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6841, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 29\n",
            "Loss:  tensor(-13.5099, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6300, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3502, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 30\n",
            "Loss:  tensor(-13.3340, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6213, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3337, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 31\n",
            "Loss:  tensor(-14.3241, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6667, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 32\n",
            "Loss:  tensor(-14.0937, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6592, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4087, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 33\n",
            "Loss:  tensor(-13.1701, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6163, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 34\n",
            "Loss:  tensor(-13.0279, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 35\n",
            "Loss:  tensor(-12.6354, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4701, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 36\n",
            "Loss:  tensor(-13.0746, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 37\n",
            "Loss:  tensor(-13.2056, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6235, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 38\n",
            "Loss:  tensor(-13.4088, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6328, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 39\n",
            "Loss:  tensor(-12.8586, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4672, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 40\n",
            "Loss:  tensor(-12.9197, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4742, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 41\n",
            "Loss:  tensor(-12.7778, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6053, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.5385, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 42\n",
            "Loss:  tensor(-12.8169, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6022, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4313, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 43\n",
            "Loss:  tensor(-12.3212, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5793, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4232, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 44\n",
            "Loss:  tensor(-13.0148, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 45\n",
            "Loss:  tensor(-13.4950, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6356, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 46\n",
            "Loss:  tensor(-13.2950, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6251, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4582, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 47\n",
            "Loss:  tensor(-13.9987, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6566, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4471, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 48\n",
            "Loss:  tensor(-13.1438, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4773, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 49\n",
            "Loss:  tensor(-12.5010, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4662, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 50\n",
            "Loss:  tensor(-13.1093, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6155, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 51\n",
            "Loss:  tensor(-13.2949, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6248, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4514, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 52\n",
            "Loss:  tensor(-12.8694, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4321, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 53\n",
            "Loss:  tensor(-12.8009, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4151, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 54\n",
            "Loss:  tensor(-12.2096, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5754, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4483, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 55\n",
            "Loss:  tensor(-12.7157, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4228, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 56\n",
            "Loss:  tensor(-13.2804, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6225, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 57\n",
            "Loss:  tensor(-12.8974, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 58\n",
            "Loss:  tensor(-12.5205, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5877, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 59\n",
            "Loss:  tensor(-13.1880, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 60\n",
            "Loss:  tensor(-13.7141, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4214, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 61\n",
            "Loss:  tensor(-13.3864, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6276, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4209, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 62\n",
            "Loss:  tensor(-13.8723, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6482, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 63\n",
            "Loss:  tensor(-13.4710, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6302, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 64\n",
            "Loss:  tensor(-13.6203, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6369, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 65\n",
            "Loss:  tensor(-13.6007, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6366, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4050, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 66\n",
            "Loss:  tensor(-13.2919, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4320, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 67\n",
            "Loss:  tensor(-12.9157, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4644, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 68\n",
            "Loss:  tensor(-13.2960, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6257, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4684, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 69\n",
            "Loss:  tensor(-13.4309, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6302, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4330, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 70\n",
            "Loss:  tensor(-13.2826, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 71\n",
            "Loss:  tensor(-12.7292, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5978, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4228, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 72\n",
            "Loss:  tensor(-13.2315, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6237, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 73\n",
            "Loss:  tensor(-12.1889, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5759, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 74\n",
            "Loss:  tensor(-13.3910, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6297, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4619, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  10 Batch: 75\n",
            "Loss:  tensor(-13.1324, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 0\n",
            "Loss:  tensor(-12.9649, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4640, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 1\n",
            "Loss:  tensor(-13.2708, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6234, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4430, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 2\n",
            "Loss:  tensor(-12.9355, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 3\n",
            "Loss:  tensor(-12.9532, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4627, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 4\n",
            "Loss:  tensor(-13.0031, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4536, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 5\n",
            "Loss:  tensor(-13.0872, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4605, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 6\n",
            "Loss:  tensor(-13.2330, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6216, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4425, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 7\n",
            "Loss:  tensor(-13.5514, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6336, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 8\n",
            "Loss:  tensor(-12.6514, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 9\n",
            "Loss:  tensor(-13.3496, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6257, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 10\n",
            "Loss:  tensor(-13.6562, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 11\n",
            "Loss:  tensor(-13.3720, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6278, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4395, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 12\n",
            "Loss:  tensor(-13.5237, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 13\n",
            "Loss:  tensor(-13.1841, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 14\n",
            "Loss:  tensor(-13.5962, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6357, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 15\n",
            "Loss:  tensor(-13.2414, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 16\n",
            "Loss:  tensor(-13.9715, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6554, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4478, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 17\n",
            "Loss:  tensor(-13.5897, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6372, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4277, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 18\n",
            "Loss:  tensor(-13.6040, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4041, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 19\n",
            "Loss:  tensor(-13.1841, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6178, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 20\n",
            "Loss:  tensor(-13.5785, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 21\n",
            "Loss:  tensor(-12.5518, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4361, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 22\n",
            "Loss:  tensor(-13.0563, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 23\n",
            "Loss:  tensor(-12.9117, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4431, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 24\n",
            "Loss:  tensor(-12.8635, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 25\n",
            "Loss:  tensor(-13.3654, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6282, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4541, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 26\n",
            "Loss:  tensor(-13.1853, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6196, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4462, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 27\n",
            "Loss:  tensor(-13.8147, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6470, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 28\n",
            "Loss:  tensor(-13.1538, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 29\n",
            "Loss:  tensor(-13.0971, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3800, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 30\n",
            "Loss:  tensor(-13.1839, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 31\n",
            "Loss:  tensor(-12.9556, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 32\n",
            "Loss:  tensor(-13.3766, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6263, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4022, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 33\n",
            "Loss:  tensor(-13.6045, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6351, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3683, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 34\n",
            "Loss:  tensor(-13.0398, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3759, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 35\n",
            "Loss:  tensor(-13.3942, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6267, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 36\n",
            "Loss:  tensor(-13.2374, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4255, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 37\n",
            "Loss:  tensor(-13.3566, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6271, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4395, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 38\n",
            "Loss:  tensor(-13.3439, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4280, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 39\n",
            "Loss:  tensor(-12.7828, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4053, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 40\n",
            "Loss:  tensor(-13.7944, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6443, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3803, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 41\n",
            "Loss:  tensor(-13.1182, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 42\n",
            "Loss:  tensor(-13.3511, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3969, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 43\n",
            "Loss:  tensor(-13.7665, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6438, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 44\n",
            "Loss:  tensor(-13.6923, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4300, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 45\n",
            "Loss:  tensor(-13.6994, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 46\n",
            "Loss:  tensor(-13.8100, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6473, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 47\n",
            "Loss:  tensor(-13.3279, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6229, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 48\n",
            "Loss:  tensor(-13.4756, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4343, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 49\n",
            "Loss:  tensor(-13.7522, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 50\n",
            "Loss:  tensor(-14.0452, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6578, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4262, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 51\n",
            "Loss:  tensor(-12.9918, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 52\n",
            "Loss:  tensor(-13.8443, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6479, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 53\n",
            "Loss:  tensor(-12.4327, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.5857, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4532, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 54\n",
            "Loss:  tensor(-13.1814, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.4619, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 55\n",
            "Loss:  tensor(-14.4138, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6726, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3844, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 56\n",
            "Loss:  tensor(-13.9478, device='cuda:0', grad_fn=<AddBackward0>) lossS: tensor(0.6515, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) lossY: tensor(0.3856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch:  11 Batch: 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D75ouinlSzGm"
      },
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "H = 15\n",
        "H2 = 15\n",
        "epochs_hgr=50\n",
        "\n",
        "\n",
        "table = [0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "batch_size = 512\n",
        "num_epochs = 25\n",
        "learning_rate = 0.0001\n",
        "batch_no = len(X_train) // batch_size\n",
        "#X_train_inv = recon_X_batch_a.data.numpy()\n",
        "#Y_train_inv = recon_Y_batch_a.data.numpy()\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from torch.autograd import Variable\n",
        "criterionMSE = nn.MSELoss()\n",
        "import math\n",
        "nb_a=200\n",
        "from torch.nn import functional as F\n",
        "def sigmoid(x):\n",
        "  output = [1 / (1 + math.exp(-x)) for x in x]\n",
        "  return output\n",
        "\n",
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 16)\n",
        "        self.fc4 = nn.Linear(16, 1)        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "class NN_a(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN_a, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1]+1, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 16)\n",
        "        self.fc4 = nn.Linear(16, 1)        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_Y_b = NN_b().cuda()\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer_Y = torch.optim.Adam(model_Y_b.parameters(), lr=0.001)\n",
        "\n",
        "model_A = NN_a().cuda()\n",
        "optimizer_A = torch.optim.Adam(model_A.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "\n",
        "model_Y = NN().cuda()\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer_Y = torch.optim.Adam(model_Y.parameters(), lr=0.001)\n",
        "criterion_ADV =  nn.MSELoss()\n",
        "#A0 = sensitive.mean() + sensitive.std()*Variable(torch.randn(data.shape[0]*nb_a, 1),requires_grad=False)\n",
        "#recon_X_batch_a0, z_a0, recon_Y_batch_a0, mu_a0, logvar_a0 = model(data.repeat(nb_a,1).view(-1, 33),A0)\n",
        "#recon_x, recon_xNC, S, U,  recon_y, mu, logvar = model(x_var, x_varNC, y_var,s_var)\n",
        "from sklearn.metrics import accuracy_score\n",
        "X_trainCUDA = Variable(torch.FloatTensor(X_train)).cuda()\n",
        "y_trainCUDA = Variable(torch.FloatTensor(np.expand_dims(y_train,axis = 1))).cuda()\n",
        "\n",
        "X_testCUDA = Variable(torch.FloatTensor(X_test)).cuda()\n",
        "y_testCUDA = Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).cuda()\n",
        "for betamse0 in range(20):\n",
        "    for o in range(10):\n",
        "        for epoch in range(num_epochs):\n",
        "            #if epoch % 50 != 0:\n",
        "                #x_train = Variable(torch.FloatTensor(X_train.values),requires_grad=True)\n",
        "                #x_test = Variable(torch.FloatTensor(X_test.values),requires_grad=True)\n",
        "                #print('Epoch {}'.format(epoch+1))\n",
        "                \n",
        "                #y_predX= model(x_train).data.numpy().T\n",
        "                #y_predXinv= model(recon_X_batch_a0).data.numpy().T\n",
        "\n",
        "                #accuracy = (y_train-np.squeeze(y_predX)).pow(2).sum()     \n",
        "                #accuracycount = accuracy_score(Y_train_inv.squeeze(1), np.squeeze(y_predXinv))\n",
        "                #print (\"Train Accuracy:\", accuracy)#,\"Train Accuracy Count:\", accuracycount, \"CLP:\", np.mean(logit_y_predX-logit_y_predXinv)**2)\n",
        "            x_train, ytrain, sens_train, gtrain = shuffle(X_train, np.expand_dims(y_train,axis = 1),  S_train, G_train)\n",
        "\n",
        "            #A = s_var.mean() + s_var.std()*Variable(torch.randn(batch_size*nb_a, 1),requires_grad=False)\n",
        "            # Mini batch learning\n",
        "            for i in range(batch_no):\n",
        "                print('Epoch: ', epoch, 'Batch:',i)\n",
        "                start = i * batch_size\n",
        "                end = start + batch_size\n",
        "\n",
        "                x_var = Variable(torch.FloatTensor(x_train[start:end])).cuda()\n",
        "                y_var = Variable(torch.FloatTensor(ytrain[start:end])).cuda()\n",
        "                s_var = Variable(torch.FloatTensor(sens_train[start:end])).cuda()\n",
        "                g_train = Variable(torch.FloatTensor(gtrain[start:end])).cuda()\n",
        "                betamse =betamse0/10 #7   ## LAMBDA =0.7\n",
        "\n",
        "                for l in range(1):\n",
        "                  optimizer_A.zero_grad()\n",
        "                  ypred_var0 = model_Y(torch.cat([x_var.view(-1, x_var.shape[1])],1)).detach()\n",
        "                  fx = model_A(torch.cat([x_var.view(-1, x_var.shape[1]),y_var],1))\n",
        "                  lambdab =  fx/torch.mean(fx)\n",
        "                  lossY = -(y_var * torch._C._nn.log_sigmoid(ypred_var0) + (1 - y_var) * torch._C._nn.log_sigmoid(-ypred_var0))\n",
        "                  lossA = -torch.mean(lossY +betamse*lambdab*lossY)\n",
        "                  lossA.backward()\n",
        "                  optimizer_A.step()\n",
        "\n",
        "\n",
        "                optimizer_Y.zero_grad()\n",
        "                fx = model_A(torch.cat([x_var.view(-1, x_var.shape[1]),y_var],1))\n",
        "                lambdab =  fx/torch.mean(fx)\n",
        "                ypred_var = model_Y(torch.cat([x_var.view(-1, x_var.shape[1])],1))\n",
        "                #lossY =criterion(ypred_var, y_var)\n",
        "                lossY = -(y_var * torch._C._nn.log_sigmoid(ypred_var) + (1 - y_var) * torch._C._nn.log_sigmoid(-ypred_var))\n",
        "                loss = torch.mean(lossY +betamse*lambdab*lossY) # + lossX_inv -2*lossX#+ betamse*MSEcount\n",
        "                loss.backward()\n",
        "                optimizer_Y.step()\n",
        "\n",
        "         \n",
        "                Ypred =  model_Y(torch.cat([X_trainCUDA.view(-1, X_trainCUDA.shape[1])],1))>0.5\n",
        "                Ho = (S_train==1)\n",
        "                Fe = (S_train==0)\n",
        "                odds=Ypred.float()[Ho].mean()/ Ypred.float()[Fe].mean()\n",
        "                PRULE= min(odds, 1/odds)\n",
        "                FP0=torch.abs(Ypred.float()[Ho & (y_trainCUDA.cpu().data.numpy()==0)].mean()-Ypred.float()[Fe & (y_trainCUDA.cpu().data.numpy()==0)].mean())\n",
        "                FN1=torch.abs((1-Ypred.float()[Ho & (y_trainCUDA.cpu().data.numpy()==1)].mean())-(1-Ypred.float()[Fe & (y_trainCUDA.cpu().data.numpy()==1)].mean()))  \n",
        "\n",
        "                Ypredtest = model_Y(torch.cat([X_testCUDA.view(-1, X_testCUDA.shape[1] )],1))>0.5      \n",
        "                Ho = (S_test==1)\n",
        "                Fe = (S_test==0)\n",
        "                odds=Ypredtest.float()[Ho].mean()/ Ypredtest.float()[Fe].mean()\n",
        "                PRULEtest= min(odds, 1/odds)\n",
        "                FP0test=torch.abs(Ypredtest.float()[Ho & (y_testCUDA.cpu().data.numpy()==0)].mean()- Ypredtest.float()[Fe& (y_testCUDA.cpu().data.numpy()==0)].mean())\n",
        "                FN1test=torch.abs((1-Ypredtest.float()[Ho & (y_testCUDA.cpu().data.numpy()==1)].mean())-(1-Ypredtest.float()[Fe & (y_testCUDA.cpu().data.numpy()==1)].mean()))  \n",
        "\n",
        "                print('ACC Train',(Ypred==y_trainCUDA).sum()/X_train.shape[0], 'PRULE',PRULE, 'ACC Test',(Ypredtest==y_testCUDA).sum()/X_test.shape[0],'PRULEtest',PRULEtest)\n",
        "\n",
        "        table = np.vstack([table,[ num_epochs, betamse,(Ypred.cpu().data.numpy()==y_trainCUDA.cpu().data.numpy()).sum()/X_train.shape[0]*100,PRULE.cpu().data.numpy(),ret.cpu().data.numpy(), FP0,FN1,\n",
        "                                  (Ypredtest.cpu().data.numpy()==y_testCUDA.cpu().data.numpy()).sum()/X_test.shape[0]*100,PRULEtest.cpu().data.numpy(),ret.cpu().data.numpy(),FP0test,FN1test]])\n",
        "\n",
        "    np.savetxt('Adult_AdelFairness', table[1:,])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHovNj0oNHOa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfdc_eSiNHUq",
        "outputId": "bdbfa8e2-ee24-4272-b267-4b676574cdd5"
      },
      "source": [
        "table.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74uZEQv72yjz"
      },
      "source": [
        "Ypred = torch.sigmoid(model_Y_b(m_NN_z(torch.cat([XNC_trainCUDA.view(-1, 43),X_trainCUDA.view(-1, X_trainCUDA.shape[1])],1))))>0.5\n",
        "Ho = (S_train==1)\n",
        "Fe = (S_train==0)\n",
        "odds=Ypred.float()[Ho].mean()/ Ypred.float()[Fe].mean()\n",
        "PRULE= min(odds, 1/odds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12eDIXPv23Ny",
        "outputId": "03d2b4f4-66e4-4b94-d3e4-8cbc243a2206"
      },
      "source": [
        "Ypred.float()[Ho].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0914, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "PHZsFOm9goWA",
        "outputId": "f3ff8a6b-3b84-4e8a-b98c-8e8db8ebc662"
      },
      "source": [
        " ((torch.sigmoid(Spred_var)>0.5)==s_var).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-256602697ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpred_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0ms_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Can only calculate the mean of floating types. Got Long instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZxDJ8PYg13Y",
        "outputId": "bd7c90e0-802d-4deb-f836-c6af99c5e50d"
      },
      "source": [
        "(torch.sigmoid(Spred_var)>0.5)==s_var"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR1AB5KigcBN",
        "outputId": "7ee58805-f7a5-429a-8c77-1852879ecce1"
      },
      "source": [
        "*Ypred_var.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "YO1_hNBN6Yct",
        "outputId": "1e239e08-eb28-46b2-fce7-1d290f278cd6"
      },
      "source": [
        "lamb =75\n",
        "lambda_ADV =lamb\n",
        "batch_size=128\n",
        "bs = 1024\n",
        "num_epochs = 500\n",
        "learning_rate = 0.0001\n",
        "batch_no = len(X_train) // bs\n",
        "lamb\n",
        "\n",
        "m_NN_y = NN_y().to(device)\n",
        "m_NN_s = NN_s().to(device)\n",
        "\n",
        "optimizer_y = torch.optim.Adam(m_NN_y.parameters(), lr=learning_rate)\n",
        "optimizer_s = torch.optim.Adam(m_NN_s.parameters(), lr=learning_rate)\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    x_train, ytrain, strain = shuffle(X_train,np.expand_dims(y_train,axis = 1),sensitive)\n",
        "    # Mini batch learning\n",
        "    epsilon=0.00000000000000001\n",
        "    for i in range(batch_no):\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "        x_var = Variable(torch.FloatTensor(x_train[start:end])).to(device)\n",
        "        y_var = Variable(torch.FloatTensor(ytrain[start:end])).to(device)\n",
        "        s_var = Variable(torch.FloatTensor(strain[start:end])).unsqueeze(1).to(device)\n",
        "        # Forward + Backward + Optimize\n",
        "        Ypred_var0 = m_NN_y(x_var).detach()\n",
        "        for l in range(10):\n",
        "            optimizer_s.zero_grad()\n",
        "            Spred_var = m_NN_s(torch.sigmoid(Ypred_var0))\n",
        "            lossS = criterion(Spred_var, s_var)\n",
        "            optimizer_s.step()\n",
        "\n",
        "        optimizer_y.zero_grad()\n",
        "        Ypred_var = m_NN_y(x_var)\n",
        "        Spred_var = m_NN_s(torch.sigmoid(Ypred_var))\n",
        "        lossS = criterion(Spred_var, s_var)\n",
        "        lossY = criterion(Ypred_var, y_var)\n",
        "        loss =  lossY\n",
        "        if epoch >= 200:\n",
        "            loss = - lambda_ADV * lossS + lossY\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer_y.step()\n",
        "    if epoch % 5 == 0:\n",
        "        y_pred2= torch.sigmoid(m_NN_y(torch.FloatTensor(X_train).to(device))).cpu().data.numpy()\n",
        "        y_pred2t= torch.sigmoid(m_NN_y(torch.FloatTensor(X_test).to(device))).cpu().data.numpy()\n",
        "        print('epoch', epoch, 'loss', loss.cpu().data.numpy(), 'lossS', lossS.cpu().data.numpy(), 'lossY', lossY.cpu().data.numpy(),'P-rule', p_rule(y_pred2,np.expand_dims(sensitive,1)),'ACC_train',accuracy_score(y_train, y_pred2>0.5),\n",
        "              'P-ruletest', p_rule(y_pred2t,np.expand_dims(sensitivet,1)),'ACC_test',accuracy_score(y_test, y_pred2t>0.5))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d8f3a0e0e31f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mm_NN_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mm_NN_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NN_y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_93R5WX5Exx",
        "outputId": "7c39094c-51ac-4da8-f5e4-a2bc2e86724b"
      },
      "source": [
        "s_var.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37S8u4Qg34bP"
      },
      "source": [
        "optimizer_Y.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eOEOwYkMG3X",
        "outputId": "a2270c90-2886-4ec5-b883-51f868204de0"
      },
      "source": [
        "(Ypredtest.cpu().data.numpy()==y_testCUDA.cpu().data.numpy()).sum()/X_test.shape[0]*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.45398710205752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYaNNt7br4IP"
      },
      "source": [
        "HGR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb9aZMmtp6SJ"
      },
      "source": [
        "\n",
        "\n",
        "# Variational Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIZ7zJxCFXgF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tf4URUOAPX44",
        "outputId": "3f6284f7-a87f-44e4-9371-5b993e0604a1"
      },
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "H = 15\n",
        "H2 = 15\n",
        "epochs_hgr=50\n",
        "\n",
        "\n",
        "table = [0,0,0,0,0,0,0,0]\n",
        "batch_size = 512\n",
        "num_epochs = 25\n",
        "learning_rate = 0.0001\n",
        "batch_no = len(X_train) // batch_size\n",
        "#X_train_inv = recon_X_batch_a.data.numpy()\n",
        "#Y_train_inv = recon_Y_batch_a.data.numpy()\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from torch.autograd import Variable\n",
        "criterionMSE = nn.MSELoss()\n",
        "import math\n",
        "nb_a=200\n",
        "from torch.nn import functional as F\n",
        "def sigmoid(x):\n",
        "  output = [1 / (1 + math.exp(-x)) for x in x]\n",
        "  return output\n",
        "\n",
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(99, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 16)\n",
        "        self.fc4 = nn.Linear(16, 1)        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "model_Y = NN().cuda()\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer_Y = torch.optim.Adam(model_Y.parameters(), lr=0.001)\n",
        "criterion_ADV =  nn.MSELoss()\n",
        "#A0 = sensitive.mean() + sensitive.std()*Variable(torch.randn(data.shape[0]*nb_a, 1),requires_grad=False)\n",
        "#recon_X_batch_a0, z_a0, recon_Y_batch_a0, mu_a0, logvar_a0 = model(data.repeat(nb_a,1).view(-1, 33),A0)\n",
        "#recon_x, recon_xNC, S, U,  recon_y, mu, logvar = model(x_var, x_varNC, y_var,s_var)\n",
        "from sklearn.metrics import accuracy_score\n",
        "X_trainCUDA = Variable(torch.FloatTensor(X_train)).cuda()\n",
        "XNC_trainCUDA = Variable(torch.FloatTensor(XNC_train)).cuda()\n",
        "y_trainCUDA = Variable(torch.FloatTensor(np.expand_dims(y_train,axis = 1))).cuda()\n",
        "\n",
        "X_testCUDA = Variable(torch.FloatTensor(X_test)).cuda()\n",
        "XNC_testCUDA = Variable(torch.FloatTensor(XNC_test)).cuda()\n",
        "y_testCUDA = Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).cuda()\n",
        "for betamse0 in range(20):\n",
        "    for o in range(10):\n",
        "        for epoch in range(num_epochs):\n",
        "            #if epoch % 50 != 0:\n",
        "                #x_train = Variable(torch.FloatTensor(X_train.values),requires_grad=True)\n",
        "                #x_test = Variable(torch.FloatTensor(X_test.values),requires_grad=True)\n",
        "                #print('Epoch {}'.format(epoch+1))\n",
        "                \n",
        "                #y_predX= model(x_train).data.numpy().T\n",
        "                #y_predXinv= model(recon_X_batch_a0).data.numpy().T\n",
        "\n",
        "                #accuracy = (y_train-np.squeeze(y_predX)).pow(2).sum()     \n",
        "                #accuracycount = accuracy_score(Y_train_inv.squeeze(1), np.squeeze(y_predXinv))\n",
        "                #print (\"Train Accuracy:\", accuracy)#,\"Train Accuracy Count:\", accuracycount, \"CLP:\", np.mean(logit_y_predX-logit_y_predXinv)**2)\n",
        "            x_train, x_trainNC, ytrain, sens_train, gtrain = shuffle(X_train, XNC_train, np.expand_dims(y_train,axis = 1),  S_train, G_train)\n",
        "\n",
        "            #A = s_var.mean() + s_var.std()*Variable(torch.randn(batch_size*nb_a, 1),requires_grad=False)\n",
        "            # Mini batch learning\n",
        "            for i in range(batch_no):\n",
        "                print('Epoch: ', epoch, 'Batch:',i)\n",
        "                start = i * batch_size\n",
        "                end = start + batch_size\n",
        "\n",
        "                x_var = Variable(torch.FloatTensor(x_train[start:end])).cuda()\n",
        "                xNC_var = Variable(torch.FloatTensor(x_trainNC[start:end])).cuda()\n",
        "                y_var = Variable(torch.FloatTensor(ytrain[start:end])).cuda()\n",
        "                s_var = Variable(torch.FloatTensor(sens_train[start:end])).cuda()\n",
        "                g_train = Variable(torch.FloatTensor(gtrain[start:end])).cuda()\n",
        "\n",
        "                fx = model_Y_b(torch.cat([xNC_var.view(-1, 43),x_var.view(-1, x_var.shape[1])],1)).detach()\n",
        "\n",
        "                optimizer_Y.zero_grad()\n",
        "                bx = model_Y(torch.cat([xNC_var.view(-1, 43),x_var.view(-1, x_var.shape[1])],1))\n",
        "                ypred_var = fx + (bx.T*(g_train[:,0]+g_train[:,1])).T\n",
        "                lossY =criterion(ypred_var, y_var)\n",
        "                betamse =betamse0/10 #7   ## LAMBDA =0.7\n",
        "                ret = torch.mean(ypred_var) -   torch.mean(ypred_var*g_train[:,0]) -   torch.mean(ypred_var*g_train[:,1])\n",
        "                loss = lossY +betamse*ret # + lossX_inv -2*lossX#+ betamse*MSEcount\n",
        "                loss.backward()\n",
        "                optimizer_Y.step()\n",
        "\n",
        "                \n",
        "                fxtrain = model_Y_b(torch.cat([XNC_trainCUDA.view(-1, 43),X_trainCUDA.view(-1, x_var.shape[1])],1)).detach()\n",
        "                bxtrain= model_Y(torch.cat([XNC_trainCUDA.view(-1, 43),X_trainCUDA.view(-1, X_trainCUDA.shape[1])],1))\n",
        "                Ypred =  torch.sigmoid(fxtrain + (bxtrain.T*(G_trainCUDA[:,0]+G_trainCUDA[:,1])).T)>0.5\n",
        "\n",
        "                Ho = (S_train==1)\n",
        "                Fe = (S_train==0)\n",
        "                odds=Ypred.float()[Ho].mean()/ Ypred.float()[Fe].mean()\n",
        "                PRULE= min(odds, 1/odds)\n",
        "\n",
        "                fxtest = model_Y_b(torch.cat([XNC_testCUDA.view(-1, 43),X_testCUDA.view(-1, x_var.shape[1])],1)).detach()\n",
        "                bxtest = model_Y(torch.cat([XNC_testCUDA.view(-1, 43),X_testCUDA.view(-1, X_testCUDA.shape[1] )],1))\n",
        "                Ypredtest =  torch.sigmoid(fxtest + (bxtest.T*(G_testCUDA[:,0]+G_testCUDA[:,1])).T)>0.5\n",
        "\n",
        "                Ho = (S_test==1)\n",
        "                Fe = (S_test==0)\n",
        "                odds=Ypredtest.float()[Ho].mean()/ Ypredtest.float()[Fe].mean()\n",
        "                PRULEtest= min(odds, 1/odds)\n",
        "                print('ACC Train',(Ypred==y_trainCUDA).sum()/X_train.shape[0], 'PRULE',PRULE, 'ACC Test',(Ypredtest==y_testCUDA).sum()/X_test.shape[0],'PRULEtest',PRULEtest)\n",
        "        table = np.vstack([table,[num_epochs, betamse, (Ypred.cpu().data.numpy()==y_trainCUDA.cpu().data.numpy()).sum()/X_train.shape[0]*100,PRULE.cpu().data.numpy(),ret.cpu().data.numpy(), \n",
        "                                (Ypredtest.cpu().data.numpy()==y_testCUDA.cpu().data.numpy()).sum()/X_test.shape[0]*100,PRULEtest.cpu().data.numpy(),ret.cpu().data.numpy()]])\n",
        "\n",
        "    np.savetxt('Adult_ProxyFairness', table[1:,])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Epoch:  7 Batch: 43\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  7 Batch: 44\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  7 Batch: 45\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2865, device='cuda:0')\n",
            "Epoch:  7 Batch: 46\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2894, device='cuda:0')\n",
            "Epoch:  7 Batch: 47\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2956, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2905, device='cuda:0')\n",
            "Epoch:  7 Batch: 48\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2908, device='cuda:0')\n",
            "Epoch:  7 Batch: 49\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2980, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2904, device='cuda:0')\n",
            "Epoch:  7 Batch: 50\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2891, device='cuda:0')\n",
            "Epoch:  7 Batch: 51\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2904, device='cuda:0')\n",
            "Epoch:  7 Batch: 52\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2923, device='cuda:0')\n",
            "Epoch:  7 Batch: 53\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2839, device='cuda:0')\n",
            "Epoch:  7 Batch: 54\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  7 Batch: 55\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  7 Batch: 56\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2688, device='cuda:0')\n",
            "Epoch:  7 Batch: 57\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2661, device='cuda:0')\n",
            "Epoch:  7 Batch: 58\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2845, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2647, device='cuda:0')\n",
            "Epoch:  7 Batch: 59\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2654, device='cuda:0')\n",
            "Epoch:  7 Batch: 60\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2637, device='cuda:0')\n",
            "Epoch:  7 Batch: 61\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2841, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2664, device='cuda:0')\n",
            "Epoch:  7 Batch: 62\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2846, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2684, device='cuda:0')\n",
            "Epoch:  7 Batch: 63\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  7 Batch: 64\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  7 Batch: 65\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2700, device='cuda:0')\n",
            "Epoch:  7 Batch: 66\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2735, device='cuda:0')\n",
            "Epoch:  7 Batch: 67\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2716, device='cuda:0')\n",
            "Epoch:  7 Batch: 68\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  7 Batch: 69\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  7 Batch: 70\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  7 Batch: 71\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  7 Batch: 72\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  7 Batch: 73\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2733, device='cuda:0')\n",
            "Epoch:  7 Batch: 74\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2736, device='cuda:0')\n",
            "Epoch:  7 Batch: 75\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8484, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  8 Batch: 0\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8486, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  8 Batch: 1\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  8 Batch: 2\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  8 Batch: 3\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  8 Batch: 4\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  8 Batch: 5\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  8 Batch: 6\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  8 Batch: 7\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  8 Batch: 8\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  8 Batch: 9\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  8 Batch: 10\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  8 Batch: 11\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  8 Batch: 12\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  8 Batch: 13\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2964, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2847, device='cuda:0')\n",
            "Epoch:  8 Batch: 14\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2879, device='cuda:0')\n",
            "Epoch:  8 Batch: 15\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2968, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2860, device='cuda:0')\n",
            "Epoch:  8 Batch: 16\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2870, device='cuda:0')\n",
            "Epoch:  8 Batch: 17\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2997, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2886, device='cuda:0')\n",
            "Epoch:  8 Batch: 18\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2989, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2876, device='cuda:0')\n",
            "Epoch:  8 Batch: 19\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2974, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2868, device='cuda:0')\n",
            "Epoch:  8 Batch: 20\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2878, device='cuda:0')\n",
            "Epoch:  8 Batch: 21\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2878, device='cuda:0')\n",
            "Epoch:  8 Batch: 22\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2881, device='cuda:0')\n",
            "Epoch:  8 Batch: 23\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2970, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2888, device='cuda:0')\n",
            "Epoch:  8 Batch: 24\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2957, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2867, device='cuda:0')\n",
            "Epoch:  8 Batch: 25\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2894, device='cuda:0')\n",
            "Epoch:  8 Batch: 26\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2907, device='cuda:0')\n",
            "Epoch:  8 Batch: 27\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2884, device='cuda:0')\n",
            "Epoch:  8 Batch: 28\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2869, device='cuda:0')\n",
            "Epoch:  8 Batch: 29\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2877, device='cuda:0')\n",
            "Epoch:  8 Batch: 30\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2854, device='cuda:0')\n",
            "Epoch:  8 Batch: 31\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2856, device='cuda:0')\n",
            "Epoch:  8 Batch: 32\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2834, device='cuda:0')\n",
            "Epoch:  8 Batch: 33\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  8 Batch: 34\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  8 Batch: 35\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  8 Batch: 36\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  8 Batch: 37\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  8 Batch: 38\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  8 Batch: 39\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  8 Batch: 40\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  8 Batch: 41\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  8 Batch: 42\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  8 Batch: 43\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  8 Batch: 44\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  8 Batch: 45\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  8 Batch: 46\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  8 Batch: 47\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  8 Batch: 48\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  8 Batch: 49\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  8 Batch: 50\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  8 Batch: 51\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2733, device='cuda:0')\n",
            "Epoch:  8 Batch: 52\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2716, device='cuda:0')\n",
            "Epoch:  8 Batch: 53\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  8 Batch: 54\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2733, device='cuda:0')\n",
            "Epoch:  8 Batch: 55\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  8 Batch: 56\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2700, device='cuda:0')\n",
            "Epoch:  8 Batch: 57\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  8 Batch: 58\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2665, device='cuda:0')\n",
            "Epoch:  8 Batch: 59\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2658, device='cuda:0')\n",
            "Epoch:  8 Batch: 60\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2669, device='cuda:0')\n",
            "Epoch:  8 Batch: 61\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2655, device='cuda:0')\n",
            "Epoch:  8 Batch: 62\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2645, device='cuda:0')\n",
            "Epoch:  8 Batch: 63\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2653, device='cuda:0')\n",
            "Epoch:  8 Batch: 64\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2687, device='cuda:0')\n",
            "Epoch:  8 Batch: 65\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2688, device='cuda:0')\n",
            "Epoch:  8 Batch: 66\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2690, device='cuda:0')\n",
            "Epoch:  8 Batch: 67\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2851, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  8 Batch: 68\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2663, device='cuda:0')\n",
            "Epoch:  8 Batch: 69\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2831, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2679, device='cuda:0')\n",
            "Epoch:  8 Batch: 70\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2829, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2670, device='cuda:0')\n",
            "Epoch:  8 Batch: 71\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2824, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  8 Batch: 72\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2828, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2681, device='cuda:0')\n",
            "Epoch:  8 Batch: 73\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2703, device='cuda:0')\n",
            "Epoch:  8 Batch: 74\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2840, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2685, device='cuda:0')\n",
            "Epoch:  8 Batch: 75\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2840, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2672, device='cuda:0')\n",
            "Epoch:  9 Batch: 0\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2648, device='cuda:0')\n",
            "Epoch:  9 Batch: 1\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2833, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2689, device='cuda:0')\n",
            "Epoch:  9 Batch: 2\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2687, device='cuda:0')\n",
            "Epoch:  9 Batch: 3\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2671, device='cuda:0')\n",
            "Epoch:  9 Batch: 4\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  9 Batch: 5\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2721, device='cuda:0')\n",
            "Epoch:  9 Batch: 6\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  9 Batch: 7\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  9 Batch: 8\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  9 Batch: 9\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  9 Batch: 10\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  9 Batch: 11\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  9 Batch: 12\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  9 Batch: 13\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2964, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  9 Batch: 14\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  9 Batch: 15\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2829, device='cuda:0')\n",
            "Epoch:  9 Batch: 16\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2982, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2834, device='cuda:0')\n",
            "Epoch:  9 Batch: 17\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2973, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2847, device='cuda:0')\n",
            "Epoch:  9 Batch: 18\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2856, device='cuda:0')\n",
            "Epoch:  9 Batch: 19\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2858, device='cuda:0')\n",
            "Epoch:  9 Batch: 20\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  9 Batch: 21\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  9 Batch: 22\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  9 Batch: 23\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  9 Batch: 24\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2855, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  9 Batch: 25\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  9 Batch: 26\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2824, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2718, device='cuda:0')\n",
            "Epoch:  9 Batch: 27\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2823, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2727, device='cuda:0')\n",
            "Epoch:  9 Batch: 28\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2817, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  9 Batch: 29\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2814, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2686, device='cuda:0')\n",
            "Epoch:  9 Batch: 30\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2821, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2689, device='cuda:0')\n",
            "Epoch:  9 Batch: 31\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8491, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  9 Batch: 32\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8488, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  9 Batch: 33\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  9 Batch: 34\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  9 Batch: 35\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  9 Batch: 36\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  9 Batch: 37\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  9 Batch: 38\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2833, device='cuda:0')\n",
            "Epoch:  9 Batch: 39\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2838, device='cuda:0')\n",
            "Epoch:  9 Batch: 40\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  9 Batch: 41\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2883, device='cuda:0')\n",
            "Epoch:  9 Batch: 42\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  9 Batch: 43\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2841, device='cuda:0')\n",
            "Epoch:  9 Batch: 44\n",
            "ACC Train tensor(0.8847, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  9 Batch: 45\n",
            "ACC Train tensor(0.8847, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  9 Batch: 46\n",
            "ACC Train tensor(0.8852, device='cuda:0') PRULE tensor(0.2851, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  9 Batch: 47\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  9 Batch: 48\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  9 Batch: 49\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  9 Batch: 50\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  9 Batch: 51\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  9 Batch: 52\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  9 Batch: 53\n",
            "ACC Train tensor(0.8851, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2701, device='cuda:0')\n",
            "Epoch:  9 Batch: 54\n",
            "ACC Train tensor(0.8847, device='cuda:0') PRULE tensor(0.2862, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2696, device='cuda:0')\n",
            "Epoch:  9 Batch: 55\n",
            "ACC Train tensor(0.8848, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2686, device='cuda:0')\n",
            "Epoch:  9 Batch: 56\n",
            "ACC Train tensor(0.8851, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2690, device='cuda:0')\n",
            "Epoch:  9 Batch: 57\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2690, device='cuda:0')\n",
            "Epoch:  9 Batch: 58\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2700, device='cuda:0')\n",
            "Epoch:  9 Batch: 59\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  9 Batch: 60\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  9 Batch: 61\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  9 Batch: 62\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  9 Batch: 63\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  9 Batch: 64\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  9 Batch: 65\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  9 Batch: 66\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2812, device='cuda:0')\n",
            "Epoch:  9 Batch: 67\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2985, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2852, device='cuda:0')\n",
            "Epoch:  9 Batch: 68\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.3014, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2858, device='cuda:0')\n",
            "Epoch:  9 Batch: 69\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.3041, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2863, device='cuda:0')\n",
            "Epoch:  9 Batch: 70\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.3038, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2853, device='cuda:0')\n",
            "Epoch:  9 Batch: 71\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.3029, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2882, device='cuda:0')\n",
            "Epoch:  9 Batch: 72\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.3017, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2913, device='cuda:0')\n",
            "Epoch:  9 Batch: 73\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.3008, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2913, device='cuda:0')\n",
            "Epoch:  9 Batch: 74\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.3002, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2911, device='cuda:0')\n",
            "Epoch:  9 Batch: 75\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2993, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2901, device='cuda:0')\n",
            "Epoch:  10 Batch: 0\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2970, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2913, device='cuda:0')\n",
            "Epoch:  10 Batch: 1\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2886, device='cuda:0')\n",
            "Epoch:  10 Batch: 2\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2850, device='cuda:0')\n",
            "Epoch:  10 Batch: 3\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2854, device='cuda:0')\n",
            "Epoch:  10 Batch: 4\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2829, device='cuda:0')\n",
            "Epoch:  10 Batch: 5\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  10 Batch: 6\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  10 Batch: 7\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  10 Batch: 8\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  10 Batch: 9\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2714, device='cuda:0')\n",
            "Epoch:  10 Batch: 10\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2686, device='cuda:0')\n",
            "Epoch:  10 Batch: 11\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2684, device='cuda:0')\n",
            "Epoch:  10 Batch: 12\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2705, device='cuda:0')\n",
            "Epoch:  10 Batch: 13\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  10 Batch: 14\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  10 Batch: 15\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  10 Batch: 16\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  10 Batch: 17\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2742, device='cuda:0')\n",
            "Epoch:  10 Batch: 18\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  10 Batch: 19\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  10 Batch: 20\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  10 Batch: 21\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  10 Batch: 22\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  10 Batch: 23\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  10 Batch: 24\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  10 Batch: 25\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  10 Batch: 26\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  10 Batch: 27\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  10 Batch: 28\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  10 Batch: 29\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  10 Batch: 30\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  10 Batch: 31\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  10 Batch: 32\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  10 Batch: 33\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  10 Batch: 34\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  10 Batch: 35\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  10 Batch: 36\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  10 Batch: 37\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  10 Batch: 38\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  10 Batch: 39\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  10 Batch: 40\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  10 Batch: 41\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  10 Batch: 42\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  10 Batch: 43\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  10 Batch: 44\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  10 Batch: 45\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2792, device='cuda:0')\n",
            "Epoch:  10 Batch: 46\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  10 Batch: 47\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  10 Batch: 48\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  10 Batch: 49\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  10 Batch: 50\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  10 Batch: 51\n",
            "ACC Train tensor(0.8848, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2733, device='cuda:0')\n",
            "Epoch:  10 Batch: 52\n",
            "ACC Train tensor(0.8849, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  10 Batch: 53\n",
            "ACC Train tensor(0.8845, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2703, device='cuda:0')\n",
            "Epoch:  10 Batch: 54\n",
            "ACC Train tensor(0.8850, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  10 Batch: 55\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  10 Batch: 56\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2714, device='cuda:0')\n",
            "Epoch:  10 Batch: 57\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2862, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2721, device='cuda:0')\n",
            "Epoch:  10 Batch: 58\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2682, device='cuda:0')\n",
            "Epoch:  10 Batch: 59\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  10 Batch: 60\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  10 Batch: 61\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  10 Batch: 62\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  10 Batch: 63\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  10 Batch: 64\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  10 Batch: 65\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  10 Batch: 66\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  10 Batch: 67\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  10 Batch: 68\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2964, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  10 Batch: 69\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2980, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  10 Batch: 70\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2973, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2837, device='cuda:0')\n",
            "Epoch:  10 Batch: 71\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2834, device='cuda:0')\n",
            "Epoch:  10 Batch: 72\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2985, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2834, device='cuda:0')\n",
            "Epoch:  10 Batch: 73\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2967, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2836, device='cuda:0')\n",
            "Epoch:  10 Batch: 74\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2968, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  10 Batch: 75\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2976, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  11 Batch: 0\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2983, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  11 Batch: 1\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  11 Batch: 2\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2974, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2864, device='cuda:0')\n",
            "Epoch:  11 Batch: 3\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2864, device='cuda:0')\n",
            "Epoch:  11 Batch: 4\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2980, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2894, device='cuda:0')\n",
            "Epoch:  11 Batch: 5\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2987, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2881, device='cuda:0')\n",
            "Epoch:  11 Batch: 6\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2992, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2897, device='cuda:0')\n",
            "Epoch:  11 Batch: 7\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2998, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2904, device='cuda:0')\n",
            "Epoch:  11 Batch: 8\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2994, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2923, device='cuda:0')\n",
            "Epoch:  11 Batch: 9\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2989, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2881, device='cuda:0')\n",
            "Epoch:  11 Batch: 10\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2981, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2886, device='cuda:0')\n",
            "Epoch:  11 Batch: 11\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2875, device='cuda:0')\n",
            "Epoch:  11 Batch: 12\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2968, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2850, device='cuda:0')\n",
            "Epoch:  11 Batch: 13\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2977, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2856, device='cuda:0')\n",
            "Epoch:  11 Batch: 14\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2977, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2857, device='cuda:0')\n",
            "Epoch:  11 Batch: 15\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2984, device='cuda:0') ACC Test tensor(0.8488, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  11 Batch: 16\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8491, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  11 Batch: 17\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8487, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  11 Batch: 18\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2977, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  11 Batch: 19\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  11 Batch: 20\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  11 Batch: 21\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8484, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  11 Batch: 22\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  11 Batch: 23\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  11 Batch: 24\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  11 Batch: 25\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8488, device='cuda:0') PRULEtest tensor(0.2736, device='cuda:0')\n",
            "Epoch:  11 Batch: 26\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8489, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  11 Batch: 27\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8490, device='cuda:0') PRULEtest tensor(0.2702, device='cuda:0')\n",
            "Epoch:  11 Batch: 28\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2706, device='cuda:0')\n",
            "Epoch:  11 Batch: 29\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2706, device='cuda:0')\n",
            "Epoch:  11 Batch: 30\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  11 Batch: 31\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  11 Batch: 32\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  11 Batch: 33\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  11 Batch: 34\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  11 Batch: 35\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  11 Batch: 36\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2846, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  11 Batch: 37\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2834, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  11 Batch: 38\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2844, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  11 Batch: 39\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2846, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  11 Batch: 40\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2837, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  11 Batch: 41\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2833, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  11 Batch: 42\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2833, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  11 Batch: 43\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  11 Batch: 44\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  11 Batch: 45\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2830, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  11 Batch: 46\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2813, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  11 Batch: 47\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2809, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2755, device='cuda:0')\n",
            "Epoch:  11 Batch: 48\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2801, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  11 Batch: 49\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2801, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  11 Batch: 50\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2808, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  11 Batch: 51\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2817, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2712, device='cuda:0')\n",
            "Epoch:  11 Batch: 52\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2824, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  11 Batch: 53\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2831, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  11 Batch: 54\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2845, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  11 Batch: 55\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2851, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  11 Batch: 56\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2760, device='cuda:0')\n",
            "Epoch:  11 Batch: 57\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  11 Batch: 58\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  11 Batch: 59\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  11 Batch: 60\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  11 Batch: 61\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2970, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  11 Batch: 62\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2989, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2819, device='cuda:0')\n",
            "Epoch:  11 Batch: 63\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2977, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  11 Batch: 64\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  11 Batch: 65\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2966, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  11 Batch: 66\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  11 Batch: 67\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  11 Batch: 68\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  11 Batch: 69\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  11 Batch: 70\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  11 Batch: 71\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  11 Batch: 72\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2712, device='cuda:0')\n",
            "Epoch:  11 Batch: 73\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  11 Batch: 74\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  11 Batch: 75\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  12 Batch: 0\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  12 Batch: 1\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  12 Batch: 2\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  12 Batch: 3\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  12 Batch: 4\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  12 Batch: 5\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  12 Batch: 6\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  12 Batch: 7\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  12 Batch: 8\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  12 Batch: 9\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  12 Batch: 10\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  12 Batch: 11\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  12 Batch: 12\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  12 Batch: 13\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  12 Batch: 14\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  12 Batch: 15\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  12 Batch: 16\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  12 Batch: 17\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  12 Batch: 18\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  12 Batch: 19\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  12 Batch: 20\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  12 Batch: 21\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  12 Batch: 22\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  12 Batch: 23\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  12 Batch: 24\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  12 Batch: 25\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  12 Batch: 26\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  12 Batch: 27\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  12 Batch: 28\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  12 Batch: 29\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  12 Batch: 30\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  12 Batch: 31\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  12 Batch: 32\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  12 Batch: 33\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  12 Batch: 34\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  12 Batch: 35\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  12 Batch: 36\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  12 Batch: 37\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  12 Batch: 38\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  12 Batch: 39\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  12 Batch: 40\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  12 Batch: 41\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  12 Batch: 42\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  12 Batch: 43\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  12 Batch: 44\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  12 Batch: 45\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  12 Batch: 46\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  12 Batch: 47\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  12 Batch: 48\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  12 Batch: 49\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  12 Batch: 50\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  12 Batch: 51\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  12 Batch: 52\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2751, device='cuda:0')\n",
            "Epoch:  12 Batch: 53\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  12 Batch: 54\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  12 Batch: 55\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  12 Batch: 56\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  12 Batch: 57\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  12 Batch: 58\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  12 Batch: 59\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  12 Batch: 60\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  12 Batch: 61\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  12 Batch: 62\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  12 Batch: 63\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  12 Batch: 64\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  12 Batch: 65\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2966, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  12 Batch: 66\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2976, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  12 Batch: 67\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2982, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  12 Batch: 68\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2989, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  12 Batch: 69\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  12 Batch: 70\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  12 Batch: 71\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  12 Batch: 72\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  12 Batch: 73\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  12 Batch: 74\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  12 Batch: 75\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  13 Batch: 0\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  13 Batch: 1\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  13 Batch: 2\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  13 Batch: 3\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  13 Batch: 4\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  13 Batch: 5\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2841, device='cuda:0')\n",
            "Epoch:  13 Batch: 6\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  13 Batch: 7\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  13 Batch: 8\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  13 Batch: 9\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  13 Batch: 10\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  13 Batch: 11\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  13 Batch: 12\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  13 Batch: 13\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2813, device='cuda:0')\n",
            "Epoch:  13 Batch: 14\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  13 Batch: 15\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2812, device='cuda:0')\n",
            "Epoch:  13 Batch: 16\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  13 Batch: 17\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  13 Batch: 18\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  13 Batch: 19\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  13 Batch: 20\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  13 Batch: 21\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2983, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  13 Batch: 22\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2985, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  13 Batch: 23\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2964, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  13 Batch: 24\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  13 Batch: 25\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  13 Batch: 26\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  13 Batch: 27\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  13 Batch: 28\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  13 Batch: 29\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  13 Batch: 30\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  13 Batch: 31\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  13 Batch: 32\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  13 Batch: 33\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  13 Batch: 34\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  13 Batch: 35\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2751, device='cuda:0')\n",
            "Epoch:  13 Batch: 36\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  13 Batch: 37\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  13 Batch: 38\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  13 Batch: 39\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2956, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  13 Batch: 40\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2829, device='cuda:0')\n",
            "Epoch:  13 Batch: 41\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  13 Batch: 42\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2976, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  13 Batch: 43\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2841, device='cuda:0')\n",
            "Epoch:  13 Batch: 44\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  13 Batch: 45\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  13 Batch: 46\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  13 Batch: 47\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  13 Batch: 48\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  13 Batch: 49\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  13 Batch: 50\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  13 Batch: 51\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  13 Batch: 52\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  13 Batch: 53\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2728, device='cuda:0')\n",
            "Epoch:  13 Batch: 54\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2717, device='cuda:0')\n",
            "Epoch:  13 Batch: 55\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  13 Batch: 56\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  13 Batch: 57\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  13 Batch: 58\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  13 Batch: 59\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  13 Batch: 60\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8431, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  13 Batch: 61\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2728, device='cuda:0')\n",
            "Epoch:  13 Batch: 62\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  13 Batch: 63\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  13 Batch: 64\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  13 Batch: 65\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  13 Batch: 66\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  13 Batch: 67\n",
            "ACC Train tensor(0.8848, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2877, device='cuda:0')\n",
            "Epoch:  13 Batch: 68\n",
            "ACC Train tensor(0.8839, device='cuda:0') PRULE tensor(0.2992, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2880, device='cuda:0')\n",
            "Epoch:  13 Batch: 69\n",
            "ACC Train tensor(0.8832, device='cuda:0') PRULE tensor(0.2986, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2884, device='cuda:0')\n",
            "Epoch:  13 Batch: 70\n",
            "ACC Train tensor(0.8839, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2946, device='cuda:0')\n",
            "Epoch:  13 Batch: 71\n",
            "ACC Train tensor(0.8848, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2896, device='cuda:0')\n",
            "Epoch:  13 Batch: 72\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2894, device='cuda:0')\n",
            "Epoch:  13 Batch: 73\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2889, device='cuda:0')\n",
            "Epoch:  13 Batch: 74\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2852, device='cuda:0')\n",
            "Epoch:  13 Batch: 75\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  14 Batch: 0\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  14 Batch: 1\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  14 Batch: 2\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  14 Batch: 3\n",
            "ACC Train tensor(0.8851, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  14 Batch: 4\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  14 Batch: 5\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  14 Batch: 6\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  14 Batch: 7\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  14 Batch: 8\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  14 Batch: 9\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2812, device='cuda:0')\n",
            "Epoch:  14 Batch: 10\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  14 Batch: 11\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  14 Batch: 12\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2843, device='cuda:0')\n",
            "Epoch:  14 Batch: 13\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  14 Batch: 14\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  14 Batch: 15\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  14 Batch: 16\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  14 Batch: 17\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  14 Batch: 18\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  14 Batch: 19\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2717, device='cuda:0')\n",
            "Epoch:  14 Batch: 20\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  14 Batch: 21\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  14 Batch: 22\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  14 Batch: 23\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  14 Batch: 24\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  14 Batch: 25\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  14 Batch: 26\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  14 Batch: 27\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  14 Batch: 28\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  14 Batch: 29\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  14 Batch: 30\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  14 Batch: 31\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  14 Batch: 32\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  14 Batch: 33\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  14 Batch: 34\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  14 Batch: 35\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  14 Batch: 36\n",
            "ACC Train tensor(0.8852, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  14 Batch: 37\n",
            "ACC Train tensor(0.8852, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  14 Batch: 38\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  14 Batch: 39\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  14 Batch: 40\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  14 Batch: 41\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  14 Batch: 42\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  14 Batch: 43\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8485, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  14 Batch: 44\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2845, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  14 Batch: 45\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  14 Batch: 46\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2844, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  14 Batch: 47\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  14 Batch: 48\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2751, device='cuda:0')\n",
            "Epoch:  14 Batch: 49\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  14 Batch: 50\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  14 Batch: 51\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  14 Batch: 52\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  14 Batch: 53\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  14 Batch: 54\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  14 Batch: 55\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  14 Batch: 56\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  14 Batch: 57\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  14 Batch: 58\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  14 Batch: 59\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2755, device='cuda:0')\n",
            "Epoch:  14 Batch: 60\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  14 Batch: 61\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  14 Batch: 62\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  14 Batch: 63\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  14 Batch: 64\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  14 Batch: 65\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  14 Batch: 66\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  14 Batch: 67\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2836, device='cuda:0')\n",
            "Epoch:  14 Batch: 68\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  14 Batch: 69\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  14 Batch: 70\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  14 Batch: 71\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  14 Batch: 72\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  14 Batch: 73\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  14 Batch: 74\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  14 Batch: 75\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2742, device='cuda:0')\n",
            "Epoch:  15 Batch: 0\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  15 Batch: 1\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  15 Batch: 2\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  15 Batch: 3\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  15 Batch: 4\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  15 Batch: 5\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  15 Batch: 6\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  15 Batch: 7\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  15 Batch: 8\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2972, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2847, device='cuda:0')\n",
            "Epoch:  15 Batch: 9\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2847, device='cuda:0')\n",
            "Epoch:  15 Batch: 10\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2978, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  15 Batch: 11\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2974, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  15 Batch: 12\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2986, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  15 Batch: 13\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  15 Batch: 14\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  15 Batch: 15\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  15 Batch: 16\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  15 Batch: 17\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  15 Batch: 18\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  15 Batch: 19\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  15 Batch: 20\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2690, device='cuda:0')\n",
            "Epoch:  15 Batch: 21\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2675, device='cuda:0')\n",
            "Epoch:  15 Batch: 22\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2679, device='cuda:0')\n",
            "Epoch:  15 Batch: 23\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2687, device='cuda:0')\n",
            "Epoch:  15 Batch: 24\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2688, device='cuda:0')\n",
            "Epoch:  15 Batch: 25\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2696, device='cuda:0')\n",
            "Epoch:  15 Batch: 26\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2846, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  15 Batch: 27\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2696, device='cuda:0')\n",
            "Epoch:  15 Batch: 28\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2686, device='cuda:0')\n",
            "Epoch:  15 Batch: 29\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2704, device='cuda:0')\n",
            "Epoch:  15 Batch: 30\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  15 Batch: 31\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  15 Batch: 32\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  15 Batch: 33\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  15 Batch: 34\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  15 Batch: 35\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  15 Batch: 36\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  15 Batch: 37\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2807, device='cuda:0')\n",
            "Epoch:  15 Batch: 38\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  15 Batch: 39\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  15 Batch: 40\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2844, device='cuda:0')\n",
            "Epoch:  15 Batch: 41\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2968, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2839, device='cuda:0')\n",
            "Epoch:  15 Batch: 42\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2851, device='cuda:0')\n",
            "Epoch:  15 Batch: 43\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.3004, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2833, device='cuda:0')\n",
            "Epoch:  15 Batch: 44\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.3019, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2839, device='cuda:0')\n",
            "Epoch:  15 Batch: 45\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.3038, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2843, device='cuda:0')\n",
            "Epoch:  15 Batch: 46\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.3041, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  15 Batch: 47\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.3062, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2847, device='cuda:0')\n",
            "Epoch:  15 Batch: 48\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.3065, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2894, device='cuda:0')\n",
            "Epoch:  15 Batch: 49\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.3063, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2908, device='cuda:0')\n",
            "Epoch:  15 Batch: 50\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.3063, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2891, device='cuda:0')\n",
            "Epoch:  15 Batch: 51\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.3029, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2874, device='cuda:0')\n",
            "Epoch:  15 Batch: 52\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.3020, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2849, device='cuda:0')\n",
            "Epoch:  15 Batch: 53\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.3015, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2850, device='cuda:0')\n",
            "Epoch:  15 Batch: 54\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2988, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2857, device='cuda:0')\n",
            "Epoch:  15 Batch: 55\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  15 Batch: 56\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2958, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  15 Batch: 57\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  15 Batch: 58\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  15 Batch: 59\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  15 Batch: 60\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  15 Batch: 61\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2718, device='cuda:0')\n",
            "Epoch:  15 Batch: 62\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  15 Batch: 63\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2692, device='cuda:0')\n",
            "Epoch:  15 Batch: 64\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2703, device='cuda:0')\n",
            "Epoch:  15 Batch: 65\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  15 Batch: 66\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  15 Batch: 67\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  15 Batch: 68\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  15 Batch: 69\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  15 Batch: 70\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  15 Batch: 71\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  15 Batch: 72\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2853, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2690, device='cuda:0')\n",
            "Epoch:  15 Batch: 73\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2703, device='cuda:0')\n",
            "Epoch:  15 Batch: 74\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2709, device='cuda:0')\n",
            "Epoch:  15 Batch: 75\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  16 Batch: 0\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2742, device='cuda:0')\n",
            "Epoch:  16 Batch: 1\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  16 Batch: 2\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  16 Batch: 3\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  16 Batch: 4\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  16 Batch: 5\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  16 Batch: 6\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  16 Batch: 7\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  16 Batch: 8\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2819, device='cuda:0')\n",
            "Epoch:  16 Batch: 9\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  16 Batch: 10\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  16 Batch: 11\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  16 Batch: 12\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2862, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  16 Batch: 13\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  16 Batch: 14\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2841, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  16 Batch: 15\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2822, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  16 Batch: 16\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  16 Batch: 17\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  16 Batch: 18\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  16 Batch: 19\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  16 Batch: 20\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  16 Batch: 21\n",
            "ACC Train tensor(0.8848, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  16 Batch: 22\n",
            "ACC Train tensor(0.8842, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  16 Batch: 23\n",
            "ACC Train tensor(0.8836, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  16 Batch: 24\n",
            "ACC Train tensor(0.8841, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  16 Batch: 25\n",
            "ACC Train tensor(0.8852, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  16 Batch: 26\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2707, device='cuda:0')\n",
            "Epoch:  16 Batch: 27\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  16 Batch: 28\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  16 Batch: 29\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  16 Batch: 30\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  16 Batch: 31\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  16 Batch: 32\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  16 Batch: 33\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  16 Batch: 34\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  16 Batch: 35\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  16 Batch: 36\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  16 Batch: 37\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  16 Batch: 38\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  16 Batch: 39\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  16 Batch: 40\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  16 Batch: 41\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  16 Batch: 42\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2819, device='cuda:0')\n",
            "Epoch:  16 Batch: 43\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  16 Batch: 44\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  16 Batch: 45\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  16 Batch: 46\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  16 Batch: 47\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  16 Batch: 48\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  16 Batch: 49\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  16 Batch: 50\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  16 Batch: 51\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  16 Batch: 52\n",
            "ACC Train tensor(0.8850, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  16 Batch: 53\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  16 Batch: 54\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  16 Batch: 55\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  16 Batch: 56\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2807, device='cuda:0')\n",
            "Epoch:  16 Batch: 57\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  16 Batch: 58\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  16 Batch: 59\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  16 Batch: 60\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  16 Batch: 61\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  16 Batch: 62\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  16 Batch: 63\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  16 Batch: 64\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  16 Batch: 65\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  16 Batch: 66\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  16 Batch: 67\n",
            "ACC Train tensor(0.8849, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  16 Batch: 68\n",
            "ACC Train tensor(0.8849, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  16 Batch: 69\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  16 Batch: 70\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2807, device='cuda:0')\n",
            "Epoch:  16 Batch: 71\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  16 Batch: 72\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  16 Batch: 73\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  16 Batch: 74\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2807, device='cuda:0')\n",
            "Epoch:  16 Batch: 75\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2813, device='cuda:0')\n",
            "Epoch:  17 Batch: 0\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  17 Batch: 1\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  17 Batch: 2\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  17 Batch: 3\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2957, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  17 Batch: 4\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  17 Batch: 5\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2833, device='cuda:0')\n",
            "Epoch:  17 Batch: 6\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  17 Batch: 7\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  17 Batch: 8\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  17 Batch: 9\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  17 Batch: 10\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  17 Batch: 11\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  17 Batch: 12\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  17 Batch: 13\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  17 Batch: 14\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  17 Batch: 15\n",
            "ACC Train tensor(0.8852, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  17 Batch: 16\n",
            "ACC Train tensor(0.8849, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  17 Batch: 17\n",
            "ACC Train tensor(0.8849, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  17 Batch: 18\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  17 Batch: 19\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  17 Batch: 20\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  17 Batch: 21\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  17 Batch: 22\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  17 Batch: 23\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  17 Batch: 24\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2856, device='cuda:0')\n",
            "Epoch:  17 Batch: 25\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  17 Batch: 26\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  17 Batch: 27\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2838, device='cuda:0')\n",
            "Epoch:  17 Batch: 28\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  17 Batch: 29\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  17 Batch: 30\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  17 Batch: 31\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  17 Batch: 32\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  17 Batch: 33\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  17 Batch: 34\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  17 Batch: 35\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  17 Batch: 36\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8483, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  17 Batch: 37\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  17 Batch: 38\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8483, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  17 Batch: 39\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2854, device='cuda:0')\n",
            "Epoch:  17 Batch: 40\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  17 Batch: 41\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  17 Batch: 42\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  17 Batch: 43\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2812, device='cuda:0')\n",
            "Epoch:  17 Batch: 44\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2958, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  17 Batch: 45\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2968, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  17 Batch: 46\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  17 Batch: 47\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  17 Batch: 48\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  17 Batch: 49\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  17 Batch: 50\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  17 Batch: 51\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  17 Batch: 52\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2719, device='cuda:0')\n",
            "Epoch:  17 Batch: 53\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2828, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2699, device='cuda:0')\n",
            "Epoch:  17 Batch: 54\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2817, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2687, device='cuda:0')\n",
            "Epoch:  17 Batch: 55\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2807, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2672, device='cuda:0')\n",
            "Epoch:  17 Batch: 56\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2805, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  17 Batch: 57\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2824, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2701, device='cuda:0')\n",
            "Epoch:  17 Batch: 58\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2676, device='cuda:0')\n",
            "Epoch:  17 Batch: 59\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2853, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2717, device='cuda:0')\n",
            "Epoch:  17 Batch: 60\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  17 Batch: 61\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  17 Batch: 62\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  17 Batch: 63\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  17 Batch: 64\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  17 Batch: 65\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  17 Batch: 66\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  17 Batch: 67\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2857, device='cuda:0') ACC Test tensor(0.8485, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  17 Batch: 68\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2842, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2709, device='cuda:0')\n",
            "Epoch:  17 Batch: 69\n",
            "ACC Train tensor(0.8848, device='cuda:0') PRULE tensor(0.2834, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2718, device='cuda:0')\n",
            "Epoch:  17 Batch: 70\n",
            "ACC Train tensor(0.8850, device='cuda:0') PRULE tensor(0.2842, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2718, device='cuda:0')\n",
            "Epoch:  17 Batch: 71\n",
            "ACC Train tensor(0.8852, device='cuda:0') PRULE tensor(0.2857, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  17 Batch: 72\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  17 Batch: 73\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  17 Batch: 74\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  17 Batch: 75\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8484, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  18 Batch: 0\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  18 Batch: 1\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  18 Batch: 2\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  18 Batch: 3\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2958, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  18 Batch: 4\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2974, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  18 Batch: 5\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2980, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  18 Batch: 6\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2985, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2792, device='cuda:0')\n",
            "Epoch:  18 Batch: 7\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8483, device='cuda:0') PRULEtest tensor(0.2852, device='cuda:0')\n",
            "Epoch:  18 Batch: 8\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2853, device='cuda:0')\n",
            "Epoch:  18 Batch: 9\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2845, device='cuda:0')\n",
            "Epoch:  18 Batch: 10\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  18 Batch: 11\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  18 Batch: 12\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  18 Batch: 13\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  18 Batch: 14\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  18 Batch: 15\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  18 Batch: 16\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  18 Batch: 17\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  18 Batch: 18\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  18 Batch: 19\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  18 Batch: 20\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2964, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  18 Batch: 21\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  18 Batch: 22\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  18 Batch: 23\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  18 Batch: 24\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  18 Batch: 25\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  18 Batch: 26\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8488, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  18 Batch: 27\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2957, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  18 Batch: 28\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  18 Batch: 29\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  18 Batch: 30\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2970, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2812, device='cuda:0')\n",
            "Epoch:  18 Batch: 31\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2967, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2844, device='cuda:0')\n",
            "Epoch:  18 Batch: 32\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2967, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2829, device='cuda:0')\n",
            "Epoch:  18 Batch: 33\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  18 Batch: 34\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  18 Batch: 35\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  18 Batch: 36\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2851, device='cuda:0')\n",
            "Epoch:  18 Batch: 37\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2966, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2849, device='cuda:0')\n",
            "Epoch:  18 Batch: 38\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2872, device='cuda:0')\n",
            "Epoch:  18 Batch: 39\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2864, device='cuda:0')\n",
            "Epoch:  18 Batch: 40\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2852, device='cuda:0')\n",
            "Epoch:  18 Batch: 41\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2875, device='cuda:0')\n",
            "Epoch:  18 Batch: 42\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2880, device='cuda:0')\n",
            "Epoch:  18 Batch: 43\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2863, device='cuda:0')\n",
            "Epoch:  18 Batch: 44\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2846, device='cuda:0')\n",
            "Epoch:  18 Batch: 45\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2958, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  18 Batch: 46\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  18 Batch: 47\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  18 Batch: 48\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  18 Batch: 49\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2833, device='cuda:0')\n",
            "Epoch:  18 Batch: 50\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2853, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  18 Batch: 51\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  18 Batch: 52\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  18 Batch: 53\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2849, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  18 Batch: 54\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  18 Batch: 55\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  18 Batch: 56\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  18 Batch: 57\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  18 Batch: 58\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  18 Batch: 59\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  18 Batch: 60\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  18 Batch: 61\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2813, device='cuda:0')\n",
            "Epoch:  18 Batch: 62\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  18 Batch: 63\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  18 Batch: 64\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2957, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  18 Batch: 65\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  18 Batch: 66\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  18 Batch: 67\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  18 Batch: 68\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  18 Batch: 69\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  18 Batch: 70\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2725, device='cuda:0')\n",
            "Epoch:  18 Batch: 71\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2712, device='cuda:0')\n",
            "Epoch:  18 Batch: 72\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2707, device='cuda:0')\n",
            "Epoch:  18 Batch: 73\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  18 Batch: 74\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2628, device='cuda:0')\n",
            "Epoch:  18 Batch: 75\n",
            "ACC Train tensor(0.8849, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2627, device='cuda:0')\n",
            "Epoch:  19 Batch: 0\n",
            "ACC Train tensor(0.8843, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2642, device='cuda:0')\n",
            "Epoch:  19 Batch: 1\n",
            "ACC Train tensor(0.8841, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2645, device='cuda:0')\n",
            "Epoch:  19 Batch: 2\n",
            "ACC Train tensor(0.8844, device='cuda:0') PRULE tensor(0.2851, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2645, device='cuda:0')\n",
            "Epoch:  19 Batch: 3\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2846, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2648, device='cuda:0')\n",
            "Epoch:  19 Batch: 4\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2837, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2644, device='cuda:0')\n",
            "Epoch:  19 Batch: 5\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2670, device='cuda:0')\n",
            "Epoch:  19 Batch: 6\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2819, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  19 Batch: 7\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2834, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2702, device='cuda:0')\n",
            "Epoch:  19 Batch: 8\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2855, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  19 Batch: 9\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  19 Batch: 10\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  19 Batch: 11\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  19 Batch: 12\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  19 Batch: 13\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  19 Batch: 14\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  19 Batch: 15\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  19 Batch: 16\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  19 Batch: 17\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8485, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  19 Batch: 18\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8483, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  19 Batch: 19\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8484, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  19 Batch: 20\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  19 Batch: 21\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  19 Batch: 22\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8486, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  19 Batch: 23\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8484, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  19 Batch: 24\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  19 Batch: 25\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  19 Batch: 26\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  19 Batch: 27\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  19 Batch: 28\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  19 Batch: 29\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  19 Batch: 30\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  19 Batch: 31\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2717, device='cuda:0')\n",
            "Epoch:  19 Batch: 32\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2699, device='cuda:0')\n",
            "Epoch:  19 Batch: 33\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2685, device='cuda:0')\n",
            "Epoch:  19 Batch: 34\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2862, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2702, device='cuda:0')\n",
            "Epoch:  19 Batch: 35\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2855, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2707, device='cuda:0')\n",
            "Epoch:  19 Batch: 36\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  19 Batch: 37\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2721, device='cuda:0')\n",
            "Epoch:  19 Batch: 38\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2833, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  19 Batch: 39\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2849, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2703, device='cuda:0')\n",
            "Epoch:  19 Batch: 40\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2719, device='cuda:0')\n",
            "Epoch:  19 Batch: 41\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  19 Batch: 42\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  19 Batch: 43\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2755, device='cuda:0')\n",
            "Epoch:  19 Batch: 44\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  19 Batch: 45\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  19 Batch: 46\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  19 Batch: 47\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  19 Batch: 48\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2839, device='cuda:0')\n",
            "Epoch:  19 Batch: 49\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  19 Batch: 50\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  19 Batch: 51\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  19 Batch: 52\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  19 Batch: 53\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  19 Batch: 54\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  19 Batch: 55\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  19 Batch: 56\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  19 Batch: 57\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  19 Batch: 58\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2974, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  19 Batch: 59\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.3004, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2937, device='cuda:0')\n",
            "Epoch:  19 Batch: 60\n",
            "ACC Train tensor(0.8848, device='cuda:0') PRULE tensor(0.3041, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2940, device='cuda:0')\n",
            "Epoch:  19 Batch: 61\n",
            "ACC Train tensor(0.8848, device='cuda:0') PRULE tensor(0.3060, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2952, device='cuda:0')\n",
            "Epoch:  19 Batch: 62\n",
            "ACC Train tensor(0.8852, device='cuda:0') PRULE tensor(0.3050, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2935, device='cuda:0')\n",
            "Epoch:  19 Batch: 63\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.3026, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2882, device='cuda:0')\n",
            "Epoch:  19 Batch: 64\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2990, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2849, device='cuda:0')\n",
            "Epoch:  19 Batch: 65\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  19 Batch: 66\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  19 Batch: 67\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  19 Batch: 68\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  19 Batch: 69\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  19 Batch: 70\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2706, device='cuda:0')\n",
            "Epoch:  19 Batch: 71\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2830, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  19 Batch: 72\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2814, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2669, device='cuda:0')\n",
            "Epoch:  19 Batch: 73\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2807, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2664, device='cuda:0')\n",
            "Epoch:  19 Batch: 74\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2813, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2634, device='cuda:0')\n",
            "Epoch:  19 Batch: 75\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2810, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2640, device='cuda:0')\n",
            "Epoch:  20 Batch: 0\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2821, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2663, device='cuda:0')\n",
            "Epoch:  20 Batch: 1\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2824, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2636, device='cuda:0')\n",
            "Epoch:  20 Batch: 2\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2829, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2673, device='cuda:0')\n",
            "Epoch:  20 Batch: 3\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2660, device='cuda:0')\n",
            "Epoch:  20 Batch: 4\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2855, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2655, device='cuda:0')\n",
            "Epoch:  20 Batch: 5\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2659, device='cuda:0')\n",
            "Epoch:  20 Batch: 6\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2695, device='cuda:0')\n",
            "Epoch:  20 Batch: 7\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2692, device='cuda:0')\n",
            "Epoch:  20 Batch: 8\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2700, device='cuda:0')\n",
            "Epoch:  20 Batch: 9\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2694, device='cuda:0')\n",
            "Epoch:  20 Batch: 10\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  20 Batch: 11\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2702, device='cuda:0')\n",
            "Epoch:  20 Batch: 12\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2725, device='cuda:0')\n",
            "Epoch:  20 Batch: 13\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  20 Batch: 14\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  20 Batch: 15\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  20 Batch: 16\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  20 Batch: 17\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  20 Batch: 18\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  20 Batch: 19\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2857, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  20 Batch: 20\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  20 Batch: 21\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2706, device='cuda:0')\n",
            "Epoch:  20 Batch: 22\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  20 Batch: 23\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  20 Batch: 24\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2849, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  20 Batch: 25\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2725, device='cuda:0')\n",
            "Epoch:  20 Batch: 26\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2844, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2716, device='cuda:0')\n",
            "Epoch:  20 Batch: 27\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  20 Batch: 28\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  20 Batch: 29\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2733, device='cuda:0')\n",
            "Epoch:  20 Batch: 30\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2751, device='cuda:0')\n",
            "Epoch:  20 Batch: 31\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  20 Batch: 32\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  20 Batch: 33\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  20 Batch: 34\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8431, device='cuda:0') PRULEtest tensor(0.2792, device='cuda:0')\n",
            "Epoch:  20 Batch: 35\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8433, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  20 Batch: 36\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  20 Batch: 37\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  20 Batch: 38\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  20 Batch: 39\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  20 Batch: 40\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2956, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2861, device='cuda:0')\n",
            "Epoch:  20 Batch: 41\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2846, device='cuda:0')\n",
            "Epoch:  20 Batch: 42\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2862, device='cuda:0')\n",
            "Epoch:  20 Batch: 43\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2848, device='cuda:0')\n",
            "Epoch:  20 Batch: 44\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2841, device='cuda:0')\n",
            "Epoch:  20 Batch: 45\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  20 Batch: 46\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2972, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  20 Batch: 47\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2973, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  20 Batch: 48\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  20 Batch: 49\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  20 Batch: 50\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  20 Batch: 51\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2751, device='cuda:0')\n",
            "Epoch:  20 Batch: 52\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  20 Batch: 53\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  20 Batch: 54\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  20 Batch: 55\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2845, device='cuda:0')\n",
            "Epoch:  20 Batch: 56\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  20 Batch: 57\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  20 Batch: 58\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2867, device='cuda:0')\n",
            "Epoch:  20 Batch: 59\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  20 Batch: 60\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  20 Batch: 61\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2721, device='cuda:0')\n",
            "Epoch:  20 Batch: 62\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2681, device='cuda:0')\n",
            "Epoch:  20 Batch: 63\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2692, device='cuda:0')\n",
            "Epoch:  20 Batch: 64\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2666, device='cuda:0')\n",
            "Epoch:  20 Batch: 65\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2668, device='cuda:0')\n",
            "Epoch:  20 Batch: 66\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2668, device='cuda:0')\n",
            "Epoch:  20 Batch: 67\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2681, device='cuda:0')\n",
            "Epoch:  20 Batch: 68\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2712, device='cuda:0')\n",
            "Epoch:  20 Batch: 69\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  20 Batch: 70\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  20 Batch: 71\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2844, device='cuda:0')\n",
            "Epoch:  20 Batch: 72\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2858, device='cuda:0')\n",
            "Epoch:  20 Batch: 73\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2874, device='cuda:0')\n",
            "Epoch:  20 Batch: 74\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  20 Batch: 75\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2836, device='cuda:0')\n",
            "Epoch:  21 Batch: 0\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  21 Batch: 1\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2842, device='cuda:0')\n",
            "Epoch:  21 Batch: 2\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  21 Batch: 3\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8487, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  21 Batch: 4\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  21 Batch: 5\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8484, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  21 Batch: 6\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  21 Batch: 7\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  21 Batch: 8\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  21 Batch: 9\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  21 Batch: 10\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  21 Batch: 11\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  21 Batch: 12\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2857, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2727, device='cuda:0')\n",
            "Epoch:  21 Batch: 13\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  21 Batch: 14\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2705, device='cuda:0')\n",
            "Epoch:  21 Batch: 15\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  21 Batch: 16\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  21 Batch: 17\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2714, device='cuda:0')\n",
            "Epoch:  21 Batch: 18\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2698, device='cuda:0')\n",
            "Epoch:  21 Batch: 19\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2691, device='cuda:0')\n",
            "Epoch:  21 Batch: 20\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2678, device='cuda:0')\n",
            "Epoch:  21 Batch: 21\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2679, device='cuda:0')\n",
            "Epoch:  21 Batch: 22\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2717, device='cuda:0')\n",
            "Epoch:  21 Batch: 23\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  21 Batch: 24\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  21 Batch: 25\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  21 Batch: 26\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  21 Batch: 27\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  21 Batch: 28\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  21 Batch: 29\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  21 Batch: 30\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  21 Batch: 31\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  21 Batch: 32\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  21 Batch: 33\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  21 Batch: 34\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2973, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  21 Batch: 35\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  21 Batch: 36\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  21 Batch: 37\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  21 Batch: 38\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  21 Batch: 39\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  21 Batch: 40\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2812, device='cuda:0')\n",
            "Epoch:  21 Batch: 41\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  21 Batch: 42\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  21 Batch: 43\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  21 Batch: 44\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  21 Batch: 45\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  21 Batch: 46\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2853, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2718, device='cuda:0')\n",
            "Epoch:  21 Batch: 47\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  21 Batch: 48\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2842, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2719, device='cuda:0')\n",
            "Epoch:  21 Batch: 49\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2846, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  21 Batch: 50\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2846, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  21 Batch: 51\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2830, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  21 Batch: 52\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  21 Batch: 53\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  21 Batch: 54\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2837, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  21 Batch: 55\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2857, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  21 Batch: 56\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  21 Batch: 57\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  21 Batch: 58\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  21 Batch: 59\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  21 Batch: 60\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  21 Batch: 61\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  21 Batch: 62\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  21 Batch: 63\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2841, device='cuda:0')\n",
            "Epoch:  21 Batch: 64\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2883, device='cuda:0')\n",
            "Epoch:  21 Batch: 65\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2878, device='cuda:0')\n",
            "Epoch:  21 Batch: 66\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2868, device='cuda:0')\n",
            "Epoch:  21 Batch: 67\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2852, device='cuda:0')\n",
            "Epoch:  21 Batch: 68\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2853, device='cuda:0')\n",
            "Epoch:  21 Batch: 69\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2866, device='cuda:0')\n",
            "Epoch:  21 Batch: 70\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  21 Batch: 71\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2843, device='cuda:0')\n",
            "Epoch:  21 Batch: 72\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2840, device='cuda:0')\n",
            "Epoch:  21 Batch: 73\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2843, device='cuda:0')\n",
            "Epoch:  21 Batch: 74\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2856, device='cuda:0')\n",
            "Epoch:  21 Batch: 75\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2880, device='cuda:0')\n",
            "Epoch:  22 Batch: 0\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  22 Batch: 1\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  22 Batch: 2\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2807, device='cuda:0')\n",
            "Epoch:  22 Batch: 3\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  22 Batch: 4\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  22 Batch: 5\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  22 Batch: 6\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2755, device='cuda:0')\n",
            "Epoch:  22 Batch: 7\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  22 Batch: 8\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  22 Batch: 9\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  22 Batch: 10\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2735, device='cuda:0')\n",
            "Epoch:  22 Batch: 11\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2751, device='cuda:0')\n",
            "Epoch:  22 Batch: 12\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  22 Batch: 13\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  22 Batch: 14\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  22 Batch: 15\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  22 Batch: 16\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  22 Batch: 17\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  22 Batch: 18\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  22 Batch: 19\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2819, device='cuda:0')\n",
            "Epoch:  22 Batch: 20\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2852, device='cuda:0')\n",
            "Epoch:  22 Batch: 21\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2883, device='cuda:0')\n",
            "Epoch:  22 Batch: 22\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2892, device='cuda:0')\n",
            "Epoch:  22 Batch: 23\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2986, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2924, device='cuda:0')\n",
            "Epoch:  22 Batch: 24\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.3016, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2922, device='cuda:0')\n",
            "Epoch:  22 Batch: 25\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.3009, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2922, device='cuda:0')\n",
            "Epoch:  22 Batch: 26\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.3008, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2906, device='cuda:0')\n",
            "Epoch:  22 Batch: 27\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2988, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2889, device='cuda:0')\n",
            "Epoch:  22 Batch: 28\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2992, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2887, device='cuda:0')\n",
            "Epoch:  22 Batch: 29\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.3001, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2884, device='cuda:0')\n",
            "Epoch:  22 Batch: 30\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2879, device='cuda:0')\n",
            "Epoch:  22 Batch: 31\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2860, device='cuda:0')\n",
            "Epoch:  22 Batch: 32\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2844, device='cuda:0')\n",
            "Epoch:  22 Batch: 33\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  22 Batch: 34\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  22 Batch: 35\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  22 Batch: 36\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  22 Batch: 37\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2974, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  22 Batch: 38\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2976, device='cuda:0') ACC Test tensor(0.8484, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  22 Batch: 39\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2974, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2838, device='cuda:0')\n",
            "Epoch:  22 Batch: 40\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  22 Batch: 41\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2972, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  22 Batch: 42\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  22 Batch: 43\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  22 Batch: 44\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  22 Batch: 45\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  22 Batch: 46\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  22 Batch: 47\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  22 Batch: 48\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  22 Batch: 49\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  22 Batch: 50\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  22 Batch: 51\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  22 Batch: 52\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  22 Batch: 53\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  22 Batch: 54\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  22 Batch: 55\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  22 Batch: 56\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  22 Batch: 57\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  22 Batch: 58\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  22 Batch: 59\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  22 Batch: 60\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  22 Batch: 61\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  22 Batch: 62\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  22 Batch: 63\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  22 Batch: 64\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  22 Batch: 65\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2760, device='cuda:0')\n",
            "Epoch:  22 Batch: 66\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  22 Batch: 67\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  22 Batch: 68\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2689, device='cuda:0')\n",
            "Epoch:  22 Batch: 69\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2957, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  22 Batch: 70\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2694, device='cuda:0')\n",
            "Epoch:  22 Batch: 71\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  22 Batch: 72\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2693, device='cuda:0')\n",
            "Epoch:  22 Batch: 73\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2691, device='cuda:0')\n",
            "Epoch:  22 Batch: 74\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2695, device='cuda:0')\n",
            "Epoch:  22 Batch: 75\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2704, device='cuda:0')\n",
            "Epoch:  23 Batch: 0\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  23 Batch: 1\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  23 Batch: 2\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2716, device='cuda:0')\n",
            "Epoch:  23 Batch: 3\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2727, device='cuda:0')\n",
            "Epoch:  23 Batch: 4\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2728, device='cuda:0')\n",
            "Epoch:  23 Batch: 5\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2727, device='cuda:0')\n",
            "Epoch:  23 Batch: 6\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  23 Batch: 7\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  23 Batch: 8\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  23 Batch: 9\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  23 Batch: 10\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  23 Batch: 11\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2968, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2792, device='cuda:0')\n",
            "Epoch:  23 Batch: 12\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  23 Batch: 13\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2848, device='cuda:0')\n",
            "Epoch:  23 Batch: 14\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  23 Batch: 15\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  23 Batch: 16\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  23 Batch: 17\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  23 Batch: 18\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  23 Batch: 19\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  23 Batch: 20\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  23 Batch: 21\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  23 Batch: 22\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  23 Batch: 23\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2970, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  23 Batch: 24\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  23 Batch: 25\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  23 Batch: 26\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  23 Batch: 27\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  23 Batch: 28\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  23 Batch: 29\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  23 Batch: 30\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  23 Batch: 31\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  23 Batch: 32\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  23 Batch: 33\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  23 Batch: 34\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8428, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  23 Batch: 35\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8424, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  23 Batch: 36\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8428, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  23 Batch: 37\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8431, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  23 Batch: 38\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  23 Batch: 39\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  23 Batch: 40\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  23 Batch: 41\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  23 Batch: 42\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  23 Batch: 43\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2964, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  23 Batch: 44\n",
            "ACC Train tensor(0.8852, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8485, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  23 Batch: 45\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  23 Batch: 46\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  23 Batch: 47\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  23 Batch: 48\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  23 Batch: 49\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  23 Batch: 50\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  23 Batch: 51\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  23 Batch: 52\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  23 Batch: 53\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  23 Batch: 54\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  23 Batch: 55\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2863, device='cuda:0')\n",
            "Epoch:  23 Batch: 56\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2967, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2847, device='cuda:0')\n",
            "Epoch:  23 Batch: 57\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2992, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2876, device='cuda:0')\n",
            "Epoch:  23 Batch: 58\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.3001, device='cuda:0') ACC Test tensor(0.8495, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  23 Batch: 59\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.3020, device='cuda:0') ACC Test tensor(0.8493, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  23 Batch: 60\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.3007, device='cuda:0') ACC Test tensor(0.8488, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  23 Batch: 61\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2990, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2792, device='cuda:0')\n",
            "Epoch:  23 Batch: 62\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8483, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  23 Batch: 63\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2736, device='cuda:0')\n",
            "Epoch:  23 Batch: 64\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  23 Batch: 65\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2728, device='cuda:0')\n",
            "Epoch:  23 Batch: 66\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8486, device='cuda:0') PRULEtest tensor(0.2716, device='cuda:0')\n",
            "Epoch:  23 Batch: 67\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2704, device='cuda:0')\n",
            "Epoch:  23 Batch: 68\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2853, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2695, device='cuda:0')\n",
            "Epoch:  23 Batch: 69\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2712, device='cuda:0')\n",
            "Epoch:  23 Batch: 70\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2825, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2685, device='cuda:0')\n",
            "Epoch:  23 Batch: 71\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2829, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  23 Batch: 72\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2811, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2706, device='cuda:0')\n",
            "Epoch:  23 Batch: 73\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2825, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2694, device='cuda:0')\n",
            "Epoch:  23 Batch: 74\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2688, device='cuda:0')\n",
            "Epoch:  23 Batch: 75\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2692, device='cuda:0')\n",
            "Epoch:  24 Batch: 0\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2707, device='cuda:0')\n",
            "Epoch:  24 Batch: 1\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  24 Batch: 2\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2728, device='cuda:0')\n",
            "Epoch:  24 Batch: 3\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2751, device='cuda:0')\n",
            "Epoch:  24 Batch: 4\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  24 Batch: 5\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  24 Batch: 6\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2792, device='cuda:0')\n",
            "Epoch:  24 Batch: 7\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  24 Batch: 8\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  24 Batch: 9\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  24 Batch: 10\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  24 Batch: 11\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  24 Batch: 12\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  24 Batch: 13\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  24 Batch: 14\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  24 Batch: 15\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  24 Batch: 16\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  24 Batch: 17\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2742, device='cuda:0')\n",
            "Epoch:  24 Batch: 18\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2714, device='cuda:0')\n",
            "Epoch:  24 Batch: 19\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  24 Batch: 20\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2701, device='cuda:0')\n",
            "Epoch:  24 Batch: 21\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2709, device='cuda:0')\n",
            "Epoch:  24 Batch: 22\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  24 Batch: 23\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  24 Batch: 24\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  24 Batch: 25\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2831, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  24 Batch: 26\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.2823, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2833, device='cuda:0')\n",
            "Epoch:  24 Batch: 27\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2826, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  24 Batch: 28\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2834, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2834, device='cuda:0')\n",
            "Epoch:  24 Batch: 29\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  24 Batch: 30\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  24 Batch: 31\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  24 Batch: 32\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  24 Batch: 33\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  24 Batch: 34\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8430, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  24 Batch: 35\n",
            "ACC Train tensor(0.8852, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8430, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  24 Batch: 36\n",
            "ACC Train tensor(0.8849, device='cuda:0') PRULE tensor(0.2844, device='cuda:0') ACC Test tensor(0.8428, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  24 Batch: 37\n",
            "ACC Train tensor(0.8844, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8431, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  24 Batch: 38\n",
            "ACC Train tensor(0.8846, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  24 Batch: 39\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  24 Batch: 40\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  24 Batch: 41\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2755, device='cuda:0')\n",
            "Epoch:  24 Batch: 42\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  24 Batch: 43\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2690, device='cuda:0')\n",
            "Epoch:  24 Batch: 44\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2851, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  24 Batch: 45\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2833, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2681, device='cuda:0')\n",
            "Epoch:  24 Batch: 46\n",
            "ACC Train tensor(0.8847, device='cuda:0') PRULE tensor(0.2797, device='cuda:0') ACC Test tensor(0.8434, device='cuda:0') PRULEtest tensor(0.2685, device='cuda:0')\n",
            "Epoch:  24 Batch: 47\n",
            "ACC Train tensor(0.8834, device='cuda:0') PRULE tensor(0.2794, device='cuda:0') ACC Test tensor(0.8431, device='cuda:0') PRULEtest tensor(0.2681, device='cuda:0')\n",
            "Epoch:  24 Batch: 48\n",
            "ACC Train tensor(0.8841, device='cuda:0') PRULE tensor(0.2798, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2686, device='cuda:0')\n",
            "Epoch:  24 Batch: 49\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2816, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2678, device='cuda:0')\n",
            "Epoch:  24 Batch: 50\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  24 Batch: 51\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  24 Batch: 52\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  24 Batch: 53\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  24 Batch: 54\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  24 Batch: 55\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  24 Batch: 56\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  24 Batch: 57\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2714, device='cuda:0')\n",
            "Epoch:  24 Batch: 58\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2705, device='cuda:0')\n",
            "Epoch:  24 Batch: 59\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2691, device='cuda:0')\n",
            "Epoch:  24 Batch: 60\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2677, device='cuda:0')\n",
            "Epoch:  24 Batch: 61\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2675, device='cuda:0')\n",
            "Epoch:  24 Batch: 62\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2679, device='cuda:0')\n",
            "Epoch:  24 Batch: 63\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2691, device='cuda:0')\n",
            "Epoch:  24 Batch: 64\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2669, device='cuda:0')\n",
            "Epoch:  24 Batch: 65\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2673, device='cuda:0')\n",
            "Epoch:  24 Batch: 66\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2716, device='cuda:0')\n",
            "Epoch:  24 Batch: 67\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  24 Batch: 68\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  24 Batch: 69\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  24 Batch: 70\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  24 Batch: 71\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  24 Batch: 72\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  24 Batch: 73\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  24 Batch: 74\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  24 Batch: 75\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  0 Batch: 0\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  0 Batch: 1\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  0 Batch: 2\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  0 Batch: 3\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  0 Batch: 4\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  0 Batch: 5\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  0 Batch: 6\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  0 Batch: 7\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  0 Batch: 8\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  0 Batch: 9\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2847, device='cuda:0')\n",
            "Epoch:  0 Batch: 10\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2859, device='cuda:0')\n",
            "Epoch:  0 Batch: 11\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2853, device='cuda:0')\n",
            "Epoch:  0 Batch: 12\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2840, device='cuda:0')\n",
            "Epoch:  0 Batch: 13\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  0 Batch: 14\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8485, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  0 Batch: 15\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8488, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  0 Batch: 16\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8487, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  0 Batch: 17\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8485, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  0 Batch: 18\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  0 Batch: 19\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  0 Batch: 20\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2855, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  0 Batch: 21\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  0 Batch: 22\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2857, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  0 Batch: 23\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  0 Batch: 24\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  0 Batch: 25\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  0 Batch: 26\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  0 Batch: 27\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  0 Batch: 28\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2972, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  0 Batch: 29\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2990, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  0 Batch: 30\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2973, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  0 Batch: 31\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2978, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2819, device='cuda:0')\n",
            "Epoch:  0 Batch: 32\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2964, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  0 Batch: 33\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  0 Batch: 34\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  0 Batch: 35\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2725, device='cuda:0')\n",
            "Epoch:  0 Batch: 36\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2735, device='cuda:0')\n",
            "Epoch:  0 Batch: 37\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  0 Batch: 38\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  0 Batch: 39\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  0 Batch: 40\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  0 Batch: 41\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  0 Batch: 42\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  0 Batch: 43\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  0 Batch: 44\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  0 Batch: 45\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  0 Batch: 46\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  0 Batch: 47\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  0 Batch: 48\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  0 Batch: 49\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  0 Batch: 50\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2974, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  0 Batch: 51\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2972, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  0 Batch: 52\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2846, device='cuda:0')\n",
            "Epoch:  0 Batch: 53\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2845, device='cuda:0')\n",
            "Epoch:  0 Batch: 54\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  0 Batch: 55\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  0 Batch: 56\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  0 Batch: 57\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  0 Batch: 58\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  0 Batch: 59\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  0 Batch: 60\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  0 Batch: 61\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  0 Batch: 62\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  0 Batch: 63\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  0 Batch: 64\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  0 Batch: 65\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  0 Batch: 66\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  0 Batch: 67\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  0 Batch: 68\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  0 Batch: 69\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2718, device='cuda:0')\n",
            "Epoch:  0 Batch: 70\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2707, device='cuda:0')\n",
            "Epoch:  0 Batch: 71\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2705, device='cuda:0')\n",
            "Epoch:  0 Batch: 72\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2712, device='cuda:0')\n",
            "Epoch:  0 Batch: 73\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2705, device='cuda:0')\n",
            "Epoch:  0 Batch: 74\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2709, device='cuda:0')\n",
            "Epoch:  0 Batch: 75\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  1 Batch: 0\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  1 Batch: 1\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  1 Batch: 2\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2707, device='cuda:0')\n",
            "Epoch:  1 Batch: 3\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2721, device='cuda:0')\n",
            "Epoch:  1 Batch: 4\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  1 Batch: 5\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  1 Batch: 6\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  1 Batch: 7\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2812, device='cuda:0')\n",
            "Epoch:  1 Batch: 8\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2841, device='cuda:0')\n",
            "Epoch:  1 Batch: 9\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2860, device='cuda:0')\n",
            "Epoch:  1 Batch: 10\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2857, device='cuda:0')\n",
            "Epoch:  1 Batch: 11\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2867, device='cuda:0')\n",
            "Epoch:  1 Batch: 12\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2862, device='cuda:0')\n",
            "Epoch:  1 Batch: 13\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  1 Batch: 14\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  1 Batch: 15\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  1 Batch: 16\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2981, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  1 Batch: 17\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2978, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  1 Batch: 18\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2995, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  1 Batch: 19\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2986, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  1 Batch: 20\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2976, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  1 Batch: 21\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  1 Batch: 22\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  1 Batch: 23\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2968, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  1 Batch: 24\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  1 Batch: 25\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  1 Batch: 26\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  1 Batch: 27\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  1 Batch: 28\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  1 Batch: 29\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  1 Batch: 30\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  1 Batch: 31\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  1 Batch: 32\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  1 Batch: 33\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2819, device='cuda:0')\n",
            "Epoch:  1 Batch: 34\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  1 Batch: 35\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  1 Batch: 36\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  1 Batch: 37\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  1 Batch: 38\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2721, device='cuda:0')\n",
            "Epoch:  1 Batch: 39\n",
            "ACC Train tensor(0.8851, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2728, device='cuda:0')\n",
            "Epoch:  1 Batch: 40\n",
            "ACC Train tensor(0.8845, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  1 Batch: 41\n",
            "ACC Train tensor(0.8846, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  1 Batch: 42\n",
            "ACC Train tensor(0.8850, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  1 Batch: 43\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  1 Batch: 44\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  1 Batch: 45\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  1 Batch: 46\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2841, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2716, device='cuda:0')\n",
            "Epoch:  1 Batch: 47\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2832, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2696, device='cuda:0')\n",
            "Epoch:  1 Batch: 48\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2702, device='cuda:0')\n",
            "Epoch:  1 Batch: 49\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2840, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  1 Batch: 50\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2832, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2691, device='cuda:0')\n",
            "Epoch:  1 Batch: 51\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  1 Batch: 52\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2834, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  1 Batch: 53\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2702, device='cuda:0')\n",
            "Epoch:  1 Batch: 54\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2840, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2699, device='cuda:0')\n",
            "Epoch:  1 Batch: 55\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2704, device='cuda:0')\n",
            "Epoch:  1 Batch: 56\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2826, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2701, device='cuda:0')\n",
            "Epoch:  1 Batch: 57\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2832, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2692, device='cuda:0')\n",
            "Epoch:  1 Batch: 58\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2817, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2675, device='cuda:0')\n",
            "Epoch:  1 Batch: 59\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2830, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2680, device='cuda:0')\n",
            "Epoch:  1 Batch: 60\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2828, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2694, device='cuda:0')\n",
            "Epoch:  1 Batch: 61\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2811, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2669, device='cuda:0')\n",
            "Epoch:  1 Batch: 62\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2811, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2682, device='cuda:0')\n",
            "Epoch:  1 Batch: 63\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2835, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2692, device='cuda:0')\n",
            "Epoch:  1 Batch: 64\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2853, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  1 Batch: 65\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  1 Batch: 66\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  1 Batch: 67\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  1 Batch: 68\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  1 Batch: 69\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  1 Batch: 70\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2854, device='cuda:0')\n",
            "Epoch:  1 Batch: 71\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2886, device='cuda:0')\n",
            "Epoch:  1 Batch: 72\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2853, device='cuda:0')\n",
            "Epoch:  1 Batch: 73\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2856, device='cuda:0')\n",
            "Epoch:  1 Batch: 74\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2981, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2878, device='cuda:0')\n",
            "Epoch:  1 Batch: 75\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2984, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2886, device='cuda:0')\n",
            "Epoch:  2 Batch: 0\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2990, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2881, device='cuda:0')\n",
            "Epoch:  2 Batch: 1\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2878, device='cuda:0')\n",
            "Epoch:  2 Batch: 2\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2867, device='cuda:0')\n",
            "Epoch:  2 Batch: 3\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2873, device='cuda:0')\n",
            "Epoch:  2 Batch: 4\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2838, device='cuda:0')\n",
            "Epoch:  2 Batch: 5\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  2 Batch: 6\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  2 Batch: 7\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2842, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  2 Batch: 8\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2828, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2725, device='cuda:0')\n",
            "Epoch:  2 Batch: 9\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2835, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  2 Batch: 10\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2822, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2701, device='cuda:0')\n",
            "Epoch:  2 Batch: 11\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2819, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  2 Batch: 12\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2813, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2696, device='cuda:0')\n",
            "Epoch:  2 Batch: 13\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2821, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2680, device='cuda:0')\n",
            "Epoch:  2 Batch: 14\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2840, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2695, device='cuda:0')\n",
            "Epoch:  2 Batch: 15\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2841, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2706, device='cuda:0')\n",
            "Epoch:  2 Batch: 16\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  2 Batch: 17\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2728, device='cuda:0')\n",
            "Epoch:  2 Batch: 18\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  2 Batch: 19\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  2 Batch: 20\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  2 Batch: 21\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  2 Batch: 22\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  2 Batch: 23\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2967, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2819, device='cuda:0')\n",
            "Epoch:  2 Batch: 24\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2974, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2838, device='cuda:0')\n",
            "Epoch:  2 Batch: 25\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2829, device='cuda:0')\n",
            "Epoch:  2 Batch: 26\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2972, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  2 Batch: 27\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  2 Batch: 28\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  2 Batch: 29\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  2 Batch: 30\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  2 Batch: 31\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  2 Batch: 32\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  2 Batch: 33\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  2 Batch: 34\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  2 Batch: 35\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  2 Batch: 36\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2834, device='cuda:0')\n",
            "Epoch:  2 Batch: 37\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  2 Batch: 38\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  2 Batch: 39\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  2 Batch: 40\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  2 Batch: 41\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  2 Batch: 42\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  2 Batch: 43\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  2 Batch: 44\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2751, device='cuda:0')\n",
            "Epoch:  2 Batch: 45\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2958, device='cuda:0') ACC Test tensor(0.8431, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  2 Batch: 46\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  2 Batch: 47\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  2 Batch: 48\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  2 Batch: 49\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2742, device='cuda:0')\n",
            "Epoch:  2 Batch: 50\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2967, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  2 Batch: 51\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2975, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  2 Batch: 52\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  2 Batch: 53\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  2 Batch: 54\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  2 Batch: 55\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  2 Batch: 56\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  2 Batch: 57\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  2 Batch: 58\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  2 Batch: 59\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  2 Batch: 60\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  2 Batch: 61\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  2 Batch: 62\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2742, device='cuda:0')\n",
            "Epoch:  2 Batch: 63\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2695, device='cuda:0')\n",
            "Epoch:  2 Batch: 64\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2677, device='cuda:0')\n",
            "Epoch:  2 Batch: 65\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2691, device='cuda:0')\n",
            "Epoch:  2 Batch: 66\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  2 Batch: 67\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  2 Batch: 68\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2721, device='cuda:0')\n",
            "Epoch:  2 Batch: 69\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  2 Batch: 70\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2855, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  2 Batch: 71\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2837, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  2 Batch: 72\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  2 Batch: 73\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2833, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  2 Batch: 74\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2829, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  2 Batch: 75\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2849, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  3 Batch: 0\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  3 Batch: 1\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  3 Batch: 2\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  3 Batch: 3\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  3 Batch: 4\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  3 Batch: 5\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  3 Batch: 6\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2846, device='cuda:0')\n",
            "Epoch:  3 Batch: 7\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2851, device='cuda:0')\n",
            "Epoch:  3 Batch: 8\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2875, device='cuda:0')\n",
            "Epoch:  3 Batch: 9\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2873, device='cuda:0')\n",
            "Epoch:  3 Batch: 10\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  3 Batch: 11\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2866, device='cuda:0')\n",
            "Epoch:  3 Batch: 12\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2891, device='cuda:0')\n",
            "Epoch:  3 Batch: 13\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2841, device='cuda:0')\n",
            "Epoch:  3 Batch: 14\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  3 Batch: 15\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2958, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2845, device='cuda:0')\n",
            "Epoch:  3 Batch: 16\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  3 Batch: 17\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  3 Batch: 18\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  3 Batch: 19\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  3 Batch: 20\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  3 Batch: 21\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  3 Batch: 22\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  3 Batch: 23\n",
            "ACC Train tensor(0.8850, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  3 Batch: 24\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2862, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  3 Batch: 25\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  3 Batch: 26\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  3 Batch: 27\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  3 Batch: 28\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  3 Batch: 29\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  3 Batch: 30\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  3 Batch: 31\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2727, device='cuda:0')\n",
            "Epoch:  3 Batch: 32\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  3 Batch: 33\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2736, device='cuda:0')\n",
            "Epoch:  3 Batch: 34\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  3 Batch: 35\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2755, device='cuda:0')\n",
            "Epoch:  3 Batch: 36\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  3 Batch: 37\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  3 Batch: 38\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  3 Batch: 39\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  3 Batch: 40\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  3 Batch: 41\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  3 Batch: 42\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  3 Batch: 43\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  3 Batch: 44\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  3 Batch: 45\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  3 Batch: 46\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  3 Batch: 47\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  3 Batch: 48\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  3 Batch: 49\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  3 Batch: 50\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  3 Batch: 51\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  3 Batch: 52\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  3 Batch: 53\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8425, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  3 Batch: 54\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8430, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  3 Batch: 55\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2967, device='cuda:0') ACC Test tensor(0.8430, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  3 Batch: 56\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  3 Batch: 57\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  3 Batch: 58\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  3 Batch: 59\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  3 Batch: 60\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2691, device='cuda:0')\n",
            "Epoch:  3 Batch: 61\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  3 Batch: 62\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  3 Batch: 63\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  3 Batch: 64\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  3 Batch: 65\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  3 Batch: 66\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2733, device='cuda:0')\n",
            "Epoch:  3 Batch: 67\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  3 Batch: 68\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  3 Batch: 69\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  3 Batch: 70\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  3 Batch: 71\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  3 Batch: 72\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  3 Batch: 73\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  3 Batch: 74\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  3 Batch: 75\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  4 Batch: 0\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  4 Batch: 1\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  4 Batch: 2\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  4 Batch: 3\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  4 Batch: 4\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  4 Batch: 5\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  4 Batch: 6\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2792, device='cuda:0')\n",
            "Epoch:  4 Batch: 7\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  4 Batch: 8\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  4 Batch: 9\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  4 Batch: 10\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  4 Batch: 11\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  4 Batch: 12\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  4 Batch: 13\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2735, device='cuda:0')\n",
            "Epoch:  4 Batch: 14\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2736, device='cuda:0')\n",
            "Epoch:  4 Batch: 15\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  4 Batch: 16\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  4 Batch: 17\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8434, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  4 Batch: 18\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2977, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  4 Batch: 19\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2983, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  4 Batch: 20\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2982, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  4 Batch: 21\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  4 Batch: 22\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2976, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  4 Batch: 23\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  4 Batch: 24\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  4 Batch: 25\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  4 Batch: 26\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  4 Batch: 27\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  4 Batch: 28\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2792, device='cuda:0')\n",
            "Epoch:  4 Batch: 29\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  4 Batch: 30\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  4 Batch: 31\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  4 Batch: 32\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  4 Batch: 33\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2857, device='cuda:0')\n",
            "Epoch:  4 Batch: 34\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2863, device='cuda:0')\n",
            "Epoch:  4 Batch: 35\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2866, device='cuda:0')\n",
            "Epoch:  4 Batch: 36\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2858, device='cuda:0')\n",
            "Epoch:  4 Batch: 37\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2834, device='cuda:0')\n",
            "Epoch:  4 Batch: 38\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2839, device='cuda:0')\n",
            "Epoch:  4 Batch: 39\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  4 Batch: 40\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2972, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  4 Batch: 41\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.3000, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  4 Batch: 42\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2999, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2859, device='cuda:0')\n",
            "Epoch:  4 Batch: 43\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2999, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  4 Batch: 44\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.3002, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2839, device='cuda:0')\n",
            "Epoch:  4 Batch: 45\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2985, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  4 Batch: 46\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  4 Batch: 47\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  4 Batch: 48\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  4 Batch: 49\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  4 Batch: 50\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  4 Batch: 51\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  4 Batch: 52\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  4 Batch: 53\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  4 Batch: 54\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  4 Batch: 55\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2855, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2718, device='cuda:0')\n",
            "Epoch:  4 Batch: 56\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  4 Batch: 57\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2718, device='cuda:0')\n",
            "Epoch:  4 Batch: 58\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  4 Batch: 59\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  4 Batch: 60\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  4 Batch: 61\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  4 Batch: 62\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2842, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  4 Batch: 63\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2824, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2716, device='cuda:0')\n",
            "Epoch:  4 Batch: 64\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2811, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2714, device='cuda:0')\n",
            "Epoch:  4 Batch: 65\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2809, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  4 Batch: 66\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2810, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2702, device='cuda:0')\n",
            "Epoch:  4 Batch: 67\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2833, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  4 Batch: 68\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2845, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2691, device='cuda:0')\n",
            "Epoch:  4 Batch: 69\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  4 Batch: 70\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  4 Batch: 71\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  4 Batch: 72\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  4 Batch: 73\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  4 Batch: 74\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  4 Batch: 75\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  5 Batch: 0\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2842, device='cuda:0')\n",
            "Epoch:  5 Batch: 1\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2845, device='cuda:0')\n",
            "Epoch:  5 Batch: 2\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2879, device='cuda:0')\n",
            "Epoch:  5 Batch: 3\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2862, device='cuda:0')\n",
            "Epoch:  5 Batch: 4\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2876, device='cuda:0')\n",
            "Epoch:  5 Batch: 5\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2866, device='cuda:0')\n",
            "Epoch:  5 Batch: 6\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2851, device='cuda:0')\n",
            "Epoch:  5 Batch: 7\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  5 Batch: 8\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  5 Batch: 9\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  5 Batch: 10\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  5 Batch: 11\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  5 Batch: 12\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  5 Batch: 13\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  5 Batch: 14\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  5 Batch: 15\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2851, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  5 Batch: 16\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2834, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  5 Batch: 17\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2837, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  5 Batch: 18\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2831, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  5 Batch: 19\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2828, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  5 Batch: 20\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2822, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  5 Batch: 21\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2833, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2707, device='cuda:0')\n",
            "Epoch:  5 Batch: 22\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2704, device='cuda:0')\n",
            "Epoch:  5 Batch: 23\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2837, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  5 Batch: 24\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2831, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  5 Batch: 25\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2846, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  5 Batch: 26\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  5 Batch: 27\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  5 Batch: 28\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  5 Batch: 29\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  5 Batch: 30\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2966, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2862, device='cuda:0')\n",
            "Epoch:  5 Batch: 31\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2995, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2910, device='cuda:0')\n",
            "Epoch:  5 Batch: 32\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.3029, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2916, device='cuda:0')\n",
            "Epoch:  5 Batch: 33\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.3056, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2942, device='cuda:0')\n",
            "Epoch:  5 Batch: 34\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.3050, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2964, device='cuda:0')\n",
            "Epoch:  5 Batch: 35\n",
            "ACC Train tensor(0.8850, device='cuda:0') PRULE tensor(0.3049, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.3000, device='cuda:0')\n",
            "Epoch:  5 Batch: 36\n",
            "ACC Train tensor(0.8851, device='cuda:0') PRULE tensor(0.3057, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2953, device='cuda:0')\n",
            "Epoch:  5 Batch: 37\n",
            "ACC Train tensor(0.8854, device='cuda:0') PRULE tensor(0.3050, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2936, device='cuda:0')\n",
            "Epoch:  5 Batch: 38\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.3049, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2924, device='cuda:0')\n",
            "Epoch:  5 Batch: 39\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.3030, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2899, device='cuda:0')\n",
            "Epoch:  5 Batch: 40\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2987, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2861, device='cuda:0')\n",
            "Epoch:  5 Batch: 41\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  5 Batch: 42\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  5 Batch: 43\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  5 Batch: 44\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  5 Batch: 45\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  5 Batch: 46\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  5 Batch: 47\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  5 Batch: 48\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  5 Batch: 49\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  5 Batch: 50\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  5 Batch: 51\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  5 Batch: 52\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2978, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  5 Batch: 53\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.3003, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  5 Batch: 54\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.3025, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2853, device='cuda:0')\n",
            "Epoch:  5 Batch: 55\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.3041, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2845, device='cuda:0')\n",
            "Epoch:  5 Batch: 56\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.3043, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2848, device='cuda:0')\n",
            "Epoch:  5 Batch: 57\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.3045, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2848, device='cuda:0')\n",
            "Epoch:  5 Batch: 58\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.3052, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2864, device='cuda:0')\n",
            "Epoch:  5 Batch: 59\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.3043, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2874, device='cuda:0')\n",
            "Epoch:  5 Batch: 60\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.3040, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2857, device='cuda:0')\n",
            "Epoch:  5 Batch: 61\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.3029, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2850, device='cuda:0')\n",
            "Epoch:  5 Batch: 62\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.3025, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2819, device='cuda:0')\n",
            "Epoch:  5 Batch: 63\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  5 Batch: 64\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  5 Batch: 65\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2735, device='cuda:0')\n",
            "Epoch:  5 Batch: 66\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  5 Batch: 67\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  5 Batch: 68\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2718, device='cuda:0')\n",
            "Epoch:  5 Batch: 69\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2692, device='cuda:0')\n",
            "Epoch:  5 Batch: 70\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2849, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  5 Batch: 71\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2827, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2687, device='cuda:0')\n",
            "Epoch:  5 Batch: 72\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2810, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2669, device='cuda:0')\n",
            "Epoch:  5 Batch: 73\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2805, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2650, device='cuda:0')\n",
            "Epoch:  5 Batch: 74\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2818, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2660, device='cuda:0')\n",
            "Epoch:  5 Batch: 75\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2829, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2660, device='cuda:0')\n",
            "Epoch:  6 Batch: 0\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2807, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2633, device='cuda:0')\n",
            "Epoch:  6 Batch: 1\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2807, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2629, device='cuda:0')\n",
            "Epoch:  6 Batch: 2\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2797, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2640, device='cuda:0')\n",
            "Epoch:  6 Batch: 3\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2787, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2655, device='cuda:0')\n",
            "Epoch:  6 Batch: 4\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2800, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2639, device='cuda:0')\n",
            "Epoch:  6 Batch: 5\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2803, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2651, device='cuda:0')\n",
            "Epoch:  6 Batch: 6\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2670, device='cuda:0')\n",
            "Epoch:  6 Batch: 7\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  6 Batch: 8\n",
            "ACC Train tensor(0.8891, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  6 Batch: 9\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  6 Batch: 10\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2830, device='cuda:0')\n",
            "Epoch:  6 Batch: 11\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2849, device='cuda:0')\n",
            "Epoch:  6 Batch: 12\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2972, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2871, device='cuda:0')\n",
            "Epoch:  6 Batch: 13\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2984, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2878, device='cuda:0')\n",
            "Epoch:  6 Batch: 14\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2984, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2887, device='cuda:0')\n",
            "Epoch:  6 Batch: 15\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2988, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2868, device='cuda:0')\n",
            "Epoch:  6 Batch: 16\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2983, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2889, device='cuda:0')\n",
            "Epoch:  6 Batch: 17\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2886, device='cuda:0')\n",
            "Epoch:  6 Batch: 18\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2958, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2892, device='cuda:0')\n",
            "Epoch:  6 Batch: 19\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2848, device='cuda:0')\n",
            "Epoch:  6 Batch: 20\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  6 Batch: 21\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  6 Batch: 22\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  6 Batch: 23\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  6 Batch: 24\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  6 Batch: 25\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  6 Batch: 26\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2727, device='cuda:0')\n",
            "Epoch:  6 Batch: 27\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8429, device='cuda:0') PRULEtest tensor(0.2742, device='cuda:0')\n",
            "Epoch:  6 Batch: 28\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8430, device='cuda:0') PRULEtest tensor(0.2704, device='cuda:0')\n",
            "Epoch:  6 Batch: 29\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8426, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  6 Batch: 30\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8427, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  6 Batch: 31\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8429, device='cuda:0') PRULEtest tensor(0.2703, device='cuda:0')\n",
            "Epoch:  6 Batch: 32\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8431, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  6 Batch: 33\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  6 Batch: 34\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  6 Batch: 35\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  6 Batch: 36\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  6 Batch: 37\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  6 Batch: 38\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  6 Batch: 39\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  6 Batch: 40\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2760, device='cuda:0')\n",
            "Epoch:  6 Batch: 41\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  6 Batch: 42\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2755, device='cuda:0')\n",
            "Epoch:  6 Batch: 43\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8483, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  6 Batch: 44\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8484, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  6 Batch: 45\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  6 Batch: 46\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2869, device='cuda:0')\n",
            "Epoch:  6 Batch: 47\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2868, device='cuda:0')\n",
            "Epoch:  6 Batch: 48\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2843, device='cuda:0')\n",
            "Epoch:  6 Batch: 49\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  6 Batch: 50\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  6 Batch: 51\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2813, device='cuda:0')\n",
            "Epoch:  6 Batch: 52\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  6 Batch: 53\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  6 Batch: 54\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8483, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  6 Batch: 55\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  6 Batch: 56\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  6 Batch: 57\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  6 Batch: 58\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2760, device='cuda:0')\n",
            "Epoch:  6 Batch: 59\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  6 Batch: 60\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2717, device='cuda:0')\n",
            "Epoch:  6 Batch: 61\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  6 Batch: 62\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  6 Batch: 63\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2852, device='cuda:0')\n",
            "Epoch:  6 Batch: 64\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2834, device='cuda:0')\n",
            "Epoch:  6 Batch: 65\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2840, device='cuda:0')\n",
            "Epoch:  6 Batch: 66\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  6 Batch: 67\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2846, device='cuda:0')\n",
            "Epoch:  6 Batch: 68\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2833, device='cuda:0')\n",
            "Epoch:  6 Batch: 69\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2836, device='cuda:0')\n",
            "Epoch:  6 Batch: 70\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2859, device='cuda:0')\n",
            "Epoch:  6 Batch: 71\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2860, device='cuda:0')\n",
            "Epoch:  6 Batch: 72\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  6 Batch: 73\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  6 Batch: 74\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  6 Batch: 75\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2717, device='cuda:0')\n",
            "Epoch:  7 Batch: 0\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2670, device='cuda:0')\n",
            "Epoch:  7 Batch: 1\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2637, device='cuda:0')\n",
            "Epoch:  7 Batch: 2\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2825, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2653, device='cuda:0')\n",
            "Epoch:  7 Batch: 3\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2793, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2622, device='cuda:0')\n",
            "Epoch:  7 Batch: 4\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2772, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2610, device='cuda:0')\n",
            "Epoch:  7 Batch: 5\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2767, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2609, device='cuda:0')\n",
            "Epoch:  7 Batch: 6\n",
            "ACC Train tensor(0.8848, device='cuda:0') PRULE tensor(0.2756, device='cuda:0') ACC Test tensor(0.8430, device='cuda:0') PRULEtest tensor(0.2622, device='cuda:0')\n",
            "Epoch:  7 Batch: 7\n",
            "ACC Train tensor(0.8851, device='cuda:0') PRULE tensor(0.2766, device='cuda:0') ACC Test tensor(0.8429, device='cuda:0') PRULEtest tensor(0.2650, device='cuda:0')\n",
            "Epoch:  7 Batch: 8\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2790, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  7 Batch: 9\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2801, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2695, device='cuda:0')\n",
            "Epoch:  7 Batch: 10\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2827, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  7 Batch: 11\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2842, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  7 Batch: 12\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  7 Batch: 13\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  7 Batch: 14\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  7 Batch: 15\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2851, device='cuda:0')\n",
            "Epoch:  7 Batch: 16\n",
            "ACC Train tensor(0.8856, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2854, device='cuda:0')\n",
            "Epoch:  7 Batch: 17\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2976, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2861, device='cuda:0')\n",
            "Epoch:  7 Batch: 18\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2981, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2858, device='cuda:0')\n",
            "Epoch:  7 Batch: 19\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2976, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  7 Batch: 20\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2964, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2866, device='cuda:0')\n",
            "Epoch:  7 Batch: 21\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  7 Batch: 22\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  7 Batch: 23\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2836, device='cuda:0')\n",
            "Epoch:  7 Batch: 24\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  7 Batch: 25\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  7 Batch: 26\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  7 Batch: 27\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2854, device='cuda:0')\n",
            "Epoch:  7 Batch: 28\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2864, device='cuda:0')\n",
            "Epoch:  7 Batch: 29\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  7 Batch: 30\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  7 Batch: 31\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  7 Batch: 32\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  7 Batch: 33\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  7 Batch: 34\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  7 Batch: 35\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  7 Batch: 36\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  7 Batch: 37\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2747, device='cuda:0')\n",
            "Epoch:  7 Batch: 38\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  7 Batch: 39\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  7 Batch: 40\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  7 Batch: 41\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2758, device='cuda:0')\n",
            "Epoch:  7 Batch: 42\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2733, device='cuda:0')\n",
            "Epoch:  7 Batch: 43\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  7 Batch: 44\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  7 Batch: 45\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2755, device='cuda:0')\n",
            "Epoch:  7 Batch: 46\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2831, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  7 Batch: 47\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2824, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2735, device='cuda:0')\n",
            "Epoch:  7 Batch: 48\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2830, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  7 Batch: 49\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2835, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  7 Batch: 50\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2760, device='cuda:0')\n",
            "Epoch:  7 Batch: 51\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2846, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  7 Batch: 52\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2835, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  7 Batch: 53\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2851, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  7 Batch: 54\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  7 Batch: 55\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  7 Batch: 56\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  7 Batch: 57\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  7 Batch: 58\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2792, device='cuda:0')\n",
            "Epoch:  7 Batch: 59\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8486, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  7 Batch: 60\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  7 Batch: 61\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  7 Batch: 62\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2887, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  7 Batch: 63\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  7 Batch: 64\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2836, device='cuda:0')\n",
            "Epoch:  7 Batch: 65\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  7 Batch: 66\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  7 Batch: 67\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2837, device='cuda:0')\n",
            "Epoch:  7 Batch: 68\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2962, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2873, device='cuda:0')\n",
            "Epoch:  7 Batch: 69\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2967, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2874, device='cuda:0')\n",
            "Epoch:  7 Batch: 70\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2968, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2889, device='cuda:0')\n",
            "Epoch:  7 Batch: 71\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2986, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2889, device='cuda:0')\n",
            "Epoch:  7 Batch: 72\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2992, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2886, device='cuda:0')\n",
            "Epoch:  7 Batch: 73\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2986, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  7 Batch: 74\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2971, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  7 Batch: 75\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2967, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2853, device='cuda:0')\n",
            "Epoch:  8 Batch: 0\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2833, device='cuda:0')\n",
            "Epoch:  8 Batch: 1\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2967, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2841, device='cuda:0')\n",
            "Epoch:  8 Batch: 2\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2837, device='cuda:0')\n",
            "Epoch:  8 Batch: 3\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  8 Batch: 4\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  8 Batch: 5\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  8 Batch: 6\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  8 Batch: 7\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  8 Batch: 8\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  8 Batch: 9\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  8 Batch: 10\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  8 Batch: 11\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  8 Batch: 12\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  8 Batch: 13\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  8 Batch: 14\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  8 Batch: 15\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  8 Batch: 16\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  8 Batch: 17\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  8 Batch: 18\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  8 Batch: 19\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2843, device='cuda:0')\n",
            "Epoch:  8 Batch: 20\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2838, device='cuda:0')\n",
            "Epoch:  8 Batch: 21\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2946, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2853, device='cuda:0')\n",
            "Epoch:  8 Batch: 22\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2834, device='cuda:0')\n",
            "Epoch:  8 Batch: 23\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2856, device='cuda:0')\n",
            "Epoch:  8 Batch: 24\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2976, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2852, device='cuda:0')\n",
            "Epoch:  8 Batch: 25\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2997, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2879, device='cuda:0')\n",
            "Epoch:  8 Batch: 26\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.3027, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2865, device='cuda:0')\n",
            "Epoch:  8 Batch: 27\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.3026, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2872, device='cuda:0')\n",
            "Epoch:  8 Batch: 28\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.3012, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2815, device='cuda:0')\n",
            "Epoch:  8 Batch: 29\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2990, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  8 Batch: 30\n",
            "ACC Train tensor(0.8858, device='cuda:0') PRULE tensor(0.2970, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  8 Batch: 31\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  8 Batch: 32\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  8 Batch: 33\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  8 Batch: 34\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  8 Batch: 35\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  8 Batch: 36\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2734, device='cuda:0')\n",
            "Epoch:  8 Batch: 37\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  8 Batch: 38\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  8 Batch: 39\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2724, device='cuda:0')\n",
            "Epoch:  8 Batch: 40\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  8 Batch: 41\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2678, device='cuda:0')\n",
            "Epoch:  8 Batch: 42\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2681, device='cuda:0')\n",
            "Epoch:  8 Batch: 43\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2851, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2668, device='cuda:0')\n",
            "Epoch:  8 Batch: 44\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2670, device='cuda:0')\n",
            "Epoch:  8 Batch: 45\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2854, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2674, device='cuda:0')\n",
            "Epoch:  8 Batch: 46\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2656, device='cuda:0')\n",
            "Epoch:  8 Batch: 47\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2669, device='cuda:0')\n",
            "Epoch:  8 Batch: 48\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2877, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2664, device='cuda:0')\n",
            "Epoch:  8 Batch: 49\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8433, device='cuda:0') PRULEtest tensor(0.2680, device='cuda:0')\n",
            "Epoch:  8 Batch: 50\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2709, device='cuda:0')\n",
            "Epoch:  8 Batch: 51\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2682, device='cuda:0')\n",
            "Epoch:  8 Batch: 52\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2679, device='cuda:0')\n",
            "Epoch:  8 Batch: 53\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2683, device='cuda:0')\n",
            "Epoch:  8 Batch: 54\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  8 Batch: 55\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  8 Batch: 56\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  8 Batch: 57\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  8 Batch: 58\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  8 Batch: 59\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2770, device='cuda:0')\n",
            "Epoch:  8 Batch: 60\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  8 Batch: 61\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  8 Batch: 62\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  8 Batch: 63\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  8 Batch: 64\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  8 Batch: 65\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2937, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  8 Batch: 66\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  8 Batch: 67\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2738, device='cuda:0')\n",
            "Epoch:  8 Batch: 68\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2727, device='cuda:0')\n",
            "Epoch:  8 Batch: 69\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2705, device='cuda:0')\n",
            "Epoch:  8 Batch: 70\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2707, device='cuda:0')\n",
            "Epoch:  8 Batch: 71\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2677, device='cuda:0')\n",
            "Epoch:  8 Batch: 72\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2670, device='cuda:0')\n",
            "Epoch:  8 Batch: 73\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2703, device='cuda:0')\n",
            "Epoch:  8 Batch: 74\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2719, device='cuda:0')\n",
            "Epoch:  8 Batch: 75\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  9 Batch: 0\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2833, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2713, device='cuda:0')\n",
            "Epoch:  9 Batch: 1\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2704, device='cuda:0')\n",
            "Epoch:  9 Batch: 2\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2672, device='cuda:0')\n",
            "Epoch:  9 Batch: 3\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2666, device='cuda:0')\n",
            "Epoch:  9 Batch: 4\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2848, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2657, device='cuda:0')\n",
            "Epoch:  9 Batch: 5\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2835, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  9 Batch: 6\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2816, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2676, device='cuda:0')\n",
            "Epoch:  9 Batch: 7\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2807, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2648, device='cuda:0')\n",
            "Epoch:  9 Batch: 8\n",
            "ACC Train tensor(0.8861, device='cuda:0') PRULE tensor(0.2801, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2651, device='cuda:0')\n",
            "Epoch:  9 Batch: 9\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2798, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2649, device='cuda:0')\n",
            "Epoch:  9 Batch: 10\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2826, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2652, device='cuda:0')\n",
            "Epoch:  9 Batch: 11\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2663, device='cuda:0')\n",
            "Epoch:  9 Batch: 12\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2679, device='cuda:0')\n",
            "Epoch:  9 Batch: 13\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2704, device='cuda:0')\n",
            "Epoch:  9 Batch: 14\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2930, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  9 Batch: 15\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2958, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2740, device='cuda:0')\n",
            "Epoch:  9 Batch: 16\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2973, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  9 Batch: 17\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2987, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  9 Batch: 18\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2978, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  9 Batch: 19\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2970, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  9 Batch: 20\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2838, device='cuda:0')\n",
            "Epoch:  9 Batch: 21\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  9 Batch: 22\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2842, device='cuda:0')\n",
            "Epoch:  9 Batch: 23\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  9 Batch: 24\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  9 Batch: 25\n",
            "ACC Train tensor(0.8864, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2829, device='cuda:0')\n",
            "Epoch:  9 Batch: 26\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2841, device='cuda:0')\n",
            "Epoch:  9 Batch: 27\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2834, device='cuda:0')\n",
            "Epoch:  9 Batch: 28\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2854, device='cuda:0')\n",
            "Epoch:  9 Batch: 29\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  9 Batch: 30\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  9 Batch: 31\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2760, device='cuda:0')\n",
            "Epoch:  9 Batch: 32\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2964, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  9 Batch: 33\n",
            "ACC Train tensor(0.8860, device='cuda:0') PRULE tensor(0.2970, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  9 Batch: 34\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2745, device='cuda:0')\n",
            "Epoch:  9 Batch: 35\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  9 Batch: 36\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  9 Batch: 37\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  9 Batch: 38\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2725, device='cuda:0')\n",
            "Epoch:  9 Batch: 39\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2725, device='cuda:0')\n",
            "Epoch:  9 Batch: 40\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8433, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  9 Batch: 41\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8430, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  9 Batch: 42\n",
            "ACC Train tensor(0.8857, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2697, device='cuda:0')\n",
            "Epoch:  9 Batch: 43\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2700, device='cuda:0')\n",
            "Epoch:  9 Batch: 44\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2853, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  9 Batch: 45\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2714, device='cuda:0')\n",
            "Epoch:  9 Batch: 46\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2735, device='cuda:0')\n",
            "Epoch:  9 Batch: 47\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  9 Batch: 48\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2954, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  9 Batch: 49\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  9 Batch: 50\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  9 Batch: 51\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8485, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  9 Batch: 52\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8485, device='cuda:0') PRULEtest tensor(0.2739, device='cuda:0')\n",
            "Epoch:  9 Batch: 53\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8481, device='cuda:0') PRULEtest tensor(0.2715, device='cuda:0')\n",
            "Epoch:  9 Batch: 54\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2705, device='cuda:0')\n",
            "Epoch:  9 Batch: 55\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2689, device='cuda:0')\n",
            "Epoch:  9 Batch: 56\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2685, device='cuda:0')\n",
            "Epoch:  9 Batch: 57\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2690, device='cuda:0')\n",
            "Epoch:  9 Batch: 58\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2698, device='cuda:0')\n",
            "Epoch:  9 Batch: 59\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2866, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2699, device='cuda:0')\n",
            "Epoch:  9 Batch: 60\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2702, device='cuda:0')\n",
            "Epoch:  9 Batch: 61\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2855, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2679, device='cuda:0')\n",
            "Epoch:  9 Batch: 62\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2672, device='cuda:0')\n",
            "Epoch:  9 Batch: 63\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  9 Batch: 64\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2822, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  9 Batch: 65\n",
            "ACC Train tensor(0.8863, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  9 Batch: 66\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  9 Batch: 67\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8486, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  9 Batch: 68\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  9 Batch: 69\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8484, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  9 Batch: 70\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  9 Batch: 71\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  9 Batch: 72\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2819, device='cuda:0')\n",
            "Epoch:  9 Batch: 73\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2829, device='cuda:0')\n",
            "Epoch:  9 Batch: 74\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  9 Batch: 75\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  10 Batch: 0\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  10 Batch: 1\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2876, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  10 Batch: 2\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  10 Batch: 3\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  10 Batch: 4\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  10 Batch: 5\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  10 Batch: 6\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  10 Batch: 7\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  10 Batch: 8\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2750, device='cuda:0')\n",
            "Epoch:  10 Batch: 9\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  10 Batch: 10\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2752, device='cuda:0')\n",
            "Epoch:  10 Batch: 11\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  10 Batch: 12\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  10 Batch: 13\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2703, device='cuda:0')\n",
            "Epoch:  10 Batch: 14\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2841, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  10 Batch: 15\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2862, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  10 Batch: 16\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  10 Batch: 17\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2857, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  10 Batch: 18\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  10 Batch: 19\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  10 Batch: 20\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  10 Batch: 21\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  10 Batch: 22\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  10 Batch: 23\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  10 Batch: 24\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  10 Batch: 25\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  10 Batch: 26\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2823, device='cuda:0')\n",
            "Epoch:  10 Batch: 27\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2845, device='cuda:0')\n",
            "Epoch:  10 Batch: 28\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8482, device='cuda:0') PRULEtest tensor(0.2868, device='cuda:0')\n",
            "Epoch:  10 Batch: 29\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2858, device='cuda:0')\n",
            "Epoch:  10 Batch: 30\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2916, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  10 Batch: 31\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  10 Batch: 32\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  10 Batch: 33\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2812, device='cuda:0')\n",
            "Epoch:  10 Batch: 34\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2807, device='cuda:0')\n",
            "Epoch:  10 Batch: 35\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  10 Batch: 36\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2784, device='cuda:0')\n",
            "Epoch:  10 Batch: 37\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  10 Batch: 38\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  10 Batch: 39\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  10 Batch: 40\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  10 Batch: 41\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  10 Batch: 42\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2852, device='cuda:0')\n",
            "Epoch:  10 Batch: 43\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2831, device='cuda:0')\n",
            "Epoch:  10 Batch: 44\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2856, device='cuda:0')\n",
            "Epoch:  10 Batch: 45\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2866, device='cuda:0')\n",
            "Epoch:  10 Batch: 46\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2960, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2872, device='cuda:0')\n",
            "Epoch:  10 Batch: 47\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2986, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2894, device='cuda:0')\n",
            "Epoch:  10 Batch: 48\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2978, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2925, device='cuda:0')\n",
            "Epoch:  10 Batch: 49\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2902, device='cuda:0')\n",
            "Epoch:  10 Batch: 50\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2902, device='cuda:0')\n",
            "Epoch:  10 Batch: 51\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2869, device='cuda:0')\n",
            "Epoch:  10 Batch: 52\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2928, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  10 Batch: 53\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  10 Batch: 54\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2822, device='cuda:0')\n",
            "Epoch:  10 Batch: 55\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  10 Batch: 56\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  10 Batch: 57\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2751, device='cuda:0')\n",
            "Epoch:  10 Batch: 58\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  10 Batch: 59\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  10 Batch: 60\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  10 Batch: 61\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2721, device='cuda:0')\n",
            "Epoch:  10 Batch: 62\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2716, device='cuda:0')\n",
            "Epoch:  10 Batch: 63\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2719, device='cuda:0')\n",
            "Epoch:  10 Batch: 64\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  10 Batch: 65\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2717, device='cuda:0')\n",
            "Epoch:  10 Batch: 66\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2675, device='cuda:0')\n",
            "Epoch:  10 Batch: 67\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2688, device='cuda:0')\n",
            "Epoch:  10 Batch: 68\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2688, device='cuda:0')\n",
            "Epoch:  10 Batch: 69\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2688, device='cuda:0')\n",
            "Epoch:  10 Batch: 70\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2864, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2645, device='cuda:0')\n",
            "Epoch:  10 Batch: 71\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2635, device='cuda:0')\n",
            "Epoch:  10 Batch: 72\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2857, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2649, device='cuda:0')\n",
            "Epoch:  10 Batch: 73\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2663, device='cuda:0')\n",
            "Epoch:  10 Batch: 74\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2644, device='cuda:0')\n",
            "Epoch:  10 Batch: 75\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2666, device='cuda:0')\n",
            "Epoch:  11 Batch: 0\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2668, device='cuda:0')\n",
            "Epoch:  11 Batch: 1\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  11 Batch: 2\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  11 Batch: 3\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  11 Batch: 4\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  11 Batch: 5\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  11 Batch: 6\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  11 Batch: 7\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  11 Batch: 8\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  11 Batch: 9\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  11 Batch: 10\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  11 Batch: 11\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  11 Batch: 12\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  11 Batch: 13\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  11 Batch: 14\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  11 Batch: 15\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  11 Batch: 16\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  11 Batch: 17\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  11 Batch: 18\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  11 Batch: 19\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  11 Batch: 20\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  11 Batch: 21\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  11 Batch: 22\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2871, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  11 Batch: 23\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  11 Batch: 24\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2807, device='cuda:0')\n",
            "Epoch:  11 Batch: 25\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2813, device='cuda:0')\n",
            "Epoch:  11 Batch: 26\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  11 Batch: 27\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2839, device='cuda:0')\n",
            "Epoch:  11 Batch: 28\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  11 Batch: 29\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  11 Batch: 30\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  11 Batch: 31\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2881, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  11 Batch: 32\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  11 Batch: 33\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  11 Batch: 34\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2853, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2709, device='cuda:0')\n",
            "Epoch:  11 Batch: 35\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2701, device='cuda:0')\n",
            "Epoch:  11 Batch: 36\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2869, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2705, device='cuda:0')\n",
            "Epoch:  11 Batch: 37\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2714, device='cuda:0')\n",
            "Epoch:  11 Batch: 38\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2711, device='cuda:0')\n",
            "Epoch:  11 Batch: 39\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2733, device='cuda:0')\n",
            "Epoch:  11 Batch: 40\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  11 Batch: 41\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2671, device='cuda:0')\n",
            "Epoch:  11 Batch: 42\n",
            "ACC Train tensor(0.8851, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  11 Batch: 43\n",
            "ACC Train tensor(0.8840, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  11 Batch: 44\n",
            "ACC Train tensor(0.8837, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2748, device='cuda:0')\n",
            "Epoch:  11 Batch: 45\n",
            "ACC Train tensor(0.8841, device='cuda:0') PRULE tensor(0.2966, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  11 Batch: 46\n",
            "ACC Train tensor(0.8859, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  11 Batch: 47\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  11 Batch: 48\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  11 Batch: 49\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  11 Batch: 50\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2920, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  11 Batch: 51\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  11 Batch: 52\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  11 Batch: 53\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  11 Batch: 54\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  11 Batch: 55\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2801, device='cuda:0')\n",
            "Epoch:  11 Batch: 56\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  11 Batch: 57\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  11 Batch: 58\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2974, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  11 Batch: 59\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2976, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  11 Batch: 60\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2978, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2838, device='cuda:0')\n",
            "Epoch:  11 Batch: 61\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2981, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2847, device='cuda:0')\n",
            "Epoch:  11 Batch: 62\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2986, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2870, device='cuda:0')\n",
            "Epoch:  11 Batch: 63\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2979, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2875, device='cuda:0')\n",
            "Epoch:  11 Batch: 64\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2859, device='cuda:0')\n",
            "Epoch:  11 Batch: 65\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2956, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  11 Batch: 66\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  11 Batch: 67\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  11 Batch: 68\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  11 Batch: 69\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2837, device='cuda:0')\n",
            "Epoch:  11 Batch: 70\n",
            "ACC Train tensor(0.8868, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2795, device='cuda:0')\n",
            "Epoch:  11 Batch: 71\n",
            "ACC Train tensor(0.8870, device='cuda:0') PRULE tensor(0.2894, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  11 Batch: 72\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  11 Batch: 73\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2895, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2746, device='cuda:0')\n",
            "Epoch:  11 Batch: 74\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  11 Batch: 75\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2880, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2757, device='cuda:0')\n",
            "Epoch:  12 Batch: 0\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  12 Batch: 1\n",
            "ACC Train tensor(0.8894, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  12 Batch: 2\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  12 Batch: 3\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2773, device='cuda:0')\n",
            "Epoch:  12 Batch: 4\n",
            "ACC Train tensor(0.8891, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  12 Batch: 5\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  12 Batch: 6\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2896, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2751, device='cuda:0')\n",
            "Epoch:  12 Batch: 7\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2886, device='cuda:0') ACC Test tensor(0.8431, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  12 Batch: 8\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2765, device='cuda:0')\n",
            "Epoch:  12 Batch: 9\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2891, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  12 Batch: 10\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  12 Batch: 11\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2884, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  12 Batch: 12\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  12 Batch: 13\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  12 Batch: 14\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2827, device='cuda:0')\n",
            "Epoch:  12 Batch: 15\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  12 Batch: 16\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  12 Batch: 17\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2843, device='cuda:0')\n",
            "Epoch:  12 Batch: 18\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2847, device='cuda:0')\n",
            "Epoch:  12 Batch: 19\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2925, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2844, device='cuda:0')\n",
            "Epoch:  12 Batch: 20\n",
            "ACC Train tensor(0.8892, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2844, device='cuda:0')\n",
            "Epoch:  12 Batch: 21\n",
            "ACC Train tensor(0.8891, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2837, device='cuda:0')\n",
            "Epoch:  12 Batch: 22\n",
            "ACC Train tensor(0.8891, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  12 Batch: 23\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  12 Batch: 24\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2807, device='cuda:0')\n",
            "Epoch:  12 Batch: 25\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2792, device='cuda:0')\n",
            "Epoch:  12 Batch: 26\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2870, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2782, device='cuda:0')\n",
            "Epoch:  12 Batch: 27\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2862, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2771, device='cuda:0')\n",
            "Epoch:  12 Batch: 28\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2860, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2781, device='cuda:0')\n",
            "Epoch:  12 Batch: 29\n",
            "ACC Train tensor(0.8891, device='cuda:0') PRULE tensor(0.2855, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  12 Batch: 30\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2859, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  12 Batch: 31\n",
            "ACC Train tensor(0.8892, device='cuda:0') PRULE tensor(0.2856, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2812, device='cuda:0')\n",
            "Epoch:  12 Batch: 32\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  12 Batch: 33\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2824, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  12 Batch: 34\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2819, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  12 Batch: 35\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2833, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  12 Batch: 36\n",
            "ACC Train tensor(0.8892, device='cuda:0') PRULE tensor(0.2840, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2813, device='cuda:0')\n",
            "Epoch:  12 Batch: 37\n",
            "ACC Train tensor(0.8892, device='cuda:0') PRULE tensor(0.2845, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  12 Batch: 38\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2849, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2840, device='cuda:0')\n",
            "Epoch:  12 Batch: 39\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2842, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2843, device='cuda:0')\n",
            "Epoch:  12 Batch: 40\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2842, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2838, device='cuda:0')\n",
            "Epoch:  12 Batch: 41\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2845, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2847, device='cuda:0')\n",
            "Epoch:  12 Batch: 42\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2845, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2852, device='cuda:0')\n",
            "Epoch:  12 Batch: 43\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2827, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  12 Batch: 44\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2827, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  12 Batch: 45\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2788, device='cuda:0')\n",
            "Epoch:  12 Batch: 46\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2755, device='cuda:0')\n",
            "Epoch:  12 Batch: 47\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2857, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  12 Batch: 48\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2844, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  12 Batch: 49\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2825, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2766, device='cuda:0')\n",
            "Epoch:  12 Batch: 50\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2845, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  12 Batch: 51\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2875, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2842, device='cuda:0')\n",
            "Epoch:  12 Batch: 52\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2886, device='cuda:0')\n",
            "Epoch:  12 Batch: 53\n",
            "ACC Train tensor(0.8894, device='cuda:0') PRULE tensor(0.2903, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2920, device='cuda:0')\n",
            "Epoch:  12 Batch: 54\n",
            "ACC Train tensor(0.8893, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2915, device='cuda:0')\n",
            "Epoch:  12 Batch: 55\n",
            "ACC Train tensor(0.8895, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2935, device='cuda:0')\n",
            "Epoch:  12 Batch: 56\n",
            "ACC Train tensor(0.8891, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2950, device='cuda:0')\n",
            "Epoch:  12 Batch: 57\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2999, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2954, device='cuda:0')\n",
            "Epoch:  12 Batch: 58\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.3007, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2970, device='cuda:0')\n",
            "Epoch:  12 Batch: 59\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.3024, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2974, device='cuda:0')\n",
            "Epoch:  12 Batch: 60\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.3028, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2988, device='cuda:0')\n",
            "Epoch:  12 Batch: 61\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.3025, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2949, device='cuda:0')\n",
            "Epoch:  12 Batch: 62\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.3019, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2969, device='cuda:0')\n",
            "Epoch:  12 Batch: 63\n",
            "ACC Train tensor(0.8891, device='cuda:0') PRULE tensor(0.3017, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2935, device='cuda:0')\n",
            "Epoch:  12 Batch: 64\n",
            "ACC Train tensor(0.8893, device='cuda:0') PRULE tensor(0.2989, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2894, device='cuda:0')\n",
            "Epoch:  12 Batch: 65\n",
            "ACC Train tensor(0.8894, device='cuda:0') PRULE tensor(0.2972, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2863, device='cuda:0')\n",
            "Epoch:  12 Batch: 66\n",
            "ACC Train tensor(0.8894, device='cuda:0') PRULE tensor(0.2956, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2857, device='cuda:0')\n",
            "Epoch:  12 Batch: 67\n",
            "ACC Train tensor(0.8893, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2865, device='cuda:0')\n",
            "Epoch:  12 Batch: 68\n",
            "ACC Train tensor(0.8892, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2856, device='cuda:0')\n",
            "Epoch:  12 Batch: 69\n",
            "ACC Train tensor(0.8892, device='cuda:0') PRULE tensor(0.2958, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2870, device='cuda:0')\n",
            "Epoch:  12 Batch: 70\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  12 Batch: 71\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2851, device='cuda:0')\n",
            "Epoch:  12 Batch: 72\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2857, device='cuda:0')\n",
            "Epoch:  12 Batch: 73\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2872, device='cuda:0')\n",
            "Epoch:  12 Batch: 74\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2929, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2873, device='cuda:0')\n",
            "Epoch:  12 Batch: 75\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2934, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2854, device='cuda:0')\n",
            "Epoch:  13 Batch: 0\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2915, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2843, device='cuda:0')\n",
            "Epoch:  13 Batch: 1\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2837, device='cuda:0')\n",
            "Epoch:  13 Batch: 2\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2819, device='cuda:0')\n",
            "Epoch:  13 Batch: 3\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  13 Batch: 4\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  13 Batch: 5\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2789, device='cuda:0')\n",
            "Epoch:  13 Batch: 6\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2873, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  13 Batch: 7\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2852, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2811, device='cuda:0')\n",
            "Epoch:  13 Batch: 8\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  13 Batch: 9\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  13 Batch: 10\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  13 Batch: 11\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  13 Batch: 12\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  13 Batch: 13\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2855, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2824, device='cuda:0')\n",
            "Epoch:  13 Batch: 14\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2844, device='cuda:0')\n",
            "Epoch:  13 Batch: 15\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  13 Batch: 16\n",
            "ACC Train tensor(0.8891, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2864, device='cuda:0')\n",
            "Epoch:  13 Batch: 17\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  13 Batch: 18\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2807, device='cuda:0')\n",
            "Epoch:  13 Batch: 19\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2794, device='cuda:0')\n",
            "Epoch:  13 Batch: 20\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  13 Batch: 21\n",
            "ACC Train tensor(0.8871, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8445, device='cuda:0') PRULEtest tensor(0.2791, device='cuda:0')\n",
            "Epoch:  13 Batch: 22\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2809, device='cuda:0')\n",
            "Epoch:  13 Batch: 23\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  13 Batch: 24\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2826, device='cuda:0')\n",
            "Epoch:  13 Batch: 25\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8444, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  13 Batch: 26\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2779, device='cuda:0')\n",
            "Epoch:  13 Batch: 27\n",
            "ACC Train tensor(0.8891, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  13 Batch: 28\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2857, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  13 Batch: 29\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2861, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  13 Batch: 30\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2736, device='cuda:0')\n",
            "Epoch:  13 Batch: 31\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2888, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2725, device='cuda:0')\n",
            "Epoch:  13 Batch: 32\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2721, device='cuda:0')\n",
            "Epoch:  13 Batch: 33\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2909, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2689, device='cuda:0')\n",
            "Epoch:  13 Batch: 34\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2694, device='cuda:0')\n",
            "Epoch:  13 Batch: 35\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2708, device='cuda:0')\n",
            "Epoch:  13 Batch: 36\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  13 Batch: 37\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2921, device='cuda:0') ACC Test tensor(0.8443, device='cuda:0') PRULEtest tensor(0.2710, device='cuda:0')\n",
            "Epoch:  13 Batch: 38\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2938, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  13 Batch: 39\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2756, device='cuda:0')\n",
            "Epoch:  13 Batch: 40\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  13 Batch: 41\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2951, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2764, device='cuda:0')\n",
            "Epoch:  13 Batch: 42\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2956, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2760, device='cuda:0')\n",
            "Epoch:  13 Batch: 43\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2767, device='cuda:0')\n",
            "Epoch:  13 Batch: 44\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2783, device='cuda:0')\n",
            "Epoch:  13 Batch: 45\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2787, device='cuda:0')\n",
            "Epoch:  13 Batch: 46\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2957, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  13 Batch: 47\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8479, device='cuda:0') PRULEtest tensor(0.2807, device='cuda:0')\n",
            "Epoch:  13 Batch: 48\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8478, device='cuda:0') PRULEtest tensor(0.2799, device='cuda:0')\n",
            "Epoch:  13 Batch: 49\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2776, device='cuda:0')\n",
            "Epoch:  13 Batch: 50\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  13 Batch: 51\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  13 Batch: 52\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2842, device='cuda:0')\n",
            "Epoch:  13 Batch: 53\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2949, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  13 Batch: 54\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2798, device='cuda:0')\n",
            "Epoch:  13 Batch: 55\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2940, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  13 Batch: 56\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  13 Batch: 57\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2931, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2790, device='cuda:0')\n",
            "Epoch:  13 Batch: 58\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2918, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  13 Batch: 59\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8475, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  13 Batch: 60\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8476, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  13 Batch: 61\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2723, device='cuda:0')\n",
            "Epoch:  13 Batch: 62\n",
            "ACC Train tensor(0.8891, device='cuda:0') PRULE tensor(0.2898, device='cuda:0') ACC Test tensor(0.8469, device='cuda:0') PRULEtest tensor(0.2730, device='cuda:0')\n",
            "Epoch:  13 Batch: 63\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2727, device='cuda:0')\n",
            "Epoch:  13 Batch: 64\n",
            "ACC Train tensor(0.8892, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  13 Batch: 65\n",
            "ACC Train tensor(0.8893, device='cuda:0') PRULE tensor(0.2912, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  13 Batch: 66\n",
            "ACC Train tensor(0.8894, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  13 Batch: 67\n",
            "ACC Train tensor(0.8896, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  13 Batch: 68\n",
            "ACC Train tensor(0.8890, device='cuda:0') PRULE tensor(0.2837, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2714, device='cuda:0')\n",
            "Epoch:  13 Batch: 69\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2829, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  13 Batch: 70\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2821, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2721, device='cuda:0')\n",
            "Epoch:  13 Batch: 71\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2799, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2684, device='cuda:0')\n",
            "Epoch:  13 Batch: 72\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2774, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2655, device='cuda:0')\n",
            "Epoch:  13 Batch: 73\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2773, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2655, device='cuda:0')\n",
            "Epoch:  13 Batch: 74\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2780, device='cuda:0') ACC Test tensor(0.8453, device='cuda:0') PRULEtest tensor(0.2684, device='cuda:0')\n",
            "Epoch:  13 Batch: 75\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2786, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2686, device='cuda:0')\n",
            "Epoch:  14 Batch: 0\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2786, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2696, device='cuda:0')\n",
            "Epoch:  14 Batch: 1\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2803, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2700, device='cuda:0')\n",
            "Epoch:  14 Batch: 2\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2823, device='cuda:0') ACC Test tensor(0.8430, device='cuda:0') PRULEtest tensor(0.2722, device='cuda:0')\n",
            "Epoch:  14 Batch: 3\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8431, device='cuda:0') PRULEtest tensor(0.2720, device='cuda:0')\n",
            "Epoch:  14 Batch: 4\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2840, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  14 Batch: 5\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2845, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  14 Batch: 6\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  14 Batch: 7\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2872, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  14 Batch: 8\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2883, device='cuda:0') ACC Test tensor(0.8446, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  14 Batch: 9\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2778, device='cuda:0')\n",
            "Epoch:  14 Batch: 10\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8449, device='cuda:0') PRULEtest tensor(0.2775, device='cuda:0')\n",
            "Epoch:  14 Batch: 11\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2785, device='cuda:0')\n",
            "Epoch:  14 Batch: 12\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2890, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2796, device='cuda:0')\n",
            "Epoch:  14 Batch: 13\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8433, device='cuda:0') PRULEtest tensor(0.2786, device='cuda:0')\n",
            "Epoch:  14 Batch: 14\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  14 Batch: 15\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2917, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2797, device='cuda:0')\n",
            "Epoch:  14 Batch: 16\n",
            "ACC Train tensor(0.8867, device='cuda:0') PRULE tensor(0.2913, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2812, device='cuda:0')\n",
            "Epoch:  14 Batch: 17\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2926, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2854, device='cuda:0')\n",
            "Epoch:  14 Batch: 18\n",
            "ACC Train tensor(0.8873, device='cuda:0') PRULE tensor(0.2952, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2884, device='cuda:0')\n",
            "Epoch:  14 Batch: 19\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2972, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2892, device='cuda:0')\n",
            "Epoch:  14 Batch: 20\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2997, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2931, device='cuda:0')\n",
            "Epoch:  14 Batch: 21\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2985, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2936, device='cuda:0')\n",
            "Epoch:  14 Batch: 22\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2987, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2948, device='cuda:0')\n",
            "Epoch:  14 Batch: 23\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2965, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2906, device='cuda:0')\n",
            "Epoch:  14 Batch: 24\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2956, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2882, device='cuda:0')\n",
            "Epoch:  14 Batch: 25\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2959, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2874, device='cuda:0')\n",
            "Epoch:  14 Batch: 26\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8470, device='cuda:0') PRULEtest tensor(0.2881, device='cuda:0')\n",
            "Epoch:  14 Batch: 27\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2945, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2872, device='cuda:0')\n",
            "Epoch:  14 Batch: 28\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8477, device='cuda:0') PRULEtest tensor(0.2866, device='cuda:0')\n",
            "Epoch:  14 Batch: 29\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8466, device='cuda:0') PRULEtest tensor(0.2813, device='cuda:0')\n",
            "Epoch:  14 Batch: 30\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2842, device='cuda:0')\n",
            "Epoch:  14 Batch: 31\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2908, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  14 Batch: 32\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2874, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2817, device='cuda:0')\n",
            "Epoch:  14 Batch: 33\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2865, device='cuda:0') ACC Test tensor(0.8452, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  14 Batch: 34\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2858, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2820, device='cuda:0')\n",
            "Epoch:  14 Batch: 35\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2850, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  14 Batch: 36\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2841, device='cuda:0') ACC Test tensor(0.8480, device='cuda:0') PRULEtest tensor(0.2780, device='cuda:0')\n",
            "Epoch:  14 Batch: 37\n",
            "ACC Train tensor(0.8875, device='cuda:0') PRULE tensor(0.2826, device='cuda:0') ACC Test tensor(0.8474, device='cuda:0') PRULEtest tensor(0.2741, device='cuda:0')\n",
            "Epoch:  14 Batch: 38\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2845, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  14 Batch: 39\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2849, device='cuda:0') ACC Test tensor(0.8458, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  14 Batch: 40\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2822, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2737, device='cuda:0')\n",
            "Epoch:  14 Batch: 41\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2828, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2744, device='cuda:0')\n",
            "Epoch:  14 Batch: 42\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2831, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  14 Batch: 43\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2841, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2726, device='cuda:0')\n",
            "Epoch:  14 Batch: 44\n",
            "ACC Train tensor(0.8865, device='cuda:0') PRULE tensor(0.2885, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2743, device='cuda:0')\n",
            "Epoch:  14 Batch: 45\n",
            "ACC Train tensor(0.8855, device='cuda:0') PRULE tensor(0.2892, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  14 Batch: 46\n",
            "ACC Train tensor(0.8850, device='cuda:0') PRULE tensor(0.2882, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2800, device='cuda:0')\n",
            "Epoch:  14 Batch: 47\n",
            "ACC Train tensor(0.8853, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2810, device='cuda:0')\n",
            "Epoch:  14 Batch: 48\n",
            "ACC Train tensor(0.8862, device='cuda:0') PRULE tensor(0.2904, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  14 Batch: 49\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2821, device='cuda:0')\n",
            "Epoch:  14 Batch: 50\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2944, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2848, device='cuda:0')\n",
            "Epoch:  14 Batch: 51\n",
            "ACC Train tensor(0.8872, device='cuda:0') PRULE tensor(0.2935, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2840, device='cuda:0')\n",
            "Epoch:  14 Batch: 52\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2927, device='cuda:0') ACC Test tensor(0.8434, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  14 Batch: 53\n",
            "ACC Train tensor(0.8869, device='cuda:0') PRULE tensor(0.2923, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2839, device='cuda:0')\n",
            "Epoch:  14 Batch: 54\n",
            "ACC Train tensor(0.8866, device='cuda:0') PRULE tensor(0.2902, device='cuda:0') ACC Test tensor(0.8430, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  14 Batch: 55\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2897, device='cuda:0') ACC Test tensor(0.8428, device='cuda:0') PRULEtest tensor(0.2769, device='cuda:0')\n",
            "Epoch:  14 Batch: 56\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2879, device='cuda:0') ACC Test tensor(0.8426, device='cuda:0') PRULEtest tensor(0.2753, device='cuda:0')\n",
            "Epoch:  14 Batch: 57\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2868, device='cuda:0') ACC Test tensor(0.8425, device='cuda:0') PRULEtest tensor(0.2731, device='cuda:0')\n",
            "Epoch:  14 Batch: 58\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2851, device='cuda:0') ACC Test tensor(0.8432, device='cuda:0') PRULEtest tensor(0.2681, device='cuda:0')\n",
            "Epoch:  14 Batch: 59\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2763, device='cuda:0')\n",
            "Epoch:  14 Batch: 60\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2836, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2729, device='cuda:0')\n",
            "Epoch:  14 Batch: 61\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2843, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2761, device='cuda:0')\n",
            "Epoch:  14 Batch: 62\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2828, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2774, device='cuda:0')\n",
            "Epoch:  14 Batch: 63\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2830, device='cuda:0') ACC Test tensor(0.8433, device='cuda:0') PRULEtest tensor(0.2805, device='cuda:0')\n",
            "Epoch:  14 Batch: 64\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  14 Batch: 65\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2838, device='cuda:0') ACC Test tensor(0.8435, device='cuda:0') PRULEtest tensor(0.2803, device='cuda:0')\n",
            "Epoch:  14 Batch: 66\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2846, device='cuda:0') ACC Test tensor(0.8427, device='cuda:0') PRULEtest tensor(0.2806, device='cuda:0')\n",
            "Epoch:  14 Batch: 67\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2867, device='cuda:0') ACC Test tensor(0.8429, device='cuda:0') PRULEtest tensor(0.2808, device='cuda:0')\n",
            "Epoch:  14 Batch: 68\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2889, device='cuda:0') ACC Test tensor(0.8426, device='cuda:0') PRULEtest tensor(0.2793, device='cuda:0')\n",
            "Epoch:  14 Batch: 69\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2907, device='cuda:0') ACC Test tensor(0.8425, device='cuda:0') PRULEtest tensor(0.2813, device='cuda:0')\n",
            "Epoch:  14 Batch: 70\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2914, device='cuda:0') ACC Test tensor(0.8421, device='cuda:0') PRULEtest tensor(0.2818, device='cuda:0')\n",
            "Epoch:  14 Batch: 71\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8427, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  14 Batch: 72\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2910, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2804, device='cuda:0')\n",
            "Epoch:  14 Batch: 73\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2911, device='cuda:0') ACC Test tensor(0.8441, device='cuda:0') PRULEtest tensor(0.2802, device='cuda:0')\n",
            "Epoch:  14 Batch: 74\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2893, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2762, device='cuda:0')\n",
            "Epoch:  14 Batch: 75\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2899, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2732, device='cuda:0')\n",
            "Epoch:  15 Batch: 0\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2736, device='cuda:0')\n",
            "Epoch:  15 Batch: 1\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2901, device='cuda:0') ACC Test tensor(0.8457, device='cuda:0') PRULEtest tensor(0.2749, device='cuda:0')\n",
            "Epoch:  15 Batch: 2\n",
            "ACC Train tensor(0.8888, device='cuda:0') PRULE tensor(0.2900, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2754, device='cuda:0')\n",
            "Epoch:  15 Batch: 3\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2768, device='cuda:0')\n",
            "Epoch:  15 Batch: 4\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2905, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  15 Batch: 5\n",
            "ACC Train tensor(0.8889, device='cuda:0') PRULE tensor(0.2919, device='cuda:0') ACC Test tensor(0.8462, device='cuda:0') PRULEtest tensor(0.2816, device='cuda:0')\n",
            "Epoch:  15 Batch: 6\n",
            "ACC Train tensor(0.8887, device='cuda:0') PRULE tensor(0.2939, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2854, device='cuda:0')\n",
            "Epoch:  15 Batch: 7\n",
            "ACC Train tensor(0.8886, device='cuda:0') PRULE tensor(0.2933, device='cuda:0') ACC Test tensor(0.8468, device='cuda:0') PRULEtest tensor(0.2865, device='cuda:0')\n",
            "Epoch:  15 Batch: 8\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2924, device='cuda:0') ACC Test tensor(0.8471, device='cuda:0') PRULEtest tensor(0.2860, device='cuda:0')\n",
            "Epoch:  15 Batch: 9\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2932, device='cuda:0') ACC Test tensor(0.8464, device='cuda:0') PRULEtest tensor(0.2858, device='cuda:0')\n",
            "Epoch:  15 Batch: 10\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2947, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2881, device='cuda:0')\n",
            "Epoch:  15 Batch: 11\n",
            "ACC Train tensor(0.8881, device='cuda:0') PRULE tensor(0.2969, device='cuda:0') ACC Test tensor(0.8447, device='cuda:0') PRULEtest tensor(0.2904, device='cuda:0')\n",
            "Epoch:  15 Batch: 12\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2968, device='cuda:0') ACC Test tensor(0.8436, device='cuda:0') PRULEtest tensor(0.2892, device='cuda:0')\n",
            "Epoch:  15 Batch: 13\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE tensor(0.2950, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2860, device='cuda:0')\n",
            "Epoch:  15 Batch: 14\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2942, device='cuda:0') ACC Test tensor(0.8442, device='cuda:0') PRULEtest tensor(0.2828, device='cuda:0')\n",
            "Epoch:  15 Batch: 15\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2936, device='cuda:0') ACC Test tensor(0.8438, device='cuda:0') PRULEtest tensor(0.2841, device='cuda:0')\n",
            "Epoch:  15 Batch: 16\n",
            "ACC Train tensor(0.8878, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8437, device='cuda:0') PRULEtest tensor(0.2833, device='cuda:0')\n",
            "Epoch:  15 Batch: 17\n",
            "ACC Train tensor(0.8879, device='cuda:0') PRULE tensor(0.2943, device='cuda:0') ACC Test tensor(0.8440, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  15 Batch: 18\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2948, device='cuda:0') ACC Test tensor(0.8439, device='cuda:0') PRULEtest tensor(0.2859, device='cuda:0')\n",
            "Epoch:  15 Batch: 19\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2955, device='cuda:0') ACC Test tensor(0.8448, device='cuda:0') PRULEtest tensor(0.2860, device='cuda:0')\n",
            "Epoch:  15 Batch: 20\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2964, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2855, device='cuda:0')\n",
            "Epoch:  15 Batch: 21\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2963, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2863, device='cuda:0')\n",
            "Epoch:  15 Batch: 22\n",
            "ACC Train tensor(0.8885, device='cuda:0') PRULE tensor(0.2961, device='cuda:0') ACC Test tensor(0.8451, device='cuda:0') PRULEtest tensor(0.2874, device='cuda:0')\n",
            "Epoch:  15 Batch: 23\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2953, device='cuda:0') ACC Test tensor(0.8455, device='cuda:0') PRULEtest tensor(0.2874, device='cuda:0')\n",
            "Epoch:  15 Batch: 24\n",
            "ACC Train tensor(0.8884, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8450, device='cuda:0') PRULEtest tensor(0.2889, device='cuda:0')\n",
            "Epoch:  15 Batch: 25\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2941, device='cuda:0') ACC Test tensor(0.8454, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  15 Batch: 26\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2922, device='cuda:0') ACC Test tensor(0.8456, device='cuda:0') PRULEtest tensor(0.2825, device='cuda:0')\n",
            "Epoch:  15 Batch: 27\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2906, device='cuda:0') ACC Test tensor(0.8460, device='cuda:0') PRULEtest tensor(0.2832, device='cuda:0')\n",
            "Epoch:  15 Batch: 28\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2878, device='cuda:0') ACC Test tensor(0.8472, device='cuda:0') PRULEtest tensor(0.2858, device='cuda:0')\n",
            "Epoch:  15 Batch: 29\n",
            "ACC Train tensor(0.8882, device='cuda:0') PRULE tensor(0.2863, device='cuda:0') ACC Test tensor(0.8465, device='cuda:0') PRULEtest tensor(0.2835, device='cuda:0')\n",
            "Epoch:  15 Batch: 30\n",
            "ACC Train tensor(0.8883, device='cuda:0') PRULE tensor(0.2841, device='cuda:0') ACC Test tensor(0.8473, device='cuda:0') PRULEtest tensor(0.2814, device='cuda:0')\n",
            "Epoch:  15 Batch: 31\n",
            "ACC Train tensor(0.8880, device='cuda:0') PRULE tensor(0.2847, device='cuda:0') ACC Test tensor(0.8459, device='cuda:0') PRULEtest tensor(0.2772, device='cuda:0')\n",
            "Epoch:  15 Batch: 32\n",
            "ACC Train tensor(0.8877, device='cuda:0') PRULE tensor(0.2839, device='cuda:0') ACC Test tensor(0.8467, device='cuda:0') PRULEtest tensor(0.2759, device='cuda:0')\n",
            "Epoch:  15 Batch: 33\n",
            "ACC Train tensor(0.8874, device='cuda:0') PRULE tensor(0.2826, device='cuda:0') ACC Test tensor(0.8461, device='cuda:0') PRULEtest tensor(0.2777, device='cuda:0')\n",
            "Epoch:  15 Batch: 34\n",
            "ACC Train tensor(0.8876, device='cuda:0') PRULE "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-96eeb22b5760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0modds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYpredtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mYpredtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mPRULEtest\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0modds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0modds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ACC Train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYpred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_trainCUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PRULE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPRULE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ACC Test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYpredtest\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_testCUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PRULEtest'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPRULEtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         table = np.vstack([table,[num_epochs, betamse, (Ypred.cpu().data.numpy()==y_trainCUDA.cpu().data.numpy()).sum()/X_train.shape[0]*100,PRULE.cpu().data.numpy(),ret.cpu().data.numpy(), \n\u001b[1;32m    122\u001b[0m                                 (Ypredtest.cpu().data.numpy()==y_testCUDA.cpu().data.numpy()).sum()/X_test.shape[0]*100,PRULEtest.cpu().data.numpy(),ret.cpu().data.numpy()]])\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                         \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'{{:.{}f}}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_NrGi69AGlq",
        "outputId": "e419cb18-b31b-4a7d-ce33-f1dcc502ddf7"
      },
      "source": [
        "fxtrain.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([39072, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixarmA_GAAXs",
        "outputId": "f4d261d5-a1da-4110-d953-4ee45b7bd85d"
      },
      "source": [
        "y_trainCUDA.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([39072, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0_E_2Mp92hM",
        "outputId": "2ab01a1e-9a05-448e-f815-816aae171f1d"
      },
      "source": [
        "g_train[:,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "        0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
              "        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
              "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "        0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
              "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
              "        0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
              "        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
              "        1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
              "        1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
              "        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
              "        1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "        0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
              "        0., 1., 0., 0., 0., 0., 1., 0.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjq0MQA5qz9z",
        "outputId": "c15e1311-4c26-413e-fe58-7a9b3687519d"
      },
      "source": [
        "(torch.sigmoid(fx)>0.5)==y_var"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "795SKjQvqnLa",
        "outputId": "89d1e1d0-0b11-49b1-8655-627dfee2a5d5"
      },
      "source": [
        "(g_train[:,0]+g_train[:,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "        0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
              "        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
              "        1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "        0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
              "        0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
              "        0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
              "        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
              "        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
              "        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "        1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
              "        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
              "        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
              "        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "        0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 0.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDqz-eXlqthR",
        "outputId": "c132960b-2b6c-4041-ad63-583be4aa67f7"
      },
      "source": [
        "g_train[:,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "        0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
              "        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
              "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "        0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
              "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
              "        0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
              "        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
              "        1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
              "        1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
              "        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
              "        1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "        0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
              "        0., 1., 0., 0., 0., 0., 1., 0.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvXjTNsmneSV",
        "outputId": "7afac0b1-cd2d-4615-afc4-371688184070"
      },
      "source": [
        "(bx.T*g_train[:,0]).T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.5246e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.8056e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-4.0466e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.4173e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.9095e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-4.1780e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.2023e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-4.2693e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-4.2898e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-4.4255e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-4.1153e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-2.8386e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.2876e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.6774e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.9159e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.5913e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-4.2529e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-4.1680e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-4.4185e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.2601e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-4.1022e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-3.7331e+14],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00],\n",
              "        [-0.0000e+00]], device='cuda:0', grad_fn=<PermuteBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-68C1VvGnKWs",
        "outputId": "d93d71ce-5c63-4d51-81fc-82b04227eadb"
      },
      "source": [
        "ypred_var"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.9911e+00],\n",
              "        [-4.3086e+14],\n",
              "        [-3.3302e+14],\n",
              "        [-4.2306e+14],\n",
              "        [-3.6673e+00],\n",
              "        [-5.0481e+00],\n",
              "        [-5.1035e+00],\n",
              "        [-7.1505e+00],\n",
              "        [-3.5063e+14],\n",
              "        [-3.7704e+14],\n",
              "        [-4.3549e+14],\n",
              "        [-3.5246e+14],\n",
              "        [-6.1639e+00],\n",
              "        [-6.4046e+00],\n",
              "        [-5.5026e+00],\n",
              "        [-4.6898e+00],\n",
              "        [-4.4032e+14],\n",
              "        [-3.4225e+14],\n",
              "        [-5.3682e+00],\n",
              "        [-4.5587e+14],\n",
              "        [-1.7998e+00],\n",
              "        [-3.3343e+14],\n",
              "        [-3.7069e+14],\n",
              "        [-4.4304e+14],\n",
              "        [-5.9034e+00],\n",
              "        [-5.8294e+00],\n",
              "        [-3.0609e+14],\n",
              "        [-4.1332e+14],\n",
              "        [-7.5818e+00],\n",
              "        [-3.4790e+14],\n",
              "        [-2.5957e+00],\n",
              "        [-3.8634e+14],\n",
              "        [-5.2786e+00],\n",
              "        [-4.2858e+14],\n",
              "        [-5.1333e+00],\n",
              "        [-2.4065e+00],\n",
              "        [-3.3925e+14],\n",
              "        [-3.4660e+14],\n",
              "        [-7.4886e+00],\n",
              "        [-3.4250e+14],\n",
              "        [-3.2546e+14],\n",
              "        [-4.3069e+14],\n",
              "        [-3.4838e+14],\n",
              "        [-3.6687e+14],\n",
              "        [-3.6995e+00],\n",
              "        [-6.8735e+00],\n",
              "        [-1.4327e+00],\n",
              "        [-4.2699e+14],\n",
              "        [-4.3208e+14],\n",
              "        [-6.3528e+00],\n",
              "        [-5.0769e+00],\n",
              "        [-4.2954e+14],\n",
              "        [-2.0896e+00],\n",
              "        [-3.9841e+14],\n",
              "        [-7.0969e+00],\n",
              "        [-7.3244e+00],\n",
              "        [-3.5742e+14],\n",
              "        [-3.9339e+14],\n",
              "        [-6.9678e+00],\n",
              "        [-3.0345e+14],\n",
              "        [-4.1695e+14],\n",
              "        [-3.5061e+14],\n",
              "        [-3.6187e+14],\n",
              "        [-4.7634e+14],\n",
              "        [-3.5735e+14],\n",
              "        [-6.0554e+00],\n",
              "        [-4.0479e+14],\n",
              "        [-4.2220e+14],\n",
              "        [-5.6641e+00],\n",
              "        [-4.4253e+14],\n",
              "        [-2.5861e+14],\n",
              "        [-4.0097e+14],\n",
              "        [-2.9388e+00],\n",
              "        [-4.3319e+14],\n",
              "        [-5.4880e+00],\n",
              "        [-4.3617e+00],\n",
              "        [-4.2782e+14],\n",
              "        [-6.1288e+00],\n",
              "        [-3.5134e+14],\n",
              "        [-3.8056e+14],\n",
              "        [-4.5342e+14],\n",
              "        [-4.3617e+14],\n",
              "        [-6.9990e+00],\n",
              "        [ 8.0791e-01],\n",
              "        [-3.8348e+00],\n",
              "        [-5.6368e+00],\n",
              "        [-4.3950e+14],\n",
              "        [-3.7643e+14],\n",
              "        [-4.0982e+00],\n",
              "        [-2.6568e+00],\n",
              "        [-4.4175e+14],\n",
              "        [-7.3069e+00],\n",
              "        [-3.7790e+14],\n",
              "        [-6.6674e+00],\n",
              "        [-3.9372e+14],\n",
              "        [-3.3321e+00],\n",
              "        [-3.2566e+00],\n",
              "        [-6.8978e+00],\n",
              "        [-7.4736e+00],\n",
              "        [-3.1228e+00],\n",
              "        [-3.3788e+14],\n",
              "        [ 1.4339e+00],\n",
              "        [-5.1243e+00],\n",
              "        [-3.7051e+00],\n",
              "        [-5.7604e+00],\n",
              "        [-5.5573e+00],\n",
              "        [-3.4720e+14],\n",
              "        [-4.8427e+00],\n",
              "        [-7.1296e+00],\n",
              "        [-4.0589e+00],\n",
              "        [-4.6329e+00],\n",
              "        [-4.2316e+14],\n",
              "        [-2.5006e-01],\n",
              "        [-3.8862e+00],\n",
              "        [-4.0466e+14],\n",
              "        [-8.2982e+00],\n",
              "        [-4.6741e+00],\n",
              "        [-6.3270e+00],\n",
              "        [-3.5844e+14],\n",
              "        [-4.3130e+14],\n",
              "        [-7.1889e+00],\n",
              "        [-4.1309e+14],\n",
              "        [-7.6153e+00],\n",
              "        [-3.6659e+14],\n",
              "        [-3.3429e+14],\n",
              "        [-4.2582e+14],\n",
              "        [-4.4287e+14],\n",
              "        [-2.8509e+00],\n",
              "        [-3.3821e+00],\n",
              "        [-7.2539e+00],\n",
              "        [-3.4173e+14],\n",
              "        [-8.4008e+00],\n",
              "        [-4.2535e+14],\n",
              "        [-3.3325e+00],\n",
              "        [-3.4443e+00],\n",
              "        [-4.8097e+00],\n",
              "        [-2.1554e+00],\n",
              "        [-4.7778e+00],\n",
              "        [-6.0077e+00],\n",
              "        [-4.7161e+00],\n",
              "        [-8.4058e+00],\n",
              "        [-8.2544e+00],\n",
              "        [-2.8199e+00],\n",
              "        [-3.7767e+14],\n",
              "        [-5.6127e+00],\n",
              "        [-3.0171e+14],\n",
              "        [-3.9095e+14],\n",
              "        [-3.8806e+00],\n",
              "        [-3.5021e+14],\n",
              "        [-3.4566e+14],\n",
              "        [-3.6248e+14],\n",
              "        [-2.1958e+00],\n",
              "        [-3.6111e+00],\n",
              "        [-4.4144e+14],\n",
              "        [-6.4224e+00],\n",
              "        [-3.7738e+14],\n",
              "        [-2.8529e+00],\n",
              "        [-7.9193e-01],\n",
              "        [-3.4470e+14],\n",
              "        [-6.4829e+00],\n",
              "        [-6.3045e+00],\n",
              "        [-3.0383e+00],\n",
              "        [-6.2759e+00],\n",
              "        [-2.4053e+00],\n",
              "        [-4.4790e+14],\n",
              "        [-7.4764e+00],\n",
              "        [ 1.4958e+00],\n",
              "        [-2.8087e+00],\n",
              "        [-1.1584e+00],\n",
              "        [-6.9435e+00],\n",
              "        [-2.4210e+00],\n",
              "        [-1.2293e+00],\n",
              "        [-5.4158e+00],\n",
              "        [-4.1149e+14],\n",
              "        [-5.0316e+00],\n",
              "        [-3.6769e+14],\n",
              "        [-5.5767e+00],\n",
              "        [-4.4552e+14],\n",
              "        [-6.1699e+00],\n",
              "        [-3.6214e+14],\n",
              "        [-3.0401e+00],\n",
              "        [-3.7559e+00],\n",
              "        [-5.8141e+00],\n",
              "        [-4.0189e+14],\n",
              "        [-1.2128e+00],\n",
              "        [-3.5986e+14],\n",
              "        [-7.8564e+00],\n",
              "        [-2.4592e+00],\n",
              "        [-4.5822e+14],\n",
              "        [-3.9800e+14],\n",
              "        [-1.9194e+00],\n",
              "        [-3.7333e+14],\n",
              "        [-4.9274e+00],\n",
              "        [-6.9431e+00],\n",
              "        [-3.2922e+14],\n",
              "        [-3.8579e+00],\n",
              "        [-3.4853e+14],\n",
              "        [-4.1533e+00],\n",
              "        [-2.5790e+00],\n",
              "        [-3.9926e+14],\n",
              "        [-6.0105e+00],\n",
              "        [-5.5554e+00],\n",
              "        [-5.4818e+00],\n",
              "        [-3.8375e+14],\n",
              "        [-6.6039e+00],\n",
              "        [-6.4211e+00],\n",
              "        [-3.8196e+14],\n",
              "        [-7.6077e-01],\n",
              "        [-3.5356e+14],\n",
              "        [-6.7445e+00],\n",
              "        [-2.6397e+00],\n",
              "        [-4.6865e+00],\n",
              "        [-8.6318e+00],\n",
              "        [-5.7695e+00],\n",
              "        [-4.1780e+14],\n",
              "        [-3.7490e+00],\n",
              "        [-4.4202e+14],\n",
              "        [-1.8546e+00],\n",
              "        [-3.2023e+14],\n",
              "        [-4.4406e+14],\n",
              "        [-4.4514e+14],\n",
              "        [-7.3141e+00],\n",
              "        [-2.9481e+00],\n",
              "        [-6.9495e+00],\n",
              "        [-4.1800e+14],\n",
              "        [-6.8137e+00],\n",
              "        [-4.2980e+14],\n",
              "        [-4.3484e+14],\n",
              "        [-4.3380e+14],\n",
              "        [-4.0011e+14],\n",
              "        [-5.7336e+00],\n",
              "        [-5.6802e+00],\n",
              "        [-3.9469e+14],\n",
              "        [-4.3625e+14],\n",
              "        [-4.9401e+00],\n",
              "        [-3.0562e+00],\n",
              "        [-4.8817e+00],\n",
              "        [-4.2557e+14],\n",
              "        [-4.4032e+14],\n",
              "        [-3.0287e+00],\n",
              "        [-6.6818e+00],\n",
              "        [-3.2148e+14],\n",
              "        [-4.2693e+14],\n",
              "        [-4.2027e+14],\n",
              "        [-3.0899e+00],\n",
              "        [-4.2749e+14],\n",
              "        [-3.4120e+14],\n",
              "        [-3.5019e+14],\n",
              "        [-6.9196e+00],\n",
              "        [-4.5282e+14],\n",
              "        [-4.4688e+14],\n",
              "        [-3.6991e+00],\n",
              "        [-5.8927e+00],\n",
              "        [-4.7262e+00],\n",
              "        [-5.3076e+00],\n",
              "        [-1.8703e+00],\n",
              "        [-3.7939e+14],\n",
              "        [-3.5927e+14],\n",
              "        [-4.2898e+14],\n",
              "        [-6.1276e+00],\n",
              "        [-4.5705e+14],\n",
              "        [-3.5609e+00],\n",
              "        [-9.2381e+00],\n",
              "        [-3.5624e+14],\n",
              "        [-4.2106e+00],\n",
              "        [-3.7506e+14],\n",
              "        [-4.4255e+14],\n",
              "        [-1.2624e+00],\n",
              "        [-4.4759e+00],\n",
              "        [-4.4425e+14],\n",
              "        [-4.6600e+00],\n",
              "        [-5.4898e+00],\n",
              "        [-4.1089e+14],\n",
              "        [-4.9488e+00],\n",
              "        [-3.4490e+14],\n",
              "        [-3.9069e+14],\n",
              "        [-4.4433e+00],\n",
              "        [-1.2494e+00],\n",
              "        [-4.5533e+14],\n",
              "        [-3.6023e+14],\n",
              "        [-3.5804e+14],\n",
              "        [-3.8887e+14],\n",
              "        [-4.8130e+00],\n",
              "        [-3.2464e+14],\n",
              "        [-4.1153e+14],\n",
              "        [-3.8400e+14],\n",
              "        [-1.4500e+00],\n",
              "        [-3.3209e+00],\n",
              "        [-5.8553e+00],\n",
              "        [-4.0894e+00],\n",
              "        [-8.0451e+00],\n",
              "        [-4.3915e+14],\n",
              "        [-3.9232e+14],\n",
              "        [-2.8386e+14],\n",
              "        [-3.2756e+14],\n",
              "        [-4.3100e+14],\n",
              "        [-6.3526e+00],\n",
              "        [-4.9911e+00],\n",
              "        [-6.2172e+00],\n",
              "        [-4.4995e+14],\n",
              "        [-3.9384e+00],\n",
              "        [-4.6418e+00],\n",
              "        [-2.7050e+00],\n",
              "        [-4.3980e+14],\n",
              "        [-3.1001e+14],\n",
              "        [-4.7602e+00],\n",
              "        [-4.3234e+14],\n",
              "        [-3.8927e+14],\n",
              "        [-4.5326e+14],\n",
              "        [-4.2953e+14],\n",
              "        [-3.9386e+14],\n",
              "        [-4.3263e+14],\n",
              "        [ 1.4761e+00],\n",
              "        [-3.8484e+14],\n",
              "        [-1.1753e+00],\n",
              "        [-9.5532e-01],\n",
              "        [-1.8992e+00],\n",
              "        [-3.5648e+14],\n",
              "        [-4.4499e+14],\n",
              "        [-4.0570e+00],\n",
              "        [-4.2730e+14],\n",
              "        [-3.5029e+00],\n",
              "        [-7.4702e+00],\n",
              "        [-4.5331e+14],\n",
              "        [-7.6262e+00],\n",
              "        [-4.7397e+00],\n",
              "        [-6.2079e+00],\n",
              "        [-4.4493e+00],\n",
              "        [-6.3477e+00],\n",
              "        [-5.2096e+00],\n",
              "        [-5.3376e+00],\n",
              "        [-4.4525e+14],\n",
              "        [-3.1342e+14],\n",
              "        [-1.7797e+00],\n",
              "        [-7.2899e+00],\n",
              "        [-3.7422e+14],\n",
              "        [-6.0292e+00],\n",
              "        [-3.5947e+14],\n",
              "        [-4.2325e+14],\n",
              "        [-3.9164e+14],\n",
              "        [-3.2876e+14],\n",
              "        [-3.6005e+14],\n",
              "        [-4.1310e+14],\n",
              "        [ 4.5919e+00],\n",
              "        [-4.2937e+14],\n",
              "        [-6.2833e+00],\n",
              "        [-6.2269e+00],\n",
              "        [-3.5282e+14],\n",
              "        [-4.7698e+00],\n",
              "        [-3.6774e+14],\n",
              "        [-4.1119e+14],\n",
              "        [-4.3687e+14],\n",
              "        [-7.4364e+00],\n",
              "        [-1.2830e+00],\n",
              "        [-3.8151e+14],\n",
              "        [-3.4264e+14],\n",
              "        [-5.2132e+00],\n",
              "        [-4.2480e+00],\n",
              "        [-8.7025e+00],\n",
              "        [-2.9714e+00],\n",
              "        [-4.3533e+14],\n",
              "        [-3.9159e+14],\n",
              "        [-2.4542e+00],\n",
              "        [-1.5116e+00],\n",
              "        [-4.3499e+14],\n",
              "        [-4.5475e+14],\n",
              "        [-4.3980e+00],\n",
              "        [-4.3631e+00],\n",
              "        [-6.9039e+00],\n",
              "        [-4.1866e+14],\n",
              "        [-3.8466e+14],\n",
              "        [-4.4183e+14],\n",
              "        [ 2.4419e-01],\n",
              "        [-4.3334e+14],\n",
              "        [-5.1993e+00],\n",
              "        [-3.6663e+14],\n",
              "        [-3.8465e+14],\n",
              "        [-5.7758e+00],\n",
              "        [-3.6731e+14],\n",
              "        [-4.3090e+14],\n",
              "        [-3.5913e+14],\n",
              "        [-4.3927e+14],\n",
              "        [-3.0577e+14],\n",
              "        [-7.2909e+00],\n",
              "        [-7.3074e+00],\n",
              "        [-2.4310e+00],\n",
              "        [-3.3186e+14],\n",
              "        [-4.2529e+14],\n",
              "        [-2.8307e+00],\n",
              "        [ 6.0422e-01],\n",
              "        [-4.0025e+14],\n",
              "        [-9.9430e-01],\n",
              "        [-7.4684e+00],\n",
              "        [-4.0676e+14],\n",
              "        [-3.3139e+00],\n",
              "        [-3.8771e+14],\n",
              "        [-2.5887e+00],\n",
              "        [-3.6928e+00],\n",
              "        [-4.1012e+14],\n",
              "        [-4.6544e+00],\n",
              "        [-6.5731e+00],\n",
              "        [-3.1103e+14],\n",
              "        [-4.4569e+14],\n",
              "        [-3.6525e+14],\n",
              "        [-4.4319e+14],\n",
              "        [-4.0113e+14],\n",
              "        [-5.3865e+00],\n",
              "        [-4.3758e+14],\n",
              "        [-5.8627e-02],\n",
              "        [-7.9074e+00],\n",
              "        [-4.1680e+14],\n",
              "        [-3.4807e+14],\n",
              "        [-2.6787e+00],\n",
              "        [-3.4991e+14],\n",
              "        [-7.6610e+00],\n",
              "        [ 2.3635e+00],\n",
              "        [-2.8401e+00],\n",
              "        [-4.6772e+00],\n",
              "        [-4.4185e+14],\n",
              "        [-6.4574e+00],\n",
              "        [-6.2355e-01],\n",
              "        [-7.6770e+00],\n",
              "        [-5.3618e+00],\n",
              "        [-3.0579e+00],\n",
              "        [-3.7829e+14],\n",
              "        [-2.0974e+14],\n",
              "        [-4.0361e+14],\n",
              "        [-4.1678e+00],\n",
              "        [-4.2795e+14],\n",
              "        [-6.5805e+00],\n",
              "        [-3.7083e+14],\n",
              "        [-3.2704e+00],\n",
              "        [-4.4438e+14],\n",
              "        [-8.0097e+00],\n",
              "        [-3.8888e+14],\n",
              "        [-4.5087e+00],\n",
              "        [-3.2601e+14],\n",
              "        [-4.1318e+14],\n",
              "        [-5.8044e+00],\n",
              "        [-4.0196e+00],\n",
              "        [-4.3264e+14],\n",
              "        [-4.9566e+00],\n",
              "        [-4.3684e+14],\n",
              "        [-3.3314e+14],\n",
              "        [-5.0664e+00],\n",
              "        [-4.3973e+14],\n",
              "        [-3.9216e+14],\n",
              "        [-5.8938e+00],\n",
              "        [-4.5590e+00],\n",
              "        [-5.2268e+00],\n",
              "        [-5.4365e+00],\n",
              "        [-3.6024e+14],\n",
              "        [-4.6592e+00],\n",
              "        [-7.3846e+00],\n",
              "        [-3.5169e+14],\n",
              "        [-6.2131e+00],\n",
              "        [-4.3915e+14],\n",
              "        [-4.0445e+14],\n",
              "        [-6.9481e+00],\n",
              "        [-2.6941e+00],\n",
              "        [-3.8448e+14],\n",
              "        [-6.0377e+00],\n",
              "        [-4.0669e+00],\n",
              "        [-4.2418e+14],\n",
              "        [-3.3957e+14],\n",
              "        [-4.4765e+00],\n",
              "        [-2.3993e+00],\n",
              "        [-3.8835e+14],\n",
              "        [-1.5729e+00],\n",
              "        [-3.0719e+00],\n",
              "        [-4.0048e+14],\n",
              "        [-3.1914e+00],\n",
              "        [-7.1887e+00],\n",
              "        [-3.8382e+14],\n",
              "        [-3.6593e+00],\n",
              "        [-4.2649e+14],\n",
              "        [-3.6917e+14],\n",
              "        [-1.6880e+00],\n",
              "        [-4.3856e+14],\n",
              "        [-3.9012e+14],\n",
              "        [-4.0209e+00],\n",
              "        [-5.7564e+00],\n",
              "        [-3.7635e+14],\n",
              "        [-5.8384e+00],\n",
              "        [-4.5138e+00],\n",
              "        [-5.4586e+00],\n",
              "        [-2.2189e+00],\n",
              "        [-7.5278e+00],\n",
              "        [-4.4029e+00],\n",
              "        [-4.3486e+14],\n",
              "        [-4.9419e+00],\n",
              "        [-4.3718e+00],\n",
              "        [-4.2685e+00],\n",
              "        [-2.1469e+00],\n",
              "        [-1.9257e+00],\n",
              "        [-4.3784e+14],\n",
              "        [-4.2655e+14],\n",
              "        [-3.7675e+14],\n",
              "        [-3.5098e+14],\n",
              "        [-4.3904e+14],\n",
              "        [-4.1022e+14],\n",
              "        [-2.9764e+00],\n",
              "        [-3.7047e+00],\n",
              "        [-4.2494e+14],\n",
              "        [-7.2125e+00],\n",
              "        [-4.2826e+14],\n",
              "        [-2.0910e+00],\n",
              "        [-4.2008e+00],\n",
              "        [-3.7331e+14],\n",
              "        [-7.6006e+00],\n",
              "        [-3.6404e+14],\n",
              "        [-5.2481e+00]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNH69TuOmkLv",
        "outputId": "0cd78c3e-3a9b-41d3-8c3a-9c6350cf378d"
      },
      "source": [
        "a=(bx.T*g_train[:,0]).T\n",
        "a.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFKr2Sh5mdMP",
        "outputId": "09aa3930-c8b6-4673-cfda-52b7469b22ae"
      },
      "source": [
        "fx.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4poV2b9jLQd",
        "outputId": "b9dbbf94-0479-42bb-8481-9dd6890a11b2"
      },
      "source": [
        "G_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39072, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr4jYbFri9tO",
        "outputId": "5d6be770-32b8-4fc4-a0d1-2be9932ea262"
      },
      "source": [
        "gtrain.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39072, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Eer_m3iiX7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}